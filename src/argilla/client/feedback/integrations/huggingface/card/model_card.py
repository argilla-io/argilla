#  Copyright 2021-present, the Recognai S.L. team.
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.

from dataclasses import dataclass, field, fields
from pathlib import Path
from platform import python_version
from typing import TYPE_CHECKING, Any, Callable, Dict, List, Literal, Optional, Union

from huggingface_hub import CardData, ModelCard
from huggingface_hub.utils import yaml_dump

from argilla._version import version
from argilla.client.feedback.training.schemas import TrainingTaskTypes
from argilla.client.models import Framework

if TYPE_CHECKING:
    import spacy
    from transformers import PreTrainedTokenizer


TEMPLATE_ARGILLA_MODEL_CARD_PATH = Path(__file__).parent / "argilla_model_template.md"


FRAMEWORK_TO_NAME_MAPPING = {
    "transformers": "Transformers",
    "peft": "PEFT Transformers library",
    "setfit": "SetFit Transformers library",
    "spacy": "Spacy Explosion",
    "spacy-transformers": "Spacy Transformers Explosion library",
    "span_marker": "SpanMarker Tom Aarsen library",
    "spark-nlp": "Spark NLP John Snow Labs library",
    "openai": "OpenAI LLMs",
    "trl": "Transformer Reinforcement Learning",
    "trlx": "Transformer Reinforcement Learning X",
    "sentence-transformers": "Sentence Transformers library",
}


TaskTypes = Literal[
    "for_text_classification",
    "for_supervised_fine_tuning",
    "for_reward_modeling",
    "for_proximal_policy_optimization",
    "for_direct_preference_optimization",
    "for_chat_completion",
    "for_question_answering",
    "for_sentence_similarity",
]


AUTOGENERATED_TRAINER_COMMENT = """
<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->
"""


TEMPLATE_TASK_CALL = "task = TrainingTask.{task_type}({training_task_args})"

YAML_FIELDS = [
    "language",
    "license",
    "tags",
    "metrics",
    "model-index",
    "base_model",
]


class ArgillaModelCard(ModelCard):
    """`ArgillaModelCard` has been created similarly to `ModelCard` from
    `huggingface_hub` but with a different template. The template is located at
    `argilla/client/feedback/integrations/huggingface/card/argilla_model_template.md`.
    """

    default_template_path = TEMPLATE_ARGILLA_MODEL_CARD_PATH


@dataclass
class FrameworkCardData(CardData):
    """Parent class to generate the variables to add to the ModelCard.

    Each framework will inherit from here and update accordingly.
    """

    # User provided
    language: Optional[Union[str, List[str]]] = None
    license: Optional[str] = None
    model_name: Optional[str] = None
    model_id: Optional[str] = None
    encoder_name: Optional[str] = None
    encoder_id: Optional[str] = None
    dataset_name: Optional[str] = None
    dataset_id: Optional[str] = None
    dataset_revision: Optional[str] = None
    tags: Optional[List[str]] = field(default_factory=lambda: ["argilla"])

    # Obtained internally from each trainer
    framework: Optional[Framework] = None
    train_size: Optional[float] = None
    seed: Optional[int] = None
    framework_kwargs: Dict[str, Any] = field(default_factory=dict)
    task: Optional[TrainingTaskTypes] = None
    task_type: Optional[TaskTypes] = None
    version: Dict[str, str] = field(
        default_factory=lambda: {
            "python": python_version(),
            "argilla": version,
        },
        init=False,
    )

    def _trainer_task_call(self) -> str:
        """Generates the creation of the `TrainingTask*` call.

        Returns:
            Representation of the training task creation as a str.
        """
        pass

    def _to_dict(self) -> Dict[str, str]:
        """Write this method to insert variables pertaining to a special framework only."""
        return {}

    def to_dict(self) -> Dict[str, Any]:
        """Main method to generate the variables that will be written in the model card."""
        default_kwargs = {field.name: getattr(self, field.name) for field in fields(self)}

        kwargs = {
            "framework": self.framework.value,
            "trainer_task_call": self._trainer_task_call(),
        }

        if self.framework_kwargs:
            kwargs["framework_kwargs"] = f"framework_kwargs={str(self.framework_kwargs)}"

        if extra_kwargs := self._to_dict():
            kwargs.update(**extra_kwargs)

        return {**default_kwargs, **kwargs}

    def to_yaml(self, line_break=None) -> str:
        return yaml_dump(
            {key: value for key, value in self.to_dict().items() if key in YAML_FIELDS and value is not None},
            sort_keys=False,
            line_break=line_break,
        ).strip()


@dataclass
class SpacyModelCardDataBase(FrameworkCardData):
    task_type: str = "for_text_classification"
    lang: Optional["spacy.Language"] = None
    gpu_id: Optional[int] = -1

    def _trainer_task_call(self) -> str:
        task_call = ""
        if formatting_func := self.task.formatting_func:
            from inspect import getsource

            task_call += getsource(formatting_func) + "\n"
            training_task_args = "formatting_func=formatting_func"
        else:
            training_task_args = (
                f"text=dataset.field_by_name({self.task.texts}){f', label=dataset.question_by_name({self.task.label})'}"
            )
        return task_call + TEMPLATE_TASK_CALL.format(task_type=self.task_type, training_task_args=training_task_args)

    def _to_dict(self) -> Dict[str, str]:
        return {"gpu_id": self.gpu_id, "lang": self.lang}


@dataclass
class SpacyModelCardData(SpacyModelCardDataBase):
    framework: Framework = Framework("spacy")
    freeze_tok2vec: bool = False

    def _to_dict(self) -> Dict[str, str]:
        kwargs = super()._to_dict()
        # Only add this variable if is different from the default
        if freeze_tok2vec := self.freeze_tok2vec:
            kwargs.update({"freeze_tok2vec": freeze_tok2vec})
        return kwargs


@dataclass
class SpacyTransformersModelCardData(FrameworkCardData):
    framework: Framework = Framework("spacy-transformers")
    update_transformer: bool = True

    def _to_dict(self) -> Dict[str, str]:
        kwargs = super()._to_dict()
        if update_transformer := not self.update_transformer:
            kwargs.update({"update_transformer": update_transformer})
        return kwargs


@dataclass
class TransformersModelCardDataBase(FrameworkCardData):
    task_type: str = "for_text_classification"
    tokenizer: "PreTrainedTokenizer" = ""

    def _trainer_task_call(self) -> str:
        task_call = ""
        if formatting_func := self.task.formatting_func:
            from inspect import getsource

            task_call += getsource(formatting_func) + "\n"
            training_task_args = "formatting_func=formatting_func"
        else:
            text = f'dataset.field_by_name("{self.task.text.name}")'
            training_task_args = (
                f"text=dataset.field_by_name({text}), label=dataset.question_by_name({self.task.label.question.name})"
            )
        return task_call + TEMPLATE_TASK_CALL.format(task_type=self.task_type, training_task_args=training_task_args)

    def _to_dict(self) -> Dict[str, str]:
        return {"tokenizer": self.tokenizer}


@dataclass
class TransformersModelCardData(TransformersModelCardDataBase):
    framework: Framework = Framework("transformers")
    task_type: Literal["for_text_classification", "for_question_answering"]

    def _trainer_task_call(self) -> str:
        task_call = ""
        if formatting_func := self.task.formatting_func:
            from inspect import getsource

            task_call += getsource(formatting_func) + "\n"
            training_task_args = "formatting_func=formatting_func"
        else:
            if self.task_type == "for_text_classification":
                training_task_args = (
                    f'text=dataset.field_by_name("{self.task.text.name}"), '
                    f'label=dataset.question_by_name("{self.task.label.question.name}")'
                )
            elif self.task_type == "for_question_answering":
                training_task_args = (
                    f'question=dataset.field_by_name("{self.task.question.name}"), '
                    f'context=dataset.field_by_name("{self.task.context.name}"), '
                    f'answer=dataset.question_by_name("{self.task.answer.name}")'
                )
            else:
                raise NotImplementedError(f"Transformer doesn't have this `task_type` implemented: `{self.task_type}`")

        return task_call + TEMPLATE_TASK_CALL.format(task_type=self.task_type, training_task_args=training_task_args)


@dataclass
class SetFitModelCardData(TransformersModelCardDataBase):
    framework: Framework = Framework("setfit")


@dataclass
class SpanMarkerModelCardData(TransformersModelCardDataBase):
    framework: Framework = Framework("span_marker")
    tags: Optional[List[str]] = field(
        default_factory=lambda: [
            "span-marker",
            "token-classification",
            "ner",
            "named-entity-recognition",
        ]
    )


@dataclass
class PeftModelCardData(TransformersModelCardDataBase):
    framework: Framework = Framework("peft")


@dataclass
class OpenAIModelCardData(FrameworkCardData):
    framework: Framework = Framework("openai")
    task_type: str = "for_chat_completion"

    def _trainer_task_call(self) -> str:
        return _formatting_func_call(self.task.formatting_func, self.task_type)


@dataclass
class TRLModelCardData(FrameworkCardData):
    framework: Framework = Framework("trl")
    task_type: Literal[
        "for_supervised_fine_tuning",
        "for_reward_modeling",
        "for_proximal_policy_optimization",
        "for_direct_preference_optimization",
    ]

    def _trainer_task_call(self) -> str:
        return _formatting_func_call(self.task.formatting_func, self.task_type)


@dataclass
class SentenceTransformerCardData(FrameworkCardData):
    framework: Framework = Framework("sentence-transformers")
    task_type: TaskTypes = "for_sentence_similarity"
    tags: Optional[List[str]] = field(
        default_factory=lambda: ["sentence-similarity", "sentence-transformers", "argilla"]
    )
    cross_encoder: bool = False

    def _trainer_task_call(self) -> str:
        task_call = ""
        if formatting_func := self.task.formatting_func:
            from inspect import getsource

            task_call += getsource(formatting_func) + "\n"
            training_task_args = "formatting_func=formatting_func"
        else:
            texts = ", ".join([f'dataset.field_by_name("{text.name}")' for text in self.task.texts])
            training_task_args = f"texts=[{texts}]{f', label=dataset.question_by_name({self.task.label.question.name})' if self.task.label else ''}"
        return task_call + TEMPLATE_TASK_CALL.format(task_type=self.task_type, training_task_args=training_task_args)

    def _to_dict(self) -> Dict[str, str]:
        if cross_encoder := self.cross_encoder:
            return {"cross_encoder": cross_encoder}
        else:
            return {}


def _formatting_func_call(formatting_func: Callable, task_type: TaskTypes) -> str:
    """Helper function to extract the code for the task call.

    Args:
        formatting_func: Function used to prepare the dataset for training.
        task_type: Method called to prepare the dataset for training.

    Returns:
        formatting_func_call
    """
    from inspect import getsource

    task_call = getsource(formatting_func) + "\n"
    training_task_args = "formatting_func=formatting_func"
    return task_call + TEMPLATE_TASK_CALL.format(task_type=task_type, training_task_args=training_task_args)
