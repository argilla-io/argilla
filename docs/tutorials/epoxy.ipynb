{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e548eacd",
   "metadata": {},
   "source": [
    "# FlyingSquid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b475019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c973973a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alessandro leite</td>\n",
       "      <td>2014-11-05T22:21:36</td>\n",
       "      <td>pls http://www10.vakinha.com.br/VaquinhaE.aspx...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Salim Tayara</td>\n",
       "      <td>2014-11-02T14:33:30</td>\n",
       "      <td>if your like drones, plz subscribe to Kamal Ta...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Phuc Ly</td>\n",
       "      <td>2014-01-20T15:27:47</td>\n",
       "      <td>go here to check the views :3﻿</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DropShotSk8r</td>\n",
       "      <td>2014-01-19T04:27:18</td>\n",
       "      <td>Came here to check the views, goodbye.﻿</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>css403</td>\n",
       "      <td>2014-11-07T14:25:48</td>\n",
       "      <td>i am 2,126,492,636 viewer :D﻿</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            author                 date  \\\n",
       "0           0  Alessandro leite  2014-11-05T22:21:36   \n",
       "1           1      Salim Tayara  2014-11-02T14:33:30   \n",
       "2           2           Phuc Ly  2014-01-20T15:27:47   \n",
       "3           3      DropShotSk8r  2014-01-19T04:27:18   \n",
       "4           4            css403  2014-11-07T14:25:48   \n",
       "\n",
       "                                                text  label  video  \n",
       "0  pls http://www10.vakinha.com.br/VaquinhaE.aspx...   -1.0      1  \n",
       "1  if your like drones, plz subscribe to Kamal Ta...   -1.0      1  \n",
       "2                     go here to check the views :3﻿   -1.0      1  \n",
       "3            Came here to check the views, goodbye.﻿   -1.0      1  \n",
       "4                      i am 2,126,492,636 viewer :D﻿   -1.0      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load data\n",
    "train_df = pd.read_csv('../tutorials/data/yt_comments_train.csv')\n",
    "tmp_df = pd.read_csv('../tutorials/data/yt_comments_test.csv')\n",
    "dev_df, test_df = train_test_split(tmp_df, test_size=0.5)\n",
    "\n",
    "# preview data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fe2ed99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ef66abd3ca4d199e1a9eb3551f6735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1711 records logged to http://localhost:6900/ws/rubrix/weak_supervision_yt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='weak_supervision_yt', processed=1711, failed=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "# build records from the train dataset\n",
    "records = [\n",
    "    rb.TextClassificationRecord(\n",
    "        inputs=row.text,\n",
    "        metadata={\"video\":row.video, \"author\": row.author}\n",
    "    )\n",
    "    for i,row in train_df.iterrows()\n",
    "]\n",
    "\n",
    "# build records from the test dataset with annotation\n",
    "labels = [\"HAM\", \"SPAM\"]\n",
    "records += [\n",
    "    rb.TextClassificationRecord(\n",
    "        inputs=row.text,\n",
    "        annotation=labels[row.label],\n",
    "        metadata={\"video\":row.video, \"author\": row.author}\n",
    "    )\n",
    "    for i,row in dev_df.iterrows()\n",
    "]\n",
    "\n",
    "# log records to Rubrix\n",
    "rb.log(records, name=\"weak_supervision_yt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafae505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/jose/backends/cryptography_backend.py:18: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes, int_to_bytes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a756f0aa61a40b7b96c34ab264c6e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing rules:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd243e6f40e047ef9460126f0d38eb2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying rules:   0%|          | 0/1711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/rubrix/lib/python3.8/site-packages/pgmpy/models/MarkovModel.py:8: FutureWarning: MarkovModel has been renamed to MarkovNetwork. Please use MarkovNetwork class, MarkovModel will be removed in future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.864,\n",
       " 'micro_precision': 0.864,\n",
       " 'micro_recall': 0.864,\n",
       " 'micro_f1': 0.864,\n",
       " 'macro_precision': 0.8635432667690732,\n",
       " 'macro_recall': 0.8688311688311688,\n",
       " 'macro_f1': 0.8634406529143371,\n",
       " 'precision_SPAM': 0.9206349206349206,\n",
       " 'recall_SPAM': 0.8285714285714286,\n",
       " 'f1_SPAM': 0.8721804511278196,\n",
       " 'support_SPAM': 70,\n",
       " 'precision_HAM': 0.8064516129032258,\n",
       " 'recall_HAM': 0.9090909090909091,\n",
       " 'f1_HAM': 0.8547008547008547,\n",
       " 'support_HAM': 55}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rubrix.labeling.text_classification import Rule, WeakLabels\n",
    "import rubrix as rb\n",
    "\n",
    "#  rules defined as Elasticsearch queries\n",
    "check_out = Rule(query=\"check out\", label=\"SPAM\")\n",
    "plz = Rule(query=\"plz OR please\", label=\"SPAM\")\n",
    "subscribe = Rule(query=\"subscribe\", label=\"SPAM\")\n",
    "my = Rule(query=\"my\", label=\"SPAM\")\n",
    "song = Rule(query=\"song\", label=\"HAM\")\n",
    "love = Rule(query=\"love\", label=\"HAM\")\n",
    "\n",
    "import re\n",
    "\n",
    "# rules defined as Python labeling functions\n",
    "def contains_http(record: rb.TextClassificationRecord):\n",
    "    if \"http\" in record.inputs[\"text\"]:\n",
    "        return \"SPAM\"\n",
    "\n",
    "def short_comment(record: rb.TextClassificationRecord):\n",
    "    return \"HAM\" if len(record.inputs[\"text\"].split()) < 5 else None\n",
    "\n",
    "def regex_check_out(record: rb.TextClassificationRecord):\n",
    "    return \"SPAM\" if re.search(r\"check.*out\", record.inputs[\"text\"], flags=re.I) else None\n",
    "\n",
    "from rubrix.labeling.text_classification import load_rules\n",
    "\n",
    "# bundle our rules in a list\n",
    "rules = [check_out, plz, subscribe, my, song, love, contains_http, short_comment, regex_check_out]\n",
    "\n",
    "# optionally add the rules defined in the web app UI\n",
    "rules += load_rules(dataset=\"weak_supervision_yt\")\n",
    "\n",
    "# apply the rules to a dataset to obtain the weak labels\n",
    "weak_labels = WeakLabels(\n",
    "    rules=rules,\n",
    "    dataset=\"weak_supervision_yt\"\n",
    ")\n",
    "\n",
    "from rubrix.labeling.text_classification import FlyingSquid\n",
    "\n",
    "# we pass our WeakLabels instance to our FlyingSquid label model\n",
    "flyingsquid_model = FlyingSquid(weak_labels)\n",
    "\n",
    "# we fit the model\n",
    "flyingsquid_model.fit()\n",
    "\n",
    "flyingsquid_model.score(tie_break_policy=\"random\")\n",
    "# {'accuracy': 0.832, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90381e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb540c06efcf462ab816ee60bc93f7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177 records logged to http://localhost:6900/ws/rubrix/flyingsquid_results\n"
     ]
    }
   ],
   "source": [
    "# get your training records with the predictions of the label model\n",
    "records_for_training = flyingsquid_model.predict()\n",
    "\n",
    "# log the records to a new dataset in Rubrix\n",
    "rb.log(records_for_training, name=\"flyingsquid_results\")\n",
    "\n",
    "# extract training data\n",
    "training_data = pd.DataFrame(\n",
    "    [\n",
    "        {\"text\": rec.inputs[\"text\"], \"label\": flyingsquid_model.weak_labels.label2int[rec.prediction[0][0]]}\n",
    "        for rec in records_for_training\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a17ce8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EVERYONE PLEASE SUBSCRIBE TO MY CHANNEL OR CAN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;a rel=\"nofollow\" class=\"ot-hashtag\" href=\"htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PARTY ROCK (8) ~﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This song is true because it is insane because...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://binbox.io/DNCkM#qT4Q1JB1﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>Maybe no one will probably read this. But just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>Check out this video on YouTube&lt;br /&gt;&lt;br /&gt;&lt;br...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>Lol check out my chanell and subscribe please ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>https://www.facebook.com/eeccon/posts/73394924...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>Perfect! &amp;lt;3﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1177 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     EVERYONE PLEASE SUBSCRIBE TO MY CHANNEL OR CAN...      0\n",
       "1     <a rel=\"nofollow\" class=\"ot-hashtag\" href=\"htt...      1\n",
       "2                                     PARTY ROCK (8) ~﻿      1\n",
       "3     This song is true because it is insane because...      1\n",
       "4                     https://binbox.io/DNCkM#qT4Q1JB1﻿      0\n",
       "...                                                 ...    ...\n",
       "1172  Maybe no one will probably read this. But just...      0\n",
       "1173  Check out this video on YouTube<br /><br /><br...      0\n",
       "1174  Lol check out my chanell and subscribe please ...      0\n",
       "1175  https://www.facebook.com/eeccon/posts/73394924...      0\n",
       "1176                                    Perfect! &lt;3﻿      1\n",
       "\n",
       "[1177 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview training data\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88e75c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# define our final classifier\n",
    "classifier = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# fit the classifier\n",
    "classifier.fit(\n",
    "    X=training_data.text.tolist(),\n",
    "    y=training_data.label.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa7294c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.16\n"
     ]
    }
   ],
   "source": [
    "# compute the test accuracy\n",
    "accuracy = classifier.score(\n",
    "    X=test_df.text.tolist(),\n",
    "    y=test_df.label.tolist()\n",
    ")\n",
    "\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad5d16",
   "metadata": {},
   "source": [
    "# Epoxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94408422",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'WeakLabelsEmbeddings' from 'rubrix.labeling.text_classification' (/mnt/d/Recognai/rubrix/src/rubrix/labeling/text_classification/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-aebd31bb3dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrubrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWeakLabelsEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSentenceTransformerModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'WeakLabelsEmbeddings' from 'rubrix.labeling.text_classification' (/mnt/d/Recognai/rubrix/src/rubrix/labeling/text_classification/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from rubrix.labeling.text_classification import WeakLabelsEmbeddings\n",
    "\n",
    "class SentenceTransformerModel(object):\n",
    "    \n",
    "    def __init__(self, embedding_model_name):\n",
    "        self.embedding_model = SentenceTransformer(embedding_model_name)\n",
    "    \n",
    "    def __call__(self, records):\n",
    "        texts = [ x.inputs[\"text\"] for x in records ]\n",
    "        embeddings = self.embedding_model.encode(texts)\n",
    "        return embeddings\n",
    "\n",
    "sentence_transformer_model = SentenceTransformerModel('average_word_embeddings_glove.840B.300d')\n",
    "\n",
    "weak_labels = WeakLabelsEmbeddings(\n",
    "    rules=rules,\n",
    "    dataset=\"weak_supervision_yt\",\n",
    "    embedding_func=sentence_transformer_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8b13f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubrix.labeling.text_classification import Epoxy\n",
    "thresholds = [1.0] * weak_labels.matrix().shape[0]\n",
    "epoxy_instance = Epoxy(weak_labels, thresholds=thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "pdb.run(\"epoxy_instance.fit()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c73f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoxy_instance.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a19c500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rubrix",
   "language": "python",
   "name": "rubrix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
