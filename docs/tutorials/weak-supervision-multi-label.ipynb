{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7641399c-d8bc-411b-952b-32a9f2100776",
   "metadata": {},
   "source": [
    "# Weak supervision in multi-label text classification tasks\n",
    "\n",
    "WORK IN PROGRESS: This tutorial is a work in progress and you can expect some changes within the next few releases.\n",
    "We will showcase new features here as soon as they are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2fec7-ded9-4752-be5d-d365ebe6c039",
   "metadata": {},
   "source": [
    "In this tutorial we will tackle two text classification tasks that deal with multi-labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c0bbe-904a-49de-9443-234252f0acb0",
   "metadata": {},
   "source": [
    "## go emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83559db4-9bc1-4080-bccb-cc154ed753ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Download preprocessed dataset\n",
    "ds_rb = rb.read_datasets(\n",
    "    load_dataset(\"rubrix/go_emotions_multi-label\", split=\"train\", use_auth_token=True),\n",
    "    task=\"TextClassification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c11e9e-9dec-424e-a582-795803e0a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log dataset to Rubrix to find good heuristics\n",
    "rb.log(ds_rb, name=\"go_emotions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c90591ef-bedb-4069-b491-bd9d7f58edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubrix.labeling.text_classification import Rule\n",
    "\n",
    "# Define our heuristic rules (can probably be improved)\n",
    "rules = [\n",
    "    Rule(\"thank*\", \"gratitude\"),\n",
    "    Rule(\"appreciate\", \"gratitude\"),\n",
    "    Rule(\"text:(thanks AND good)\", [\"admiration\", \"gratitude\"]),\n",
    "    Rule(\"advice\", \"admiration\"),\n",
    "    Rule(\"amazing\", \"admiration\"),\n",
    "    Rule(\"awesome\", \"admiration\"),\n",
    "    Rule(\"impressed\", \"admiration\"),\n",
    "    Rule(\"text:(good AND (point OR call OR idea OR job))\", \"admiration\"),\n",
    "    Rule(\"legend\", \"admiration\"),\n",
    "    Rule(\"exactly\", \"approval\"),\n",
    "    Rule(\"agree\", \"approval\"),\n",
    "    Rule(\"yeah\", \"approval\"),\n",
    "    Rule(\"suck\", \"annoyance\"),\n",
    "    Rule(\"pissed\", \"annoyance\"),\n",
    "    Rule(\"annoying\", \"annoyance\"),\n",
    "    Rule(\"ruined\", \"annoyance\"),\n",
    "    Rule(\"hoping\", \"optimism\"),\n",
    "    Rule(\"text:(\\\"good luck\\\")\", \"optimism\"),\n",
    "    Rule(\"\\\"nice day\\\"\", \"optimism\"),\n",
    "    Rule(\"\\\"what is\\\"\", \"curiosity\"),\n",
    "    Rule(\"\\\"can you\\\"\", \"curiosity\"),\n",
    "    Rule(\"\\\"would you\\\"\", \"curiosity\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de1f67bb-8666-4fd9-a293-f0e6a1168f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b9b3058a434f9793065bf1059f607d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing rules:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c99a7d89304768b241ff6f20ee39f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying rules:   0%|          | 0/4208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbc69a9302f42da9f45c6d84dcd2af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filling weak label matrix:   0%|          | 0/4208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rubrix.labeling.text_classification import WeakMultiLabels\n",
    "\n",
    "# Compute the weak labels for our dataset given the rules\n",
    "weak_labels = WeakMultiLabels(\"go_emotions\", rules=rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdc6fea9-f248-4f55-a542-a0296f2873f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>coverage</th>\n",
       "      <th>annotated_coverage</th>\n",
       "      <th>overlaps</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>thank*</th>\n",
       "      <td>{gratitude}</td>\n",
       "      <td>0.196768</td>\n",
       "      <td>0.196237</td>\n",
       "      <td>0.037785</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appreciate</th>\n",
       "      <td>{gratitude}</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text:(thanks AND good)</th>\n",
       "      <td>{admiration, gratitude}</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advice</th>\n",
       "      <td>{admiration}</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>{admiration}</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>{admiration}</td>\n",
       "      <td>0.025190</td>\n",
       "      <td>0.034946</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impressed</th>\n",
       "      <td>{admiration}</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text:(good AND (point OR call OR idea OR job))</th>\n",
       "      <td>{admiration}</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.018817</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legend</th>\n",
       "      <td>{admiration}</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exactly</th>\n",
       "      <td>{approval}</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agree</th>\n",
       "      <td>{approval}</td>\n",
       "      <td>0.016873</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeah</th>\n",
       "      <td>{approval}</td>\n",
       "      <td>0.024952</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suck</th>\n",
       "      <td>{annoyance}</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pissed</th>\n",
       "      <td>{annoyance}</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoying</th>\n",
       "      <td>{annoyance}</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.018817</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruined</th>\n",
       "      <td>{annoyance}</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoping</th>\n",
       "      <td>{optimism}</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text:(\"good luck\")</th>\n",
       "      <td>{optimism}</td>\n",
       "      <td>0.015209</td>\n",
       "      <td>0.018817</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"nice day\"</th>\n",
       "      <td>{optimism}</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"what is\"</th>\n",
       "      <td>{curiosity}</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"can you\"</th>\n",
       "      <td>{curiosity}</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"would you\"</th>\n",
       "      <td>{curiosity}</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>{curiosity, annoyance, admiration, approval, o...</td>\n",
       "      <td>0.327234</td>\n",
       "      <td>0.384409</td>\n",
       "      <td>0.041825</td>\n",
       "      <td>161</td>\n",
       "      <td>11</td>\n",
       "      <td>0.936047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            label  \\\n",
       "thank*                                                                                {gratitude}   \n",
       "appreciate                                                                            {gratitude}   \n",
       "text:(thanks AND good)                                                    {admiration, gratitude}   \n",
       "advice                                                                               {admiration}   \n",
       "amazing                                                                              {admiration}   \n",
       "awesome                                                                              {admiration}   \n",
       "impressed                                                                            {admiration}   \n",
       "text:(good AND (point OR call OR idea OR job))                                       {admiration}   \n",
       "legend                                                                               {admiration}   \n",
       "exactly                                                                                {approval}   \n",
       "agree                                                                                  {approval}   \n",
       "yeah                                                                                   {approval}   \n",
       "suck                                                                                  {annoyance}   \n",
       "pissed                                                                                {annoyance}   \n",
       "annoying                                                                              {annoyance}   \n",
       "ruined                                                                                {annoyance}   \n",
       "hoping                                                                                 {optimism}   \n",
       "text:(\"good luck\")                                                                     {optimism}   \n",
       "\"nice day\"                                                                             {optimism}   \n",
       "\"what is\"                                                                             {curiosity}   \n",
       "\"can you\"                                                                             {curiosity}   \n",
       "\"would you\"                                                                           {curiosity}   \n",
       "total                                           {curiosity, annoyance, admiration, approval, o...   \n",
       "\n",
       "                                                coverage  annotated_coverage  \\\n",
       "thank*                                          0.196768            0.196237   \n",
       "appreciate                                      0.016160            0.021505   \n",
       "text:(thanks AND good)                          0.007842            0.010753   \n",
       "advice                                          0.008317            0.008065   \n",
       "amazing                                         0.025428            0.021505   \n",
       "awesome                                         0.025190            0.034946   \n",
       "impressed                                       0.002139            0.005376   \n",
       "text:(good AND (point OR call OR idea OR job))  0.008555            0.018817   \n",
       "legend                                          0.001901            0.002688   \n",
       "exactly                                         0.004278            0.002688   \n",
       "agree                                           0.016873            0.021505   \n",
       "yeah                                            0.024952            0.021505   \n",
       "suck                                            0.002139            0.008065   \n",
       "pissed                                          0.002139            0.008065   \n",
       "annoying                                        0.003327            0.018817   \n",
       "ruined                                          0.000713            0.002688   \n",
       "hoping                                          0.003565            0.005376   \n",
       "text:(\"good luck\")                              0.015209            0.018817   \n",
       "\"nice day\"                                      0.000713            0.005376   \n",
       "\"what is\"                                       0.004040            0.005376   \n",
       "\"can you\"                                       0.004278            0.008065   \n",
       "\"would you\"                                     0.000951            0.005376   \n",
       "total                                           0.327234            0.384409   \n",
       "\n",
       "                                                overlaps  correct  incorrect  \\\n",
       "thank*                                          0.037785       73          0   \n",
       "appreciate                                      0.009506        7          1   \n",
       "text:(thanks AND good)                          0.007605        8          0   \n",
       "advice                                          0.006654        3          0   \n",
       "amazing                                         0.003565        8          0   \n",
       "awesome                                         0.006179       12          1   \n",
       "impressed                                       0.000000        2          0   \n",
       "text:(good AND (point OR call OR idea OR job))  0.002376        7          0   \n",
       "legend                                          0.000475        1          0   \n",
       "exactly                                         0.001188        1          0   \n",
       "agree                                           0.003089        6          2   \n",
       "yeah                                            0.004990        5          3   \n",
       "suck                                            0.000475        3          0   \n",
       "pissed                                          0.000475        2          1   \n",
       "annoying                                        0.000951        7          0   \n",
       "ruined                                          0.000238        1          0   \n",
       "hoping                                          0.000713        2          0   \n",
       "text:(\"good luck\")                              0.002139        4          3   \n",
       "\"nice day\"                                      0.000000        2          0   \n",
       "\"what is\"                                       0.000951        2          0   \n",
       "\"can you\"                                       0.000713        3          0   \n",
       "\"would you\"                                     0.000000        2          0   \n",
       "total                                           0.041825      161         11   \n",
       "\n",
       "                                                precision  \n",
       "thank*                                           1.000000  \n",
       "appreciate                                       0.875000  \n",
       "text:(thanks AND good)                           1.000000  \n",
       "advice                                           1.000000  \n",
       "amazing                                          1.000000  \n",
       "awesome                                          0.923077  \n",
       "impressed                                        1.000000  \n",
       "text:(good AND (point OR call OR idea OR job))   1.000000  \n",
       "legend                                           1.000000  \n",
       "exactly                                          1.000000  \n",
       "agree                                            0.750000  \n",
       "yeah                                             0.625000  \n",
       "suck                                             1.000000  \n",
       "pissed                                           0.666667  \n",
       "annoying                                         1.000000  \n",
       "ruined                                           1.000000  \n",
       "hoping                                           1.000000  \n",
       "text:(\"good luck\")                               0.571429  \n",
       "\"nice day\"                                       1.000000  \n",
       "\"what is\"                                        1.000000  \n",
       "\"can you\"                                        1.000000  \n",
       "\"would you\"                                      1.000000  \n",
       "total                                            0.936047  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check coverage/precision of our rules\n",
    "weak_labels.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6985e6b7-7c28-4efc-84d2-08b7fff02ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubrix.labeling.text_classification import MajorityVoter\n",
    "\n",
    "# Use the majority voter as the label model\n",
    "label_model = MajorityVoter(weak_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "152abc10-1538-4660-aa3a-0e210887c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get records with the predictions from the label model to train a down-stream model\n",
    "train_rb = rb.DatasetForTextClassification(label_model.predict())\n",
    "\n",
    "# Copy label model predictions to annotation\n",
    "for rec in train_rb:\n",
    "    rec.annotation = [pred[0] for pred in rec.prediction if pred[1] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fce0c5a0-bfa5-4649-a59a-f0114f7891a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get records with manual annotations to use as test set for the down-stream model\n",
    "test_rb = rb.DatasetForTextClassification(weak_labels.records(has_annotation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "232a2d46-1516-4c7d-8d39-d55fe0d8130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Create dataset dictionary and shuffle training set\n",
    "ds = DatasetDict(\n",
    "    train=train_rb.prepare_for_training().shuffle(seed=42),\n",
    "    test=test_rb.prepare_for_training()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072218ae-2167-48d8-8b93-243daff497b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push dataset for training our down-stream model to the HF hub\n",
    "ds.push_to_hub(\"rubrix/go_emotions_training\", private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0957ad2-f05d-4ea4-b303-d77495a449e9",
   "metadata": {},
   "source": [
    "### Train transformers down-stream model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88365498-15df-4aff-ae3a-48c22e4e1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6635d069-e242-4d89-92be-ecce502b92db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23f052f685c4c7b88ae627b30e3c3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48552906ee5e499f8d9fc330c13eb6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_func(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize the data\n",
    "tokenized_ds = ds.map(tokenize_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5d04aa2-560d-450d-8242-db5ea4a44844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25301609aa924a49bbe92ed8cb481315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5022b7f93285445ba0aaf90cd696a6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def binarize_labels(examples):\n",
    "    return {\"label\": [\n",
    "        [int(i in labels) for i in range(len(ds[\"test\"].features[\"label\"][0].names))] \n",
    "        for labels in examples[\"label\"]\n",
    "    ]}\n",
    "\n",
    "# Turn labels into multi-label format\n",
    "binarized_tokenized_ds = tokenized_ds.map(binarize_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9ee91-82f0-4cb1-a1b6-10369804e22a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Init our down-stream model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    problem_type=\"multi_label_classification\", \n",
    "    num_labels=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2dd0c0bd-b7d9-4e1c-a734-8c2a8e9d57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# Set our training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\", \n",
    "    evaluation_strategy=\"epoch\", \n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,   \n",
    "    per_device_eval_batch_size=16, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d50f9ae8-2b1a-4905-b19f-62bcfa8c64d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "# Define our metrics\n",
    "metric = load_metric(\"f1\", config_name=\"multilabel\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = ( 1. / (1 + np.exp(-logits)) ) > 0.5\n",
    "    \n",
    "    metrics = metric.compute(predictions=predictions, references=labels, average=\"micro\")\n",
    "    per_label_metric = metric.compute(predictions=predictions, references=labels, average=None)\n",
    "    for label, f1 in zip(ds[\"train\"].features[\"label\"][0].names, per_label_metric[\"f1\"]):\n",
    "        metrics[f\"f1_{label}\"] = f1\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "61e0896c-dc7b-4844-95b6-a258aa8f8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# Init the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=binarized_tokenized_ds[\"train\"],\n",
    "    eval_dataset=binarized_tokenized_ds[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd25cb-1cf8-4721-a8e8-c16eb0c7aaf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the down-stream model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0dfbaa-90f3-4803-8e93-b86e1440bd51",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Research topic dataset\n",
    "\n",
    "See Appendix B for the data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4cdd38-604c-4fe6-8104-fc6b136d331a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 00:17:22.386 | WARNING  | datasets.builder:_create_builder_config:378 - Using custom data configuration rubrix--go_emotions_multi_label-c52a16149c24284f\n",
      "2022-03-16 00:17:22.392 | WARNING  | datasets.builder:download_and_prepare:531 - Reusing dataset parquet (/home/david/.cache/huggingface/datasets/parquet/rubrix--go_emotions_multi_label-c52a16149c24284f/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Download preprocessed dataset\n",
    "ds_rb = rb.read_datasets(\n",
    "    load_dataset(\"rubrix/go_emotions_multi_label\", split=\"train\", use_auth_token=True),\n",
    "    task=\"TextClassification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "34899478-62ae-4864-8196-36348aa568c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4626453ea0af4a2cb96b91add2bfcbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20972 records logged to http://localhost:6900/ws/rubrix/research_titles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='research_titles', processed=20972, failed=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log dataset to Rubrix to find good heuristics\n",
    "rb.log(records, \"research_titles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f85fd20-7086-4581-9078-2a28c9155997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubrix.labeling.text_classification import Rule\n",
    "\n",
    "# Define our heuristic rules (can probably be improved)\n",
    "rules = [\n",
    "    Rule(\"stock*\", \"Quantitative Finance\"),\n",
    "    Rule(\"*asset*\", \"Quantitative Finance\"),\n",
    "    Rule(\"trading\", \"Quantitative Finance\"),\n",
    "    Rule(\"finance\", \"Quantitative Finance\"),\n",
    "    Rule(\"pric*\", \"Quantitative Finance\"),\n",
    "    Rule(\"economy\", \"Quantitative Finance\"),\n",
    "    Rule(\"deep AND neural AND network*\", \"Computer Science\"),\n",
    "    Rule(\"convolutional\", \"Computer Science\"),\n",
    "    Rule(\"memor* AND (design* OR network*)\", \"Computer Science\"),\n",
    "    Rule(\"system* AND design*\", \"Computer Science\"),\n",
    "    Rule(\"allocat* AND *net*\", \"Computer Science\"),\n",
    "    Rule(\"program\", \"Computer Science\"),\n",
    "    Rule(\"scattering\", \"Physics\"),\n",
    "    Rule(\"astro*\", \"Physics\"),\n",
    "    Rule(\"material*\", \"Physics\"),\n",
    "    Rule(\"spin\", \"Physics\"),\n",
    "    Rule(\"magnetic\", \"Physics\"),\n",
    "    Rule(\"optical\", \"Physics\"),\n",
    "    Rule(\"ray\", \"Physics\"),\n",
    "    Rule(\"entangle*\", \"Physics\"),\n",
    "    Rule(\"*algebra*\", \"Mathematics\"),\n",
    "    Rule(\"manifold* AND (NOT learn*)\", \"Mathematics\"),\n",
    "    Rule(\"equation\", \"Mathematics\"),\n",
    "    Rule(\"spaces\", \"Mathematics\"), \n",
    "    Rule(\"operators\", \"Mathematics\"), \n",
    "    Rule(\"regression\", \"Statistics\"),\n",
    "    Rule(\"bayes*\", \"Statistics\"),\n",
    "    Rule(\"estimation\", \"Statistics\"),\n",
    "    Rule(\"mixture\", \"Statistics\"),\n",
    "    Rule(\"gaussian\", \"Statistics\"),\n",
    "    Rule(\"gene\", \"Quantitative Biology\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41d2c90-e550-4d44-9935-b5eeea415c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 00:17:31.646 | WARNING  | rubrix.client.api:load:366 - The argument 'as_pandas' in `rb.load` will be deprecated in the future, and we will always return a `Dataset`. To emulate the future behavior set `as_pandas=False`. To get a pandas DataFrame, call `Dataset.to_pandas()`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ae298816df4df3b8700a32b8135265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing rules:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5356b5e04645a89c180c89ec0e61ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying rules:   0%|          | 0/20972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830b4f9c1c0747dfbe2e9ec021267267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filling weak label matrix:   0%|          | 0/20972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rubrix.labeling.text_classification import WeakMultiLabels\n",
    "\n",
    "# Compute the weak labels for our dataset given the rules\n",
    "weak_labels = WeakMultiLabels(\"research_titles\", rules=rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5bfc002-0845-4d36-b2c5-8133995561ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>coverage</th>\n",
       "      <th>annotated_coverage</th>\n",
       "      <th>overlaps</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stock*</th>\n",
       "      <td>{Quantitative Finance}</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*asset*</th>\n",
       "      <td>{Quantitative Finance}</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trading</th>\n",
       "      <td>{Quantitative Finance}</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finance</th>\n",
       "      <td>{Quantitative Finance}</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pric*</th>\n",
       "      <td>{Quantitative Finance}</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>{Quantitative Finance}</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep AND neural AND network*</th>\n",
       "      <td>{Computer Science}</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>0.744186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convolutional</th>\n",
       "      <td>{Computer Science}</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.009297</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memor* AND (design* OR network*)</th>\n",
       "      <td>{Computer Science}</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system* AND design*</th>\n",
       "      <td>{Computer Science}</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allocat* AND *net*</th>\n",
       "      <td>{Computer Science}</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program</th>\n",
       "      <td>{Computer Science}</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scattering</th>\n",
       "      <td>{Physics}</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astro*</th>\n",
       "      <td>{Physics}</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material*</th>\n",
       "      <td>{Physics}</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spin</th>\n",
       "      <td>{Physics}</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.015018</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magnetic</th>\n",
       "      <td>{Physics}</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>0.907407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optical</th>\n",
       "      <td>{Physics}</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>0.006913</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ray</th>\n",
       "      <td>{Physics}</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entangle*</th>\n",
       "      <td>{Physics}</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*algebra*</th>\n",
       "      <td>{Mathematics}</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manifold* AND (NOT learn*)</th>\n",
       "      <td>{Mathematics}</td>\n",
       "      <td>0.007057</td>\n",
       "      <td>0.008343</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equation</th>\n",
       "      <td>{Mathematics}</td>\n",
       "      <td>0.010681</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spaces</th>\n",
       "      <td>{Mathematics}</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>0.926829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operators</th>\n",
       "      <td>{Mathematics}</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression</th>\n",
       "      <td>{Statistics}</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bayes*</th>\n",
       "      <td>{Statistics}</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>49</td>\n",
       "      <td>13</td>\n",
       "      <td>0.790323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estimation</th>\n",
       "      <td>{Statistics}</td>\n",
       "      <td>0.021266</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "      <td>0.730337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture</th>\n",
       "      <td>{Statistics}</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaussian</th>\n",
       "      <td>{Statistics}</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene</th>\n",
       "      <td>{Quantitative Biology}</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>{Quantitative Biology, Computer Science, Stati...</td>\n",
       "      <td>0.174614</td>\n",
       "      <td>0.183075</td>\n",
       "      <td>0.016737</td>\n",
       "      <td>706</td>\n",
       "      <td>132</td>\n",
       "      <td>0.842482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              label  \\\n",
       "stock*                                                       {Quantitative Finance}   \n",
       "*asset*                                                      {Quantitative Finance}   \n",
       "trading                                                      {Quantitative Finance}   \n",
       "finance                                                      {Quantitative Finance}   \n",
       "pric*                                                        {Quantitative Finance}   \n",
       "economy                                                      {Quantitative Finance}   \n",
       "deep AND neural AND network*                                     {Computer Science}   \n",
       "convolutional                                                    {Computer Science}   \n",
       "memor* AND (design* OR network*)                                 {Computer Science}   \n",
       "system* AND design*                                              {Computer Science}   \n",
       "allocat* AND *net*                                               {Computer Science}   \n",
       "program                                                          {Computer Science}   \n",
       "scattering                                                                {Physics}   \n",
       "astro*                                                                    {Physics}   \n",
       "material*                                                                 {Physics}   \n",
       "spin                                                                      {Physics}   \n",
       "magnetic                                                                  {Physics}   \n",
       "optical                                                                   {Physics}   \n",
       "ray                                                                       {Physics}   \n",
       "entangle*                                                                 {Physics}   \n",
       "*algebra*                                                             {Mathematics}   \n",
       "manifold* AND (NOT learn*)                                            {Mathematics}   \n",
       "equation                                                              {Mathematics}   \n",
       "spaces                                                                {Mathematics}   \n",
       "operators                                                             {Mathematics}   \n",
       "regression                                                             {Statistics}   \n",
       "bayes*                                                                 {Statistics}   \n",
       "estimation                                                             {Statistics}   \n",
       "mixture                                                                {Statistics}   \n",
       "gaussian                                                               {Statistics}   \n",
       "gene                                                         {Quantitative Biology}   \n",
       "total                             {Quantitative Biology, Computer Science, Stati...   \n",
       "\n",
       "                                  coverage  annotated_coverage  overlaps  \\\n",
       "stock*                            0.000954            0.000715  0.000334   \n",
       "*asset*                           0.000477            0.000715  0.000286   \n",
       "trading                           0.000954            0.000238  0.000191   \n",
       "finance                           0.000048            0.000238  0.000000   \n",
       "pric*                             0.003433            0.003337  0.000715   \n",
       "economy                           0.000238            0.000238  0.000000   \n",
       "deep AND neural AND network*      0.009155            0.010250  0.002098   \n",
       "convolutional                     0.010109            0.009297  0.002146   \n",
       "memor* AND (design* OR network*)  0.001383            0.002145  0.000286   \n",
       "system* AND design*               0.001144            0.002384  0.000238   \n",
       "allocat* AND *net*                0.000763            0.000715  0.000000   \n",
       "program                           0.002623            0.003099  0.000143   \n",
       "scattering                        0.004053            0.002861  0.001001   \n",
       "astro*                            0.003099            0.004052  0.000620   \n",
       "material*                         0.004148            0.003099  0.000238   \n",
       "spin                              0.013542            0.015018  0.002146   \n",
       "magnetic                          0.011301            0.012872  0.002432   \n",
       "optical                           0.007105            0.006913  0.001097   \n",
       "ray                               0.005865            0.007390  0.001192   \n",
       "entangle*                         0.002623            0.002861  0.000095   \n",
       "*algebra*                         0.014829            0.018355  0.000572   \n",
       "manifold* AND (NOT learn*)        0.007057            0.008343  0.000858   \n",
       "equation                          0.010681            0.007867  0.000954   \n",
       "spaces                            0.010586            0.009774  0.001812   \n",
       "operators                         0.006151            0.005959  0.001526   \n",
       "regression                        0.009393            0.009058  0.002527   \n",
       "bayes*                            0.015306            0.014779  0.003147   \n",
       "estimation                        0.021266            0.021216  0.003338   \n",
       "mixture                           0.003290            0.003099  0.001287   \n",
       "gaussian                          0.009250            0.011204  0.002766   \n",
       "gene                              0.001287            0.001669  0.000191   \n",
       "total                             0.174614            0.183075  0.016737   \n",
       "\n",
       "                                  correct  incorrect  precision  \n",
       "stock*                                  3          0   1.000000  \n",
       "*asset*                                 3          0   1.000000  \n",
       "trading                                 1          0   1.000000  \n",
       "finance                                 1          0   1.000000  \n",
       "pric*                                   9          5   0.642857  \n",
       "economy                                 1          0   1.000000  \n",
       "deep AND neural AND network*           32         11   0.744186  \n",
       "convolutional                          32          7   0.820513  \n",
       "memor* AND (design* OR network*)        9          0   1.000000  \n",
       "system* AND design*                     9          1   0.900000  \n",
       "allocat* AND *net*                      3          0   1.000000  \n",
       "program                                11          2   0.846154  \n",
       "scattering                             10          2   0.833333  \n",
       "astro*                                 17          0   1.000000  \n",
       "material*                              10          3   0.769231  \n",
       "spin                                   60          3   0.952381  \n",
       "magnetic                               49          5   0.907407  \n",
       "optical                                27          2   0.931034  \n",
       "ray                                    27          4   0.870968  \n",
       "entangle*                              11          1   0.916667  \n",
       "*algebra*                              70          7   0.909091  \n",
       "manifold* AND (NOT learn*)             28          7   0.800000  \n",
       "equation                               24          9   0.727273  \n",
       "spaces                                 38          3   0.926829  \n",
       "operators                              22          3   0.880000  \n",
       "regression                             33          5   0.868421  \n",
       "bayes*                                 49         13   0.790323  \n",
       "estimation                             65         24   0.730337  \n",
       "mixture                                10          3   0.769231  \n",
       "gaussian                               36         11   0.765957  \n",
       "gene                                    6          1   0.857143  \n",
       "total                                 706        132   0.842482  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check coverage/precision of our rules\n",
    "weak_labels.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8152fabd-969d-40b1-a4fc-956f8783ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubrix.labeling.text_classification import MajorityVoter\n",
    "\n",
    "# Use the majority voter as the label model\n",
    "label_model = MajorityVoter(weak_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7edc676-5c9a-4b21-82d6-1a820b466483",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = rb.DatasetForTextClassification(label_model.predict()).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45f92a3-b9a8-482a-9f37-52e4802790b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels in multi-label format\n",
    "train_df[\"label\"] = train_df.prediction.map(\n",
    "    lambda x: [\n",
    "        {p[0]: int(p[1] > 0.5) for p in x}[label] \n",
    "        for label in weak_labels.labels\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f2a5d4b-4d6a-4dc0-8533-287f92c745f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain, BinaryRelevance\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define our down-stream model\n",
    "classifier = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', BinaryRelevance(MultinomialNB()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "019aae12-aab3-4d9c-9695-80018541c3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                ('clf',\n",
       "                 BinaryRelevance(classifier=MultinomialNB(),\n",
       "                                 require_dense=[True, True]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fit the down-stream classifier\n",
    "classifier.fit(\n",
    "    X=train_df.text,\n",
    "    y=np.array(train_df.label.tolist()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "858f1c6e-99df-4918-803c-18647e2edd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for test set\n",
    "predictions = classifier.predict(\n",
    "    X=[rec.text for rec in weak_labels.records(has_annotation=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b12a128-a184-494d-a926-6100a9d252da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.23      0.36      1740\n",
      "           1       0.77      0.59      0.67      1141\n",
      "           2       0.88      0.66      0.75      1186\n",
      "           3       0.50      0.01      0.02       109\n",
      "           4       0.45      0.11      0.18        45\n",
      "           5       0.55      0.67      0.60      1069\n",
      "\n",
      "   micro avg       0.72      0.49      0.58      5290\n",
      "   macro avg       0.66      0.38      0.43      5290\n",
      "weighted avg       0.75      0.49      0.56      5290\n",
      " samples avg       0.58      0.52      0.53      5290\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/rubrix/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(weak_labels.annotation(), predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c082b-38c7-4f3a-94a7-ab0cdbc5acbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## APPENDIX A\n",
    "\n",
    "We want to limit the labels, and down-sample single-label annotations to move the focus to multi-label outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16336e27-c99c-4a51-b81b-bc63fb26daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf227957-7eb6-4ac5-b9d5-f3c671865377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f48b2d858e46189ff8510524a2b71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436b97fc180a428fbc53cb24ab91943a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 23:59:34.112 | WARNING  | datasets.builder:_create_builder_config:333 - No config specified, defaulting to: go_emotions/simplified\n",
      "2022-03-15 23:59:34.120 | WARNING  | datasets.builder:download_and_prepare:531 - Reusing dataset go_emotions (/home/david/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b8c2fb279545aa8f904ef054361fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "go_emotions = datasets.load_dataset(\"go_emotions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "814047aa-d1df-4da4-9f68-2562f08bf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = go_emotions[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6444063b-2bb7-4653-9dfe-eb57306bc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2str(i):\n",
    "    #return int(i)\n",
    "    return go_emotions[\"train\"].features[\"labels\"].feature.int2str(int(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a75bfea6-cc9e-4d29-b091-b8cd9459069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_freq = []\n",
    "\n",
    "idx_multi = df.labels.map(lambda x: len(x) > 1)\n",
    "df[\"is_single\"] = df.labels.map(lambda x: 0 if len(x) > 1 else 1) \n",
    "df[idx_multi].labels.map(lambda x: [label_freq.append(int(l)) for l in x])\n",
    "pd.Series(label_freq).value_counts();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31b129f2-b92c-4ac7-a2aa-e6601dc9404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(split: str) -> pd.DataFrame:\n",
    "    df = go_emotions[split].to_pandas()\n",
    "    df[\"is_single\"] = df.labels.map(lambda x: 0 if len(x) > 1 else 1)\n",
    "    \n",
    "    #['admiration', 'approval', 'annoyance', 'gratitude', 'curiosity', 'optimism', 'amusement']\n",
    "    idx_most_common = df.labels.map(lambda x: all([int(label) in [0, 4, 3, 15, 7, 15, 20] for label in x]))\n",
    "    df_multi = df[(df.is_single == 0) & idx_most_common]\n",
    "    df_single = df[idx_most_common].sample(3*len(df_multi), weights=\"is_single\", axis=0, random_state=42)\n",
    "    return pd.concat([df_multi, df_single]).sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c784365d-4830-481d-a771-57a0d9623cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "def make_records(row, is_train: bool) -> rb.TextClassificationRecord:\n",
    "    annotation = [int2str(i) for i in row.labels] if not is_train else None\n",
    "    return rb.TextClassificationRecord(\n",
    "        inputs=row.text,\n",
    "        annotation=annotation,\n",
    "        multi_label=True,\n",
    "        id=row.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa658986-026e-4936-9c78-25b8c65516bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recs = create(\"train\").apply(make_records, axis=1, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4ce778d-83b1-4799-9a67-f304f027cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recs = create(\"test\").apply(make_records, axis=1, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1e552bc-df6f-4368-8d30-7d8e35238fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = train_recs.to_list() + test_recs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f854543-63ea-4b52-bf17-cf33ec604e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rb = rb.DatasetForTextClassification(records).to_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f61ddb4d-1387-47b4-b01c-3072e835e4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ff3efe852046beb60232c09e4c04b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_rb.push_to_hub(\"rubrix/go_emotions_multi-label\", private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1de2b1-97be-4372-8919-2dfc422a86b1",
   "metadata": {},
   "source": [
    "## APPENDIX B\n",
    "\n",
    "https://www.kaggle.com/shivanandmn/multilabel-classification-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708ac8e3-b809-430a-941a-ac0d5fb36446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55420944-3786-4dab-9b35-7cbcc47a9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/david/Downloads/topic_modeling_researc_articles/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87774d1a-b14a-41ff-9080-0eb34c008db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d16639d4-1e3a-4c71-b629-3090c8223830",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_id = train_test_split(df.ID, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771f9ebf-4f12-4533-b3f9-f2a820ea0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Computer Science\", \"Physics\", \"Mathematics\", \"Statistics\", \"Quantitative Biology\", \"Quantitative Finance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b539077-6dec-459b-ab48-0684410d78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_record(row):\n",
    "    annotation = [label for label in labels if row[label] == 1]\n",
    "    return rb.TextClassificationRecord(\n",
    "        inputs=row.TITLE,\n",
    "        annotation=annotation if row.ID in test_id else None,\n",
    "        multi_label=True,\n",
    "        id=row.ID,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb7e6338-d3e8-41c5-a130-7b0b20a068e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = df.apply(make_record, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2de5c5a-8eb4-49a7-b0f5-d6f2283323fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d68ba77-89ec-4856-87b1-603be88ae1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rb = rb.DatasetForTextClassification(records.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b47a6b98-d0a1-459e-b5bd-3514d5692d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eeb3777625a4bb8849460ba43ff6ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_rb.to_datasets().push_to_hub(\"rubrix/research_titles_multi-label\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987ecd4-1d4c-475b-be38-b94381ae9d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
