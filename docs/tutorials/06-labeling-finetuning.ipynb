{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d018ede1-93e5-44f7-a8b8-ea8436d063c1",
   "metadata": {},
   "source": [
    "# üè∑Ô∏è How to label your data and fine-tune a ü§ó sentiment classifier\n",
    "\n",
    "This tutorial will show you how to fine-tune a sentiment classifier for your own domain, starting with no labeled data.\n",
    "\n",
    "Most online tutorials about fine-tuning models assume you already have a training dataset. You'll find many tutorials for fine-tuning a pre-trained model with widely-used datasets, such as IMDB for sentiment analysis. \n",
    "\n",
    "However, very often **what you want is to fine-tune a model for your use case**. It's well-known that NLP model performance degrades with \"out-of-domain\" data. For example, a sentiment classifier pre-trained on movie reviews (e.g., IMDB) will not perform very well with customer requests.\n",
    "\n",
    "In this tutorial, we'll build a sentiment classifier for user requests in the banking domain as follows:\n",
    "\n",
    "- üèÅ Start with the most popular sentiment classifier on the Hugging Face Hub (2.3 million monthly downloads as of July 2021) which has been fine-tuned on the SST2 sentiment dataset. \n",
    "\n",
    "- üè∑Ô∏è Label a training dataset with banking user requests starting with the pre-trained sentiment classifier predictions.\n",
    "\n",
    "- ‚öôÔ∏è Fine-tune the pre-trained classifier with your training dataset.\n",
    "\n",
    "- üè∑Ô∏è Label more data by correcting the predictions of the fine-tuned model.\n",
    "\n",
    "- ‚öôÔ∏è Fine-tune the pre-trained classifier with the extended training dataset.\n",
    "\n",
    "\n",
    "This is an overview of the workflow we'll be following:\n",
    "\n",
    "\n",
    "![Labeling workflow](img/labeling_tutorial/workflow.svg \"Labeling workflow\")\n",
    "\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69321d8f-d3c4-4627-96ef-de416db75181",
   "metadata": {},
   "source": [
    "## Setup Rubrix\n",
    "\n",
    "\n",
    "**If you are new to Rubrix, visit and star Rubrix for updates**: ‚≠ê [Github repository](https://github.com/recognai/rubrix)\n",
    "\n",
    "If you have not installed and launched Rubrix, check the [Setup and Installation guide](https://docs.rubrix.ml/en/latest/getting_started/setup%26installation.html).\n",
    "\n",
    "\n",
    "Once installed, you only need to import Rubrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700d6c2c-b8c8-4e3e-8bd4-94d2b8fca85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518697a-c010-4532-b6d2-0ed1f831d106",
   "metadata": {},
   "source": [
    "## Install tutorial dependencies\n",
    "\n",
    "In this tutorial, we'll use the `transformers` and `datasets` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906d7d1-ea0d-4158-b6dc-a386342858e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers -qqq\n",
    "%pip install datasets -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2697c2cd-d6d1-45fb-97b6-2bf2b97d60c0",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "\n",
    "For building our fine-tuned classifier we'll be using two main resources, both available in the ü§ó Hub :\n",
    "\n",
    "1. A **dataset** in the banking domain: `banking77`\n",
    "\n",
    "2. A **pre-trained sentiment classifier**: `distilbert-base-uncased-finetuned-sst-2-english`\n",
    "\n",
    "### **Dataset**: `Banking 77`\n",
    "\n",
    "This dataset contains online banking user queries annotated with their corresponding intents. \n",
    "\n",
    "In our case, **we'll label the sentiment of these queries**, which might be useful for digital assistants and customer service analytics.\n",
    "\n",
    "\n",
    "Let's load the dataset directly from the hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73889eff-4214-4d49-bec9-816d5bf83175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "banking_ds = load_dataset(\"banking77\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9695362-66c7-422d-b614-891b69d24e05",
   "metadata": {},
   "source": [
    "For this tutoral, let's split the dataset into two 50% splits. We'll start with the `to_label1` split for data exploration and annotation and keep `to_label2` for further iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4128da4-9dc5-4ac6-aa8a-f6ec7d303e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_label1, to_label2 = banking_ds['train'].train_test_split(test_size=0.5, seed=42).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7c761-0240-4d64-85e7-8f2a32882d26",
   "metadata": {},
   "source": [
    "### **Model**: sentiment `distilbert` fine-tuned on sst-2\n",
    "\n",
    "\n",
    "As of July 2021, the `distilbert-base-uncased-finetuned-sst-2-english` is the most popular text-classification model in the [Hugging Face Hub](https://huggingface.co/models?pipeline_tag=text-classification).\n",
    "\n",
    "This model is a distilbert model fine-tuned on the highly popular sentiment classification benchmark SST-2 (Stanford Sentiment Treebank). \n",
    "\n",
    "As we will see later, this is a general-purpose sentiment classifier, which will need further fine-tuning for specific use cases and styles of text. In our case, **we'll explore its quality on banking user queries and build a training set for adapting it to this domain**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "498b7a66-8554-43fb-9ae1-c6bed273158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_classifier = pipeline(\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    task=\"sentiment-analysis\", \n",
    "    return_all_scores=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e7b69-017e-45c2-b2c4-99061e854b0e",
   "metadata": {},
   "source": [
    "Now let's test this pipeline with an example of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0caf9146-8cad-43e5-bc24-c4caedc93d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I just have one additional card from the USA. Do you support that?',\n",
       " [[{'label': 'NEGATIVE', 'score': 0.5619744062423706},\n",
       "   {'label': 'POSITIVE', 'score': 0.43802565336227417}]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_label1[3]['text'], sentiment_classifier(to_label1[3]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72de2fa5-4128-4f79-8d23-bd171370ae8b",
   "metadata": {},
   "source": [
    "The model assigns more probability to the `NEGATIVE` class. Following our annotation policy (read more below), we'll label examples like this as `POSITIVE` as they are general questions, not related to issues or problems with the banking application. The ultimate goal will be to fine-tune the model to predict `POSITIVE` for these cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3742e35a-6afc-4aeb-8701-b0245cd77350",
   "metadata": {},
   "source": [
    "### A note on sentiment analysis and data annotation\n",
    "\n",
    "Sentiment analysis is one of the most subjective tasks in NLP. What we understand by sentiment will vary from one application to another and depend on the business objectives of the project. Also, sentiment can be modeled in different ways, leading to different **labeling schemes**. For example, sentiment can be modeled as real value (going from -1 to 1, from 0 to 1.0, etc.) or with 2 or more labels (including different degrees such as positive, negative, neutral, etc.)\n",
    "\n",
    "For this tutorial, we'll use the **original labeling scheme** defined by the pre-trained model which is composed of two labels: `POSITIVE` and `NEGATIVE`. We could have added the `NEUTRAL` label, but let's keep it simple. \n",
    "\n",
    "Another important issue when approaching a data annotaion project are the **annotation guidelines**, which explain how to assign the labels to specific examples. As we'll see later, the messages we'll be labeling are mostly questions with a neutral sentiment, which we'll label with the `POSITIVE` label, and some other are negative questions which we'll label with the `NEGATIVE` label. Later on, we'll show some examples of each label.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd871f0a-6056-4663-81f1-fc74a9cc03bb",
   "metadata": {},
   "source": [
    "## 1. Run the **pre-trained model** over the dataset and log the predictions\n",
    "\n",
    "As a first step, let's use the pre-trained model for predicting over our raw dataset. For this will use the handy `dataset.map` method from the `datasets` library.\n",
    "\n",
    "![Predict-log workflow](img/labeling_tutorial/predict_log.svg \"predict-log workflow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5887a8a9-36a4-414a-b323-d66d0ca1fd36",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfdbab73-3316-47d5-8545-2cacbe076b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(examples):\n",
    "    return {\"predictions\": sentiment_classifier(examples['text'], truncation=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064d185-e020-49c1-bc7f-29bdda8648b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_label1 = to_label1.map(predict, batched=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa97a9b-fbad-49b7-98bc-b13d1a1648cb",
   "metadata": {},
   "source": [
    "### Log\n",
    "\n",
    "The following code builds a list of Rubrix records with the predictions and logs them into a Rubrix Dataset. We'll use this dataset to explore and label our first training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c642e5cb-a96d-4bd2-b6f0-c36f7fa3bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for example in to_label1.shuffle():\n",
    "    record = rb.TextClassificationRecord(\n",
    "        inputs=example[\"text\"],\n",
    "        metadata={'category': example['label']}, # log the intents for exploration of specific intents\n",
    "        prediction=[(pred['label'], pred['score']) for pred in example['predictions']],\n",
    "        prediction_agent=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    )\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a243e3-aa1f-4cc2-8f3c-ef7890a6e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.log(name='labeling_with_pretrained', records=records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc4a080-a8e0-4ccb-9252-a32af4849470",
   "metadata": {},
   "source": [
    "## 2. Explore and label data with the pretrained model\n",
    "\n",
    "In this step, we'll start by exploring how the pre-trained model is performing with our dataset. \n",
    "\n",
    "At first sight:\n",
    "\n",
    "- The pre-trained sentiment classifier tends to label most of the examples as `NEGATIVE` (4.835 of 5.001 records). You can see this yourself using the `Predictions / Predicted as:` filter\n",
    "\n",
    "- Using this filter and filtering by predicted as `POSITIVE`, we see that examples like \"*I didn't withdraw the amount of cash that is showing up in the app.*\" are not predicted as expected (according to our basic \"annotation policy\" described in the preliminaries).\n",
    "\n",
    "\n",
    "Taking into account this analysis, we can start labeling our data. \n",
    "\n",
    "![label workflow](img/labeling_tutorial/label.svg \"label workflow\")\n",
    "\n",
    "Rubrix provides you with a search-driven UI to annotated data, using free-text search, search filters and the Elasticsearch query DSL for advanced queries. This is most useful for sparse datasets, tasks with a high number of labels or unbalanced classes. In the standard case, we recommend you to follow the workflow below:\n",
    "\n",
    "1. **Start labeling examples sequentially**, without using search features. This way you'll annotate a fraction of your data which will be aligned with the dataset distribution.\n",
    "\n",
    "2. Once you have a sense of the data, you can **start using filters and search features to annotate examples with specific labels**. In our case, we'll label examples predicted as `POSITIVE` by our pre-trained model, and then a few examples predicted as `NEGATIVE`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320bb3cf-f4ea-4f06-b7bc-d5fcd95c6e54",
   "metadata": {},
   "source": [
    "\n",
    "### Labeling random examples\n",
    "\n",
    "![labeling](https://github.com/dvsrepo/imgs/raw/main/labeling_tutorial/1.gif \"labeling\")\n",
    "\n",
    "\n",
    "\n",
    "### Labeling POSITIVE examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc5b75c-40ff-46ff-8187-2709173e8bdf",
   "metadata": {},
   "source": [
    "![labeling](https://github.com/dvsrepo/imgs/raw/main/labeling_tutorial/2.gif \"labeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af186865-d609-491b-97ce-9a0417e70d0e",
   "metadata": {},
   "source": [
    "After spending some minutes, we've labelled almost **5% of our raw dataset with more than 200 annotated examples**, which is a small dataset but should be enough for a first fine-tuning of our banking sentiment classifier:\n",
    "\n",
    "<div>\n",
    "<img src=\"img/labeling_tutorial/annotations1.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83a1d6-9700-4f13-ad01-8ac1d00b1260",
   "metadata": {},
   "source": [
    "## 3. Fine-tune the pre-trained model\n",
    "\n",
    "In this step, we'll load our training set from Rubrix and fine-tune using the `Trainer` API from Hugging Face `transformers`. For this, we closely follow the guide [Fine-tuning a pre-trained model](https://huggingface.co/transformers/training.html#fine-tuning-a-pretrained-model) from the `transformers` docs.\n",
    "\n",
    "\n",
    "![finetune workflow](img/labeling_tutorial/fine_tune.svg \"finetune workflow\")\n",
    "\n",
    "\n",
    "First, let's load our dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b331bd-e4e0-41b5-9370-28f8aac01aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df = rb.load(name='labeling_with_pretrained')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df5aace-bdc2-41dd-9b2f-0e0c13539678",
   "metadata": {},
   "source": [
    "This dataset contains all records, let's filter only our annotations using the status column. The `Validated` status corresponds to annotated records. You can read more about how [record status is defined in Rubrix](https://docs.rubrix.ml/en/stable/reference/rubrix_webapp_reference.html#status-filter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c62f17ce-8bc4-489f-ac09-ad1469f5f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df = rb_df[rb_df.status == \"Validated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207a8c3f-f5c9-4bd3-baed-3edd804a5f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>prediction</th>\n",
       "      <th>annotation</th>\n",
       "      <th>prediction_agent</th>\n",
       "      <th>annotation_agent</th>\n",
       "      <th>multi_label</th>\n",
       "      <th>explanation</th>\n",
       "      <th>id</th>\n",
       "      <th>metadata</th>\n",
       "      <th>status</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>{'text': 'I saw there is a cash withdrawal fro...</td>\n",
       "      <td>[(NEGATIVE, 0.9997006654739381), (POSITIVE, 0....</td>\n",
       "      <td>[NEGATIVE]</td>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>.local-Rubrix</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0001e324-3247-4716-addc-d9d9c83fd8f9</td>\n",
       "      <td>{'category': 20}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4772</th>\n",
       "      <td>{'text': 'Why is it showing that my account ha...</td>\n",
       "      <td>[(NEGATIVE, 0.9991878271102901), (POSITIVE, 0....</td>\n",
       "      <td>[NEGATIVE]</td>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>.local-Rubrix</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0017e5c9-c135-44b9-8efb-a17ffecdbe68</td>\n",
       "      <td>{'category': 34}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>{'text': 'I thought I lost my card but I found...</td>\n",
       "      <td>[(POSITIVE, 0.9842885732650751), (NEGATIVE, 0....</td>\n",
       "      <td>[POSITIVE]</td>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>.local-Rubrix</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0048ccce-8c9f-453d-81b1-a966695e579c</td>\n",
       "      <td>{'category': 13}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>{'text': 'I wanted to top up my account and it...</td>\n",
       "      <td>[(NEGATIVE, 0.999732434749603), (POSITIVE, 0.0...</td>\n",
       "      <td>[NEGATIVE]</td>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>.local-Rubrix</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0046aadc-2344-40d2-a930-81f00687bf44</td>\n",
       "      <td>{'category': 59}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>{'text': 'I need to deposit my virtual card, h...</td>\n",
       "      <td>[(NEGATIVE, 0.9992493987083431), (POSITIVE, 0....</td>\n",
       "      <td>[POSITIVE]</td>\n",
       "      <td>distilbert-base-uncased-finetuned-sst-2-english</td>\n",
       "      <td>.local-Rubrix</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>00071745-741d-4555-82b3-54d25db44c38</td>\n",
       "      <td>{'category': 37}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 inputs  \\\n",
       "4771  {'text': 'I saw there is a cash withdrawal fro...   \n",
       "4772  {'text': 'Why is it showing that my account ha...   \n",
       "4773  {'text': 'I thought I lost my card but I found...   \n",
       "4774  {'text': 'I wanted to top up my account and it...   \n",
       "4775  {'text': 'I need to deposit my virtual card, h...   \n",
       "\n",
       "                                             prediction  annotation  \\\n",
       "4771  [(NEGATIVE, 0.9997006654739381), (POSITIVE, 0....  [NEGATIVE]   \n",
       "4772  [(NEGATIVE, 0.9991878271102901), (POSITIVE, 0....  [NEGATIVE]   \n",
       "4773  [(POSITIVE, 0.9842885732650751), (NEGATIVE, 0....  [POSITIVE]   \n",
       "4774  [(NEGATIVE, 0.999732434749603), (POSITIVE, 0.0...  [NEGATIVE]   \n",
       "4775  [(NEGATIVE, 0.9992493987083431), (POSITIVE, 0....  [POSITIVE]   \n",
       "\n",
       "                                     prediction_agent annotation_agent  \\\n",
       "4771  distilbert-base-uncased-finetuned-sst-2-english    .local-Rubrix   \n",
       "4772  distilbert-base-uncased-finetuned-sst-2-english    .local-Rubrix   \n",
       "4773  distilbert-base-uncased-finetuned-sst-2-english    .local-Rubrix   \n",
       "4774  distilbert-base-uncased-finetuned-sst-2-english    .local-Rubrix   \n",
       "4775  distilbert-base-uncased-finetuned-sst-2-english    .local-Rubrix   \n",
       "\n",
       "      multi_label explanation                                    id  \\\n",
       "4771        False        None  0001e324-3247-4716-addc-d9d9c83fd8f9   \n",
       "4772        False        None  0017e5c9-c135-44b9-8efb-a17ffecdbe68   \n",
       "4773        False        None  0048ccce-8c9f-453d-81b1-a966695e579c   \n",
       "4774        False        None  0046aadc-2344-40d2-a930-81f00687bf44   \n",
       "4775        False        None  00071745-741d-4555-82b3-54d25db44c38   \n",
       "\n",
       "              metadata     status event_timestamp  \n",
       "4771  {'category': 20}  Validated            None  \n",
       "4772  {'category': 34}  Validated            None  \n",
       "4773  {'category': 13}  Validated            None  \n",
       "4774  {'category': 59}  Validated            None  \n",
       "4775  {'category': 37}  Validated            None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4300cd1e-0b11-4893-9918-aab365ecbb56",
   "metadata": {},
   "source": [
    "### Prepare training and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56e5fc-de02-4a8d-8b1c-a397aee8382a",
   "metadata": {},
   "source": [
    "Let's now prepare our dataset for training and testing our sentiment classifier, using the `datasets` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc7dab5-164b-4013-ba06-41c94cccc926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# select text input and the annotated label\n",
    "rb_df['text'] = rb_df.inputs.transform(lambda r: r['text'])\n",
    "# keep in mind that `rb_df.annotation` can be a list of labels\n",
    "# to support multi-label text classifiers\n",
    "rb_df['labels'] = rb_df.annotation\n",
    "\n",
    "\n",
    "# create ü§ó dataset from pandas with labels as numeric ids\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "train_ds = Dataset.from_pandas(rb_df[['text', 'labels']])\n",
    "train_ds = train_ds.map(lambda example: {'labels': label2id[example['labels']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130a2377-3009-47a8-9f5f-a883eae51d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['__index_level_0__', 'labels', 'text'],\n",
       "        num_rows: 183\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['__index_level_0__', 'labels', 'text'],\n",
       "        num_rows: 46\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = train_ds.train_test_split(test_size=0.2) ; train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f26f9a-f653-4418-8cec-c7081ecabfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_ds['train'].map(tokenize_function, batched=True).shuffle(seed=42)\n",
    "eval_dataset = train_ds['test'].map(tokenize_function, batched=True).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c66f064-72f0-49a7-968c-eb5dd64eb697",
   "metadata": {},
   "source": [
    "### Train our sentiment classifier\n",
    "\n",
    "As we mentioned before, we're going to fine-tune the `distilbert-base-uncased-finetuned-sst-2-english` model. Another option will be fine-tuning a distilbert masked language model from scratch, we leave this experiment to you.\n",
    "\n",
    "Let's load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ea5cc1-f634-4c66-9150-eb0ec48c478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ba7321-832c-49f3-87c8-10a7d24fb0ef",
   "metadata": {},
   "source": [
    "Let's configure the Trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c2fc4-78b2-43b0-8e19-2f2c899e2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import Trainer\n",
    "from datasets import load_metric\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"distilbert-base-uncased-sentiment-banking\", \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=30\n",
    ")\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    model=model, \n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=eval_dataset, \n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0828cc3e-9c2f-4a48-aa2f-bc141cb0b234",
   "metadata": {},
   "source": [
    "And finally train our first model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96ccd6-0a2b-4a1f-846d-588915f4dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7703d9a4-bfce-466f-accc-65f65a784f2d",
   "metadata": {},
   "source": [
    "## 4. Testing the fine-tuned model\n",
    "\n",
    "In this step, let's first test the model we have just trained.\n",
    "\n",
    "Let's create a new pipeline with our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7aa3305-78bc-4316-a886-0c5b3e95d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_sentiment_classifier = pipeline(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    task=\"sentiment-analysis\", \n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d7669-63ac-42c3-a21c-b50958bdbc9e",
   "metadata": {},
   "source": [
    "And compare its predictions with the pre-trained model with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cad3506-fa39-40f9-9dc5-99aaf23e7700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[{'label': 'NEGATIVE', 'score': 0.0002401248930254951},\n",
       "   {'label': 'POSITIVE', 'score': 0.9997599124908447}]],\n",
       " [[{'label': 'NEGATIVE', 'score': 0.9992493987083435},\n",
       "   {'label': 'POSITIVE', 'score': 0.0007506058318540454}]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_sentiment_classifier(\n",
    "    'I need to deposit my virtual card, how do i do that.'\n",
    "), sentiment_classifier(\n",
    "    'I need to deposit my virtual card, how do i do that.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95827c-bee6-4488-b8ac-84b5c2ab9149",
   "metadata": {},
   "source": [
    "As you can see, our fine-tuned model now classifies this general questions (not related to issues or problems) as `POSITIVE`, while the pre-trained model still classifies this as `NEGATIVE`.\n",
    "\n",
    "Let's check now an example related to an issue where both models work as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3714da8c-f57b-4f04-8905-53e17a9ff130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[{'label': 'NEGATIVE', 'score': 0.9988037347793579},\n",
       "   {'label': 'POSITIVE', 'score': 0.001196274533867836}]],\n",
       " [[{'label': 'NEGATIVE', 'score': 0.9983781576156616},\n",
       "   {'label': 'POSITIVE', 'score': 0.0016218466917052865}]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_sentiment_classifier(\n",
    "    'Why is my payment still pending?'\n",
    "), sentiment_classifier(\n",
    "    'Why is my payment still pending?'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae254b5-5d48-4670-baca-7918bd0d15c7",
   "metadata": {},
   "source": [
    "## 5. Run our **fine-tuned model** over the dataset and log the predictions\n",
    "\n",
    "\n",
    "Let's now create a dataset from the remaining records (those which we haven't annotated in the first annotation session).\n",
    "\n",
    "We'll do this using the `Default` status, which means the record hasn't been assigned a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62066df5-4900-4df0-b504-499bcea85955",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df = rb.load(name='labeling_with_pretrained')\n",
    "rb_df = rb_df[rb_df.status == \"Default\"]\n",
    "rb_df['text'] = rb_df.inputs.transform(lambda r: r['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cea805-2a8b-4adc-af73-4d60130b84d6",
   "metadata": {},
   "source": [
    "From here, this is basically the same as step 1, in this case using our fine-tuned model:\n",
    "\n",
    "![Predict-log workflow](img/labeling_tutorial/predict_log2.svg \"predict-log workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d00c4121-f8b0-48f4-b7e2-eb02a18e63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(rb_df[['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b387ffb2-35b0-42f5-b23a-c09074722838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(examples):\n",
    "    return {\"predictions\": finetuned_sentiment_classifier(examples['text'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f16fdc-5c34-49c9-8453-9d56ddbcd044",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(predict, batched=True, batch_size=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55a373c8-fc54-4c78-8198-4163dd352dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for example in ds.shuffle():\n",
    "    record = rb.TextClassificationRecord(\n",
    "        inputs=example[\"text\"],\n",
    "        prediction=[(pred['label'], pred['score']) for pred in example['predictions']],\n",
    "        prediction_agent=\"distilbert-base-uncased-banking77-sentiment\"\n",
    "    )\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6594400-0605-44a4-b0cd-e3f7c0401189",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.log(name='labeling_with_finetuned', records=records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e1315-ee55-4c3c-a3d8-1d4f930f0d69",
   "metadata": {},
   "source": [
    "## 6. Explore and label data with the fine-tuned model\n",
    "\n",
    "\n",
    "In this step, we'll start by exploring how the fine-tuned model is performing with our dataset. \n",
    "\n",
    "At first sight, using the predicted as filter by `POSITIVE` and then by `NEGATIVE`, we see that the fine-tuned model predictions are more aligned with our \"annotation policy\".\n",
    "\n",
    "Now that the model is performing better for our use case, we'll extend our training set with highly informative examples. A typical workflow for doing this is as follows:\n",
    "\n",
    "1. **Use the prediction score filter** for labeling uncertain examples. Below you can see how to use this filter for labeling examples withing the range from 0 to 0.6.\n",
    "\n",
    "![labeling](https://github.com/dvsrepo/imgs/raw/main/labeling_tutorial/3.gif \"labeling\")\n",
    "\n",
    "\n",
    "\n",
    "2. Label examples predicted as `POSITIVE` by our fine-tuned model, and then predicted as `NEGATIVE` to correct the predictions.\n",
    "\n",
    "\n",
    "After spending some minutes, we've labelled almost **2% of our raw dataset with around 80 annotated examples**, which is a small dataset but hopefully with highly informative examples.\n",
    "\n",
    "<div>\n",
    "<img src=\"img/labeling_tutorial/annotations2.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595c332-1d1d-4e15-a22c-7fcbb6556234",
   "metadata": {},
   "source": [
    "## 7. Fine-tuning with the extended training dataset\n",
    "\n",
    "In this step, we'll add the new examples to our training set and fine-tune a new version of our banking sentiment classifier.\n",
    "\n",
    "![Finetune workflow](img/labeling_tutorial/fine_tune2.svg \"Finetune workflow\")\n",
    "\n",
    "\n",
    "\n",
    "### Add labeled examples to our previous training set\n",
    "\n",
    "Let's add our new examples to our previous training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fafcf0ca-d86e-436e-9670-3680a9746531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_df(dataset_name):\n",
    "    rb_df = rb.load(name=dataset_name)\n",
    "    rb_df = rb_df[rb_df.status == \"Validated\"] ; len(rb_df)\n",
    "    rb_df['text'] = rb_df.inputs.transform(lambda r: r['text'])\n",
    "    rb_df['labels'] = rb_df.annotation.transform(lambda r: r[0])\n",
    "    return rb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34938d9f-0284-4157-bd08-fd1a9a7a41b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prepare_train_df('labeling_with_finetuned') ; len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8819b45e-841f-4070-822a-35a7ab4f2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns('__index_level_0__')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c6a0d-2aaf-478e-a576-a1c5a0ee1d19",
   "metadata": {},
   "source": [
    "We'll use the [.add_item](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.add_item) method from the `datasets` library to add our examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce9e243a-61e6-46b4-99e9-9c8617d55161",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in df.iterrows():\n",
    "    tokenization = tokenizer(r[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    train_dataset = train_dataset.add_item({\n",
    "        \"attention_mask\": tokenization[\"attention_mask\"],\n",
    "        \"input_ids\": tokenization[\"input_ids\"],\n",
    "        \"labels\": label2id[r['labels']],\n",
    "        \"text\": r['text'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9de88f04-f040-4ab8-b9fd-d40da6c1c43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'labels', 'text'],\n",
       "    num_rows: 266\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe83626-ebed-429d-95c3-42762548066d",
   "metadata": {},
   "source": [
    "### Train our sentiment classifier\n",
    "\n",
    "As we want to measure the effect of adding examples to our training set we will:\n",
    "\n",
    "- Fine-tune from the pre-trained sentiment weights (as we did before)\n",
    "- Use the previous test set and the extended train set (obtaining a metric we use to compare this new version with our previous model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26336d72-a6da-42ce-b254-3218e872bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40586f10-53fd-4200-ba73-33901bc343df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dataset.shuffle(seed=42)\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    model=model, \n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=eval_dataset, \n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe93720-5bd3-450a-a8c3-4ff2834623e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"distilbert-base-uncased-sentiment-banking\", push_to_hub=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d3e6b-0684-47db-ab69-ff705945363f",
   "metadata": {},
   "source": [
    "## Wrap-up\n",
    "\n",
    "In this tutorial, you've learnt to build a training set from scratch with the help of a pre-trained model, performing two iterations of `predict` > `log` > `label`. \n",
    "\n",
    "Although this is somehow a toy example, you could apply this workflow to your own projects to adapt existing models or building them from scratch. \n",
    "\n",
    "In this tutorial, we've covered one way of building training sets: hand labeling. If you are interested in other methods, which could be combined witth hand labeling, checkout the following tutorials:\n",
    "\n",
    "- [Active learning with modAL](https://docs.rubrix.ml/en/stable/tutorials/05-active_learning.html)\n",
    "- [Weak supervision with Snorkel](https://docs.rubrix.ml/en/stable/tutorials/04-snorkel.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a625c698-1b6b-4e71-8077-1649de637fca",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "### ‚≠ê Star Rubrix [Github repo](https://github.com/recognai/rubrix) to stay updated.\n",
    "\n",
    "### üìö [Rubrix documentation](https://docs.rubrix.ml) for more guides and tutorials.\n",
    "\n",
    "### üôã‚Äç‚ôÄÔ∏è Join the Rubrix community! A good place to start is the [discussion forum](https://github.com/recognai/rubrix/discussions)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}