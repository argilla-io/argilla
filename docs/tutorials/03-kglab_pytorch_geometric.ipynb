{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "462a1283-4b08-4fec-8dc4-233f07b93f13",
   "metadata": {},
   "source": [
    "# ðŸ§ª Semi-supervised node classification with `kglab` and PyTorch Geometric\n",
    "\n",
    "We introduce the application of neural networks on knowledge graphs using `kglab`. \n",
    "\n",
    "Graph Neural networks (GNNs) have gained popularity in a number of practical applications, including knowledge graphs, social networks and recommender systems. In the context of knowledge graphs, GNNs are being used for tasks such as link prediction, node classification or knowledge graph embeddings. Use cases for these tasks include `Automatic Knowledge Base Construction` (AKBC) and `Data Curation` of data from different sources and with varying quality and trust.\n",
    "\n",
    "In this tutorial, we will learn to:\n",
    "\n",
    "- use `kglab` to represent a knowledge graph as a Pytorch Tensor, a suitable structure working with PyTorch neural nets\n",
    "\n",
    "- use the widely known `pytorch_geometric` (PyG) GNN library together with `kglab`.\n",
    "\n",
    "- train a GNN with `pytorch_geometric` and `PyTorch Lightning` for semi-supervised node classification of the recipes knowledge graph.\n",
    "\n",
    "- build and iterate on training data using `rubrix` with a Human-in-the-loop (HITL) approach.\n",
    "\n",
    "## Our use case in a nutshell\n",
    "\n",
    "Our goal in this notebook will be to build a semi-supervised node classifier of recipes and ingredients from scratch using kglab, PyG and Rubrix. \n",
    "\n",
    "Our classifier will be able to classify the nodes in our 15K nodes knowledge graph according to a set of pre-defined flavour related categories: `sweet`, `salty`, `piquant`, `sour`, etc. To account for mixed flavours (e.g., sweet chili sauce), our model will be multi-class (we have several target labels), multi-label (a node can be labelled as with 0 or several categories)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb92c5a-c3b7-4246-a386-8864fce7b215",
   "metadata": {},
   "source": [
    "## Install `kglab` and `Pytorch Geometric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2fc773-7d89-4132-87c6-5946ae7c6018",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cpu.html -qqq\n",
    "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cpu.html -qqq\n",
    "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.8.0+cpu.html -qqq\n",
    "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.8.0+cpu.html -qqq\n",
    "!pip install torch-geometric -qqq\n",
    "!pip install torch -qqq\n",
    "\n",
    "!pip install kglab -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b091b38-3565-4f17-a4d1-0a274c23d7fd",
   "metadata": {},
   "source": [
    "## 1. Loading and exploring the recipes knowledge graph\n",
    "\n",
    "We'll be working with the \"recipes\" knowledge graph, which is used throughout the `kglab` tutorial (see the [Syllabus](https://derwen.ai/docs/kgl/tutorial/)).\n",
    "\n",
    "This version of the recipes kg contains around ~15K recipes linked to their respective ingredients, as well as some other properties such as cooking time, labels and descriptions. \n",
    "\n",
    "Let's load the knowledge graph into a `kg` object by reading from an RDF file (in Turtle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea7a6f2a-af54-498c-a8bb-919ffd3de318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kglab\n",
    "\n",
    "NAMESPACES = {\n",
    "    \"wtm\":  \"http://purl.org/heals/food/\",\n",
    "    \"ind\":  \"http://purl.org/heals/ingredient/\",\n",
    "    \"recipe\":  \"https://www.food.com/recipe/\",\n",
    "    }\n",
    "\n",
    "kg = kglab.KnowledgeGraph(namespaces = NAMESPACES)\n",
    "\n",
    "_ = kg.load_rdf(\"data/recipe_lg.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb4e57d-cb2b-4e63-b53d-8f640245021c",
   "metadata": {},
   "source": [
    "Let's take a look at our graph structure using the `Measure` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f6db803-1665-4c54-9a0a-50a4c8492b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nodes: 15983 ; Edges: 160980'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure = kglab.Measure()\n",
    "measure.measure_graph(kg)\n",
    "\n",
    "f\"Nodes: {measure.get_node_count()} ; Edges: {measure.get_edge_count()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b120a39-c473-4114-9f12-b6d5b7481961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/food/hasIngredient</th>\n",
       "      <td>113537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.w3.org/1999/02/22-rdf-syntax-ns#type</th>\n",
       "      <td>15981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.w3.org/2004/02/skos/core#definition</th>\n",
       "      <td>15481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/food/hasCookTime</th>\n",
       "      <td>15407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.w3.org/2004/02/skos/core#prefLabel</th>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  count\n",
       "http://purl.org/heals/food/hasIngredient         113537\n",
       "http://www.w3.org/1999/02/22-rdf-syntax-ns#type   15981\n",
       "http://www.w3.org/2004/02/skos/core#definition    15481\n",
       "http://purl.org/heals/food/hasCookTime            15407\n",
       "http://www.w3.org/2004/02/skos/core#prefLabel       574"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure.p_gen.get_tally() # tallies the counts of predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61a7459d-9f57-49a4-b36e-de499f713689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://www.food.com/recipe/67888</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.food.com/recipe/501028</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.food.com/recipe/277843</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.food.com/recipe/38276</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.food.com/recipe/262816</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/celery_seed</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/rotel_tomatoes</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/tempeh</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/fresh_herbs</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/flat_leaf_parsley</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15981 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    count\n",
       "https://www.food.com/recipe/67888                      25\n",
       "https://www.food.com/recipe/501028                     25\n",
       "https://www.food.com/recipe/277843                     24\n",
       "https://www.food.com/recipe/38276                      24\n",
       "https://www.food.com/recipe/262816                     23\n",
       "...                                                   ...\n",
       "http://purl.org/heals/ingredient/celery_seed            2\n",
       "http://purl.org/heals/ingredient/rotel_tomatoes         2\n",
       "http://purl.org/heals/ingredient/tempeh                 2\n",
       "http://purl.org/heals/ingredient/fresh_herbs            2\n",
       "http://purl.org/heals/ingredient/flat_leaf_parsley      2\n",
       "\n",
       "[15981 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure.s_gen.get_tally() # tallies the counts of predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94e18c1b-4f57-4478-9f06-decdaeff5b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/food/Recipe</th>\n",
       "      <td>15407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/Salt</th>\n",
       "      <td>9034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/AllPurposeFlour</th>\n",
       "      <td>6456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/ChickenEgg</th>\n",
       "      <td>6041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/WhiteSugar</th>\n",
       "      <td>5979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/dry_onion_flakes</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/smoked_chicken</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/black_cumin</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/sugar_free_non_fat_vanilla_yogurt</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://purl.org/heals/ingredient/veal_roast</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>563 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    count\n",
       "http://purl.org/heals/food/Recipe                   15407\n",
       "http://purl.org/heals/ingredient/Salt                9034\n",
       "http://purl.org/heals/ingredient/AllPurposeFlour     6456\n",
       "http://purl.org/heals/ingredient/ChickenEgg          6041\n",
       "http://purl.org/heals/ingredient/WhiteSugar          5979\n",
       "...                                                   ...\n",
       "http://purl.org/heals/ingredient/dry_onion_flakes       1\n",
       "http://purl.org/heals/ingredient/smoked_chicken         1\n",
       "http://purl.org/heals/ingredient/black_cumin            1\n",
       "http://purl.org/heals/ingredient/sugar_free_non...      1\n",
       "http://purl.org/heals/ingredient/veal_roast             1\n",
       "\n",
       "[563 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure.o_gen.get_tally() # tallies the counts of predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd29b208-d9cd-4086-a391-292e4497f387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PT30M</th>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT20M</th>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT25M</th>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT10M</th>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT15M</th>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jucy lucy cheeseburger</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boulettes</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best ever butter cookies</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classic gingersnap cookies</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthony s tomato mozzarella crepes</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16276 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    count\n",
       "PT30M                                1129\n",
       "PT20M                                1074\n",
       "PT25M                                 956\n",
       "PT10M                                 938\n",
       "PT15M                                 906\n",
       "...                                   ...\n",
       "jucy lucy cheeseburger                  1\n",
       "boulettes                               1\n",
       "best ever butter cookies                1\n",
       "classic gingersnap cookies              1\n",
       "anthony s tomato mozzarella crepes      1\n",
       "\n",
       "[16276 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure.l_gen.get_tally() # tallies the counts of literals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80a620-bf54-41e1-bd91-7ff383f2d5d8",
   "metadata": {},
   "source": [
    "From the above exploration, we can extract some conclusions to guide the next steps:\n",
    "\n",
    "- We have a limited number of relationships, being `hasIngredient` the most frequent.\n",
    "\n",
    "- We have rather unique literals for labels and descriptions, but a certain amount of repetition for `hasCookTime`.\n",
    "\n",
    "- As we would have expected, most frequently referenced objects are ingredients such as `Salt`, `ChikenEgg` and so on. \n",
    "\n",
    "\n",
    "Now, let's move into preparing our knowledge graph for PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc5491-bff6-4d97-9b1f-564d0cee79f3",
   "metadata": {},
   "source": [
    "## 2. Representing our knowledge graph as a `PyTorch` Tensor\n",
    "\n",
    "Let's now represent our `kg` as a `PyTorch` tensor using the `kglab.SubgraphTensor` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2650e50-d101-47af-8465-802fe3cd7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = kglab.SubgraphTensor(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d769f9-9c8a-43c3-a4d6-b14825155f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorify(g, sg, excludes):\n",
    "    def exclude(rel):\n",
    "        return sg.n3fy(rel) in excludes\n",
    "    \n",
    "    relations = sorted(set(g.predicates()))\n",
    "    subjects = set(g.subjects())\n",
    "    objects = set(g.objects())\n",
    "    nodes = list(subjects.union(objects))\n",
    "    \n",
    "    relations_dict = {rel: i for i, rel in enumerate(list(relations)) if not exclude(rel)}\n",
    "    \n",
    "    # this offset enables consecutive indices in our final vector\n",
    "    offset = len(relations_dict.keys())\n",
    "    \n",
    "    nodes_dict = {node: i+offset for i, node in enumerate(nodes)}\n",
    "\n",
    "    \n",
    "    edge_list = []\n",
    "    \n",
    "    for s, p, o in g.triples((None, None, None)):\n",
    "        if p in relations_dict.keys(): # this means is not excluded\n",
    "            src, dst, rel = nodes_dict[s], nodes_dict[o], relations_dict[p]\n",
    "            edge_list.append([src, dst, 2 * rel])\n",
    "            edge_list.append([dst, src, 2 * rel + 1])\n",
    "    \n",
    "    # turn into str keys and concat\n",
    "    node_vector = [sg.n3fy(node) for node in relations_dict.keys()] + [sg.n3fy(node) for node in nodes_dict.keys()]\n",
    "    return edge_list, node_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac3c53-5e4a-4f43-8aff-f9fde2050b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list, node_vector = tensorify(kg.rdf_graph(), sg, excludes=['skos:description', 'skos:prefLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c5629-8ad9-4f7a-b497-0369724bc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edge_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67ebf7-9e21-4fa6-ab7b-26b82d7f2bfa",
   "metadata": {},
   "source": [
    "Let's create `kglab.Subgraph` to be used for encoding/decoding numerical ids and uris, which will be useful for preparing our training data, as well as making sense of the predictions of our neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c50e43-fb24-42d1-b1e2-b11dde400ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = kglab.Subgraph(kg=kg, preload=node_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5332478-a25f-42a6-a08a-1b2478e53467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "tensor = torch.tensor(edge_list, dtype=torch.long).t().contiguous() \n",
    "edge_index, edge_type = tensor[:2], tensor[2]\n",
    "data = Data(edge_index=edge_index)\n",
    "data.edge_type = edge_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5665a5c-ae8d-4e06-aba5-e76e039ebbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.edge_index.shape, data.edge_type.shape, data.edge_type.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c1023-d7e6-4e14-9e47-bb4e05c69c4e",
   "metadata": {},
   "source": [
    "## 3. Building a training set with Rubrix\n",
    "\n",
    "Now that we have a tensor representation of our kg which we can feed into our neural network, let's now focus on the training data.\n",
    "\n",
    "As we will be doing semi-supervised classification, we need to build a training set (i.e., some recipes and ingredients with ground-truth labels). \n",
    "\n",
    "\n",
    "For this, we can use [Rubrix](https://github.com/recognai/rubrix), an open-source tool for exploring, labeling and iterating on data for AI. Rubrix allows data scientists and subject matter experts to rapidly iterate on training and evaluation data by enabling iterative, asynchronous and potentially distributed workflows.\n",
    "\n",
    "In Rubrix, a very simple workflow during model development looks like this:\n",
    "\n",
    "1. Log unlabelled data records with `rb.log()` into a Rubrix dataset. At this step you could use weak supervision methods (e.g., Snorkel) to pre-populate and then only refine the suggested labels, or use a pretrained model to guide your annotation process. In our case, we will just log recipe and ingredient \"records\" along with some metadata (RDF types, labels, etc.).\n",
    "\n",
    "2. Rapidly explore and label records in your dataset using the webapp which follows a search-driven approach, which is especially useful with large, potentially noisy datasets and for quickly leveraging domain knowledge (e.g., recipes containing WhiteSugar are likely sweet). For the tutorial, we have spent around 30min for labelling around 600 records.\n",
    "\n",
    "3. Retrieve your annotations any time using `rb.load()` or `rb.snapshot()`, which return a convenient `pd.Dataframe` making it quite handy to process and use for model development. In our case, we will load a snapshot, do a train_test_split with scikit_learn, and then use this for training our GNN.\n",
    "\n",
    "4. After training a model, you can go back to step 1, this time using your model and its predictions, to spot improvements, quickly label other portions of the data, and so on. In our case, as we've started with a very limited training set (~600 examples), we will use our node classifier and `rb.log()` it's predictions over the rest of our data (unlabelled recipes and ingredients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179328f2-56ee-463b-9338-10c1fc585a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Bitter', 'Meaty', 'Piquant', 'Salty', 'Sour', 'Sweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ceba7-9132-4842-88a1-add9733f0f57",
   "metadata": {},
   "source": [
    "### Setup Rubrix\n",
    "\n",
    "If you have not installed and launched Rubrix, check the [installation guide](https://github.com/recognai/rubrix#get-started). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc2add-0482-47b0-92ea-778a008fd53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89a854-729a-463d-a85a-e282352ec3f8",
   "metadata": {},
   "source": [
    "### 0. Preparing our raw dataset of recipes and ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb37ae9-fadf-4187-a028-65853b7cccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sparql = \"\"\"\n",
    "    SELECT distinct *\n",
    "    WHERE {\n",
    "        ?uri a wtm:Recipe .\n",
    "        ?uri a ?type .\n",
    "        ?uri skos:definition ?definition .\n",
    "        ?uri wtm:hasIngredient ?ingredient\n",
    "    } \n",
    "\"\"\"\n",
    "df = kg.query_as_df(sparql=sparql)\n",
    "\n",
    "# We group the ingredients into one column containing lists:\n",
    "recipes_df = df.groupby(['uri', 'definition', 'type'])['ingredient'].apply(list).reset_index(name='ingredients') ; recipes_df\n",
    "\n",
    "sparql_ingredients = \"\"\"\n",
    "    SELECT distinct *\n",
    "    WHERE {\n",
    "        ?uri a wtm:Ingredient .\n",
    "        ?uri a ?type .\n",
    "        OPTIONAL { ?uri skos:prefLabel ?definition } \n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "df = kg.query_as_df(sparql=sparql_ingredients)\n",
    "df['ingredients'] = None\n",
    "\n",
    "ing_recipes_df = pd.concat([recipes_df, df]).reset_index(drop=True)\n",
    "\n",
    "ing_recipes_df.fillna('', inplace=True) ; ing_recipes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7527d5-2750-45ba-b4fa-3d5a946dac44",
   "metadata": {},
   "source": [
    "### 1. Logging into Rubrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f9721f-cbc8-4b54-9938-ca77da5bde8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "records = []\n",
    "for i, r in ing_recipes_df.iterrows():\n",
    "    item = rb.TextClassificationRecord(\n",
    "            inputs={\n",
    "                \"id\":r.uri, \n",
    "                \"definition\": r.definition,\n",
    "                \"ingredients\": str(r.ingredients), \n",
    "                \"type\": r.type\n",
    "            }, # log node fields\n",
    "            prediction=[(label, 0.0) for label in LABELS], # log \"dummy\" predictions for aiding annotation\n",
    "            metadata={'ingredients': r.ingredients, \"type\": r.type}, # metadata filters for quick exploration and annotation\n",
    "            prediction_agent=\"kglab_tutorial\", # who's performing/logging the prediction\n",
    "            multi_label=True\n",
    "        )\n",
    "    records.append(item)\n",
    "rb.log(records=records, name=\"kg_classification_tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5841e9-ac04-4c1c-ba4b-c28a2a953035",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Annotation session with Rubrix (optional)\n",
    "\n",
    "In this step you can go to your rubrix dataset and annotate some examples of each class.\n",
    "\n",
    "If you have no time to do this, just skip this part as we have prepared a dataset for you with around ~600 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd8409-c141-45a4-bebe-e1dc0c1649b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Loading our labelled records and create a train_test split (optional)\n",
    "\n",
    "In this step you can go to your rubrix dataset and annotate some examples of each class.\n",
    "\n",
    "If you have no time to do this, just skip this part as we have prepared a dataset for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be0fe7-2d5e-48ab-9627-20af351e041c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rb.snapshots(dataset=\"kg_node_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b40be-f46e-4156-8024-42008529ecdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = rb.load(name=\"kg_node_classification\", snapshot='1619530026.060097') ; df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26df5f7-bee0-495b-89ff-e568e34a3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df)\n",
    "train_df.to_csv('data/train_recipes_new.csv')\n",
    "test_df.to_csv('data/test_recipes_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9c7b9-b163-427b-9ff6-e64aa605b311",
   "metadata": {},
   "source": [
    "### 4. Creating PyTorch train and test sets\n",
    "\n",
    "Here we take our train and test datasets and transform them into `torch.Tensor` objects with the help of our kglab `Subgraph` for turning `uris` into `torch.long` indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c252ee-96c9-4d55-bc8d-2c1d5af73a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('data/train_recipes.csv') # use your own labelled datasets if you've created a snapshot\n",
    "test_df = pd.read_csv('data/test_recipes.csv')\n",
    "\n",
    "# we make sure lists are parsed correctly\n",
    "train_df.labels = train_df.labels.apply(eval)\n",
    "test_df.labels = test_df.labels.apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c30d368-31a3-4ddd-92ad-4f1fc6a4edbb",
   "metadata": {},
   "source": [
    "Let's create label lookups for label to int and viceversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e053a2-d48d-448f-aee4-5ab477bcf0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {label:i for i,label in enumerate(LABELS)} ; \n",
    "id2label = {i:l for l,i in label2id.items()} ; (id2label, label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5718a3-93df-40cb-952e-55c0d2a5f3d2",
   "metadata": {},
   "source": [
    "The following function turns our DataFrame into numerical arrays for node indices and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200e0b6-6ff7-4802-a664-a2cb39c53611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_indices_labels(df):\n",
    "    # turn our dense labels into a one-hot list\n",
    "    def one_hot(label_ids):\n",
    "        a = np.zeros(len(LABELS))\n",
    "        a.put(label_ids, np.ones(len(label_ids)))\n",
    "        return a\n",
    "    \n",
    "    indices, labels = [], []\n",
    "    for uri, label in zip(df.uri.tolist(), df.labels.tolist()):\n",
    "        indices.append(sg.transform(uri))\n",
    "        labels.append(one_hot([label2id[label] for label in label]))\n",
    "    return indices, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc443d7-6c1b-4d53-b6ea-aee0d5545829",
   "metadata": {},
   "source": [
    "Finally, let's turn our dataset into PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ca453-289a-4eb6-a319-b4d80dd63f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, train_labels = create_indices_labels(train_df)\n",
    "test_indices, test_labels = create_indices_labels(test_df)\n",
    "\n",
    "train_idx = torch.tensor(train_indices, dtype=torch.long)\n",
    "train_y = torch.tensor(train_labels, dtype=torch.float)\n",
    "\n",
    "test_idx = torch.tensor(test_indices, dtype=torch.long)\n",
    "test_y = torch.tensor(test_labels, dtype=torch.float) ; train_idx[:10], train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8d2998-7b0c-459d-83b9-0932d6fb5d48",
   "metadata": {},
   "source": [
    "Let's see if we can recover the correct URIs for our numerical ids using our `kglab.Subgraph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0218b01-cc5e-4711-b989-d2eda5cf7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_df.loc[0], sg.inverse_transform(17910))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940ed1f-0a1b-471e-8fb0-87b92e568bab",
   "metadata": {},
   "source": [
    "## 4. Creating a Subgraph of recipe and ingredient nodes\n",
    "Here we create a node list to be used as a seed for building our `PyG` subgraph (using k-hops as we will see in the next section). The reason is that we do not want to encode all nodes in the graph (such as literals, durations, etc.). Our goal would be to encode only `recipes` and `ingredients`, as all nodes passed through the GNN will be classified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc573f1-cbfe-4f3e-8ec6-4a9b676410bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = torch.LongTensor([\n",
    "    sg.transform(i) for i in ing_recipes_df.uri.values\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392229e0-d5c2-49e7-ad6e-0badce1ef257",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx.max(), node_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a843b-ef2a-426c-b269-74bbcfe5f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ing_recipes_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17207f40-ca5f-4ba4-8864-ae81a61eff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.inverse_transform(node_idx[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d289603-a877-4d34-bddd-0905592cec59",
   "metadata": {},
   "source": [
    "## 5. Semi-supervised node classification with PyTorch Geometric\n",
    "\n",
    "\n",
    "### Graph Convolutional Networks\n",
    "\n",
    "\n",
    "### PyTorch Geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dec11b-640e-4145-acec-0acd14c1a051",
   "metadata": {},
   "source": [
    "### Creating a `PyG` subgraph\n",
    "\n",
    "Here we build a subgraph with `k` hops from target to source starting with all `recipe` and `ingredient` nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426a472-1680-4932-9ba7-216f35e5f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import k_hop_subgraph\n",
    "# here we take all connected nodes with k hops\n",
    "k = 1\n",
    "node_idx, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "    node_idx, \n",
    "    k, \n",
    "    data.edge_index, \n",
    "    relabel_nodes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602bbf87-ba80-4034-85ff-4ab60b0f44d8",
   "metadata": {},
   "source": [
    "We have increased the size of our node set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5c84c-d903-499b-9b2d-7de679c3fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc2cfec-8b3a-4500-b698-283496635664",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d56575-e6dd-42a4-8308-c6ce5e7f9d77",
   "metadata": {},
   "source": [
    "Here we compute some measures needed for defining the size of our layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f8f570-482a-4b2e-8d33-35c60ff116bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index = edge_index\n",
    "\n",
    "data.num_nodes = data.edge_index.max().item() + 1\n",
    "\n",
    "data.num_relations = data.edge_type.max().item() + 1\n",
    "\n",
    "data.edge_type = data.edge_type[edge_mask]\n",
    "\n",
    "data.num_classes = len(LABELS)\n",
    "\n",
    "data.num_nodes, data.num_relations, data.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803debb-cc19-49d2-81d6-1e1f5a591e90",
   "metadata": {},
   "source": [
    "### Defining a basic Relational Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053de53-5cfd-4265-9877-aad8856d10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import FastRGCNConv, RGCNConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bec31-1bd5-4322-b978-6e0a276187cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGCNConv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab70603-2352-4d59-8130-fe951258e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, num_relations, num_classes, out_channels=16, num_bases=30, dropout=0.0, layer_type=FastRGCNConv, ):\n",
    "        \n",
    "        super(RGCN, self).__init__()\n",
    "        \n",
    "        self.conv1 = layer_type(\n",
    "            num_nodes, \n",
    "            out_channels, \n",
    "            num_relations, \n",
    "            num_bases=num_bases\n",
    "        )\n",
    "        self.conv2 = layer_type(\n",
    "            out_channels, \n",
    "            num_classes, \n",
    "            num_relations, \n",
    "            num_bases=num_bases\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = F.relu(self.conv1(None, edge_index, edge_type))\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a89c23-2753-4f3d-b9b7-c17258b1d0cb",
   "metadata": {},
   "source": [
    "### Create our model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a393b6-0598-4fab-8686-2e5c060b2ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    num_relations=data.num_relations,\n",
    "    num_classes=data.num_classes,\n",
    "    #out_channels=64,\n",
    "    dropout=0.2,\n",
    "    layer_type=RGCNConv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca05b45-7ee2-4ebe-b3b4-3eef23244aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu') # ('cuda')\n",
    "data = data.to(device)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters()) # lr=0.05, weight_decay=0.005\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7894dcd-ff92-4648-9fed-39ca45203633",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_module = torch.nn.BCELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.edge_index, data.edge_type)\n",
    "    loss = loss_module(out[train_idx], train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def accuracy(predictions, y):\n",
    "    predictions = np.round(predictions)\n",
    "    return predictions.eq(y).to(torch.float).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred = model(data.edge_index, data.edge_type)\n",
    "    train_acc = accuracy(pred[train_idx], train_y)\n",
    "    test_acc = accuracy(pred[test_idx], test_y)\n",
    "    return train_acc.item(), test_acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30f759-6d20-419c-b2e1-6ee1c47d4d82",
   "metadata": {},
   "source": [
    "### Training our RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20cbf4d-2b1a-47b6-aa9f-0c9f507a5b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, 50):\n",
    "    loss = train()\n",
    "    train_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {train_acc:.4f} '\n",
    "          f'Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a40799a-7a63-4873-9ea6-d70d688dd98c",
   "metadata": {},
   "source": [
    "## 6. Using our model and analyzing its predictions with Rubrix\n",
    "Let's see the shape of our model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7b799-f3ff-4ad7-a02e-bca79aa275b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(edge_index, edge_type) ; pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de11194-2992-436a-b94d-0d15fc600f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(tensor, values):\n",
    "    return torch.nonzero(tensor[..., None] == values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20e3725-1dbf-4b3c-9fd2-de2a0d212868",
   "metadata": {},
   "source": [
    "### Analizing predictions over the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd064a2-2a57-45ea-a92e-838c774f6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = find(node_idx,test_idx)[:,0] ; len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d9a2f-8ddd-4127-b432-e9b82e83f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = torch.zeros(node_idx.shape[0], dtype=bool)\n",
    "index[test_idx] = True\n",
    "idx = node_idx[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d0694-4aad-40c0-9437-03342481dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "uris = [sg.inverse_transform(i) for i in idx]\n",
    "predicted_labels = [l for l in pred[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c8a79b-e4e2-43fa-9de7-4157a7eadd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(zip(uris,predicted_labels)) ; predictions[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0752d2d1-3fb4-41e0-b3ec-474ce36bfd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "records = []\n",
    "for uri,predicted_labels in predictions:\n",
    "    ids = ing_recipes_df.index[ing_recipes_df.uri == uri]\n",
    "    if len(ids) > 0:\n",
    "        r = ing_recipes_df.iloc[ids]\n",
    "        # get the gold labels from our test set\n",
    "        gold_labels = test_df.iloc[test_df.index[test_df.uri == uri]].labels.values[0]\n",
    "        item = rb.TextClassificationRecord(\n",
    "                inputs={\"id\":r.uri.values[0], \"definition\": r.definition.values[0], \"ingredients\": str(r.ingredients.values[0]), \"type\": r.type.values[0]}, \n",
    "                prediction=[(id2label[i], score) for i,score in enumerate(predicted_labels)],\n",
    "                annotation=gold_labels,\n",
    "                metadata={'ingredients': r.ingredients.values[0], \"type\": r.type.values[0]}, \n",
    "                prediction_agent=\"node_classifier_v1\", \n",
    "                multi_label=True\n",
    "        )\n",
    "        records.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c7c19-fca5-44ba-8ff1-ebf2134115ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.log(records, name=\"kg_node_classification_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e2c685-1cf3-457d-93ad-0f52ea6c0931",
   "metadata": {},
   "source": [
    "### Analizing predictions over unseen nodes (and potentially relabeling them)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9b3224-a053-44f8-a4c1-cc5480fbde9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's find the ids for the nodes in our training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0cbeb-4beb-49ff-a711-48ed78c14071",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_idx = find(node_idx,torch.cat((test_idx, train_idx)))[:,0] ; len(train_test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d9066-f29f-40a1-9ae8-1352e6330a53",
   "metadata": {},
   "source": [
    "Let's get the ids, uris and labels of the nodes which were not in our train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42711958-2a38-4329-a6dd-7577ba331935",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = torch.ones(node_idx.shape[0], dtype=bool)\n",
    "index[train_test_idx] = False\n",
    "idx = node_idx[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c67fdad-eebf-431f-b01e-d8e73009ba22",
   "metadata": {
    "tags": []
   },
   "source": [
    "We use our `SubgraphTensor` for getting back our URIs and build `uri,predicted_labels` pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd831e59-bd9f-4e84-b639-e28bd45ef050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uris = [sg.inverse_transform(i) for i in idx]\n",
    "predicted_labels = [l for l in pred[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9eecbd-61a7-4044-80de-f919ae665f0b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = list(zip(uris,predicted_labels)) ; predictions[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc018ca-80e6-4f9b-8119-0af06e6a4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "records = []\n",
    "for uri,predicted_labels in predictions:\n",
    "    ids = ing_recipes_df.index[ing_recipes_df.uri == uri]\n",
    "    if len(ids) > 0:\n",
    "        r = ing_recipes_df.iloc[ids]\n",
    "        item = rb.TextClassificationRecord(\n",
    "                inputs={\"id\":r.uri.values[0], \"definition\": r.definition.values[0], \"ingredients\": str(r.ingredients.values[0]), \"type\": r.type.values[0]}, \n",
    "                prediction=[(id2label[i], score) for i,score in enumerate(predicted_labels)], \n",
    "                metadata={'ingredients': r.ingredients.values[0], \"type\": r.type.values[0]}, \n",
    "                prediction_agent=\"node_classifier_v1\", \n",
    "                multi_label=True\n",
    "        )\n",
    "        records.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e1a44-4e99-4d30-bbba-24098a7230c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.log(records, name=\"kg_node_classification_unseen_nodes_v3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cb6772-b513-4cc7-9585-ce9428605d1f",
   "metadata": {},
   "source": [
    "## Exercise 1: Training experiments with PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a3722-1b9a-4b28-b083-5f22be533219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wandb -qqq # optional\n",
    "!pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae9d36-045a-4621-93a3-915e365f5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login #optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd26a5-b17a-4a30-a2d3-9452777a30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "data.train_idx = train_idx\n",
    "data.train_y = train_y\n",
    "data.test_idx = test_idx\n",
    "data.test_y = test_y\n",
    "\n",
    "dataloader = DataLoader([data], batch_size=1); dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d8575-5887-4293-92a2-2d66eb119850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "class RGCNNodeClassification(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = RGCN(**model_kwargs)\n",
    "        self.loss_module = torch.nn.BCELoss()\n",
    "    \n",
    "    def forward(self, edge_index, edge_type):\n",
    "        return self.model(edge_index, edge_type)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=0.001)\n",
    "        return optimizer\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        idx, y = data.train_idx, data.train_y\n",
    "        edge_index, edge_type = data.edge_index, data.edge_type\n",
    "        x = self.forward(edge_index, edge_type)\n",
    "        loss = self.loss_module(x[idx], y)\n",
    "        x = x.detach()\n",
    "        self.log('train_acc', accuracy(x[idx], y), prog_bar=True)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss \n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        idx, y = data.test_idx, data.test_y\n",
    "        edge_index, edge_type = data.edge_index, data.edge_type\n",
    "        x = self.forward(edge_index, edge_type)\n",
    "        loss = self.loss_module(x[idx], y)\n",
    "        x = x.detach()\n",
    "        self.log('val_acc', accuracy(x[idx], y), prog_bar=True)\n",
    "        self.log('val_loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1eea0-2de6-45b3-a04b-d93f523fa7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96158253-9b32-4eed-9abd-be5b6402b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pl = RGCNNodeClassification(\n",
    "    num_nodes=data.num_nodes,\n",
    "    num_relations=data.num_relations,\n",
    "    num_classes=data.num_classes,\n",
    "    #out_channels=64,\n",
    "    dropout=0.2,\n",
    "    layer_type=RGCNConv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d0c33-adc2-4c8b-bc9e-8555a22a3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f68524-b4d3-49af-9fe7-b95e109fc4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    default_root_dir='pl_runs',\n",
    "    checkpoint_callback=ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n",
    "    max_epochs=200,\n",
    "    #logger= WandbLogger(), # optional\n",
    "    callbacks=[earlystopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7415e9-736f-4536-b60c-3717f741ac8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(model_pl, dataloader, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b092f3-34ac-4890-b752-a73e89e7da16",
   "metadata": {},
   "source": [
    "## Exercise 2: Bootstrapping annotation with a zeroshot-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d97db4-ab74-4ea3-be17-46c9a6e84f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "322f5aa8-635d-4be7-a8ee-fff65d4a80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "  \n",
    "pretrained_model =  \"valhalla/distilbart-mnli-12-1\" # \"typeform/squeezebert-mnli\"\n",
    "\n",
    "pl = pipeline('zero-shot-classification', model=pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1371af0-ae0a-4814-996b-beeb76455a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'chocolate cake',\n",
       " 'labels': ['Sweet', 'Piquant', 'Bitter', 'Salty', 'Meaty', 'Sour'],\n",
       " 'scores': [0.6839402914047241,\n",
       "  0.02114126645028591,\n",
       "  0.0025301866699010134,\n",
       "  0.001267178449779749,\n",
       "  0.0004893316072411835,\n",
       "  0.00013206301082391292]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl(\"chocolate cake\", LABELS, hypothesis_template='The flavour is {}.',multi_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15e239-fc32-491b-8c58-5f34505bb563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "records = []\n",
    "for i, r in ing_recipes_df.iterrows():\n",
    "    item = rb.TextClassificationRecord(\n",
    "            inputs={\n",
    "                \"id\":r.uri, \n",
    "                \"definition\": r.definition,\n",
    "                \"ingredients\": str(r.ingredients), \n",
    "                \"type\": r.type\n",
    "            }, \n",
    "            prediction= # TODO: here we log he predictions of our zeroshot pipeline as a list of tuples (label, score)\n",
    "            metadata={'ingredients': r.ingredients, \"type\": r.type}, \n",
    "            prediction_agent=\"valhalla/distilbart-mnli-12-1\", \n",
    "            multi_label=True\n",
    "        )\n",
    "    records.append(item)\n",
    "rb.log(records=records, name=\"kg_classification_tutorial_zeroshot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
