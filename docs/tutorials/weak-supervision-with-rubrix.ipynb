{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a77a750-072d-4dae-afb8-d725e21be584",
   "metadata": {},
   "source": [
    "# üì∞ Building a news classifier with weak supervision\n",
    "\n",
    "## TL;DR\n",
    "\n",
    "1. We build a news classifier using rules and weak supervision\n",
    "2. For this example, we use the AG News dataset but you can follow this process to programatically label any dataset.\n",
    "3. The train split without labels is used to build a training set with rules, Rubrix and Snorkel's Label model.\n",
    "4. The test set is used for evaluating our weak labels, label model and downstream news classifier.\n",
    "5. We achieve 0.81 macro avg. f1-score without using a single example from the original dataset and using a pretty lightweight model (scikit-learn's `MultinomialNB`).\n",
    "\n",
    "The following diagram shows the overall process for using Weak supervision with Rubrix:\n",
    "\n",
    "![Labeling workflow](https://raw.githubusercontent.com/recognai/rubrix-materials/main/tutorials/weak_supervision/weak_supervision.svg \"Labeling workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e851ab7-eaea-4548-a2eb-6d762cce41c1",
   "metadata": {},
   "source": [
    "## Setup Rubrix\n",
    "\n",
    "Rubrix, is a free and open-source tool to explore, annotate, and monitor data for NLP projects.\n",
    "\n",
    "If you are new to Rubrix, check out the ‚≠ê [Github repository](https://github.com/recognai/rubrix).\n",
    "\n",
    "You can install Rubrix on your local machine, on a server, or using a cloud provider. If you have not installed and launched Rubrix, check the [Setup and Installation guide](../getting_started/setup&installation.rst).\n",
    "\n",
    "Once installed, you only need to import Rubrix and some other libraries we'll be using for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cefabae-cc6e-4ac8-a749-e1f61c8e8c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "from rubrix.labeling.text_classification import *\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ef86e-26e1-4cdc-b05b-60605bf13e25",
   "metadata": {},
   "source": [
    "## 1. Load test and unlabelled datasets into Rubrix\n",
    "\n",
    "\n",
    "Let's load the test split from the `ag_news` dataset, which we'll be using for testing our label and downstream models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f033bb-a731-47b5-abcb-d9ea913b20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ag_news\", split=\"test\")\n",
    "\n",
    "labels = dataset.features[\"label\"].names\n",
    "\n",
    "records = [\n",
    "    rb.TextClassificationRecord(\n",
    "        inputs=record[\"text\"],\n",
    "        metadata={\"split\": \"test\"},\n",
    "        annotation=labels[record[\"label\"]]\n",
    "    )\n",
    "    for record in dataset\n",
    "]\n",
    "\n",
    "rb.log(records, name=\"news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57bf497-2a75-4c79-9487-b3a84602bbea",
   "metadata": {},
   "source": [
    "Let's load the train split from the `ag_news` dataset without labels. Our goal will be to programmatically build a training set using rules and weak supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d06c80-bb41-4668-ad07-d96da8e4b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ag_news\", split=\"train\")\n",
    "\n",
    "records = [\n",
    "    rb.TextClassificationRecord(\n",
    "        inputs=record[\"text\"],\n",
    "        metadata={\"split\": \"unlabelled\"},\n",
    "    )\n",
    "    for record in dataset\n",
    "]\n",
    "\n",
    "rb.log(records, name=\"news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b943c5e-2a5d-40b5-9805-7fd78e5161a3",
   "metadata": {},
   "source": [
    "The result of the above is the following dataset in Rubrix with 127.600 records (120.000 unlabelled and 7.600 for testing). \n",
    "\n",
    "You can use the webapp for finding good rules for programmatic labeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a7255c-9f67-483c-b253-f186df8286cf",
   "metadata": {},
   "source": [
    "![News dataste](img/news_tutorial.gif \"Snorkel exploration with Rubrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1616037-9a0a-4dd9-b187-d14f9d0bfa7d",
   "metadata": {},
   "source": [
    "## 2. Create rules and weak labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3043489a-82b3-4409-b809-a9791e2094e6",
   "metadata": {},
   "source": [
    "Let's define some rules for each category, here you can use the expressive power of Elasticsearch's query string DSL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a60722-45af-495e-9b93-613483a41441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define queries and patterns for each category (using ES DSL)\n",
    "queries = [\n",
    "  ([\"money\", \"financ*\", \"dollar*\"], \"Business\"),\n",
    "  ([\"war\", \"gov*\", \"minister*\", \"conflict\"], \"World\"),\n",
    "  ([\"footbal*\", \"sport*\", \"game\", \"play*\"], \"Sports\"),\n",
    "  ([\"sci*\", \"techno*\", \"computer*\", \"software\", \"web\"], \"Sci/Tech\")\n",
    "] \n",
    "\n",
    "rules = [\n",
    "    Rule(query=term, label=label)\n",
    "    for terms,label in queries\n",
    "    for term in terms\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbddd64f-9c78-48fd-bca5-9046cbf8842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_labels = WeakLabels(\n",
    "    rules=rules, \n",
    "    dataset=\"news\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a9e96-3191-446b-a29d-3a5003a18c4b",
   "metadata": {},
   "source": [
    "It takes around 24 seconds to apply the rules and get the weak labels for the 127.600 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99815bcd-9bc7-416e-bff8-a8871fb0fcb9",
   "metadata": {},
   "source": [
    "Typically, you want to iterate on the rules and check their statistics. For this, you can use `weak_labels.summary` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3219d7f3-950d-45b3-a31e-0d3622f7feeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>coverage</th>\n",
       "      <th>overlaps</th>\n",
       "      <th>conflicts</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>{Business}</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>0.447761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financ*</th>\n",
       "      <td>{Business}</td>\n",
       "      <td>0.019655</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>80</td>\n",
       "      <td>55</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dollar*</th>\n",
       "      <td>{Business}</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>87</td>\n",
       "      <td>37</td>\n",
       "      <td>0.701613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>war</th>\n",
       "      <td>{World}</td>\n",
       "      <td>0.011779</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>75</td>\n",
       "      <td>26</td>\n",
       "      <td>0.742574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gov*</th>\n",
       "      <td>{World}</td>\n",
       "      <td>0.045078</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>170</td>\n",
       "      <td>174</td>\n",
       "      <td>0.494186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minister*</th>\n",
       "      <td>{World}</td>\n",
       "      <td>0.030031</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>193</td>\n",
       "      <td>22</td>\n",
       "      <td>0.897674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conflict</th>\n",
       "      <td>{World}</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>footbal*</th>\n",
       "      <td>{Sports}</td>\n",
       "      <td>0.013166</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>107</td>\n",
       "      <td>7</td>\n",
       "      <td>0.938596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport*</th>\n",
       "      <td>{Sports}</td>\n",
       "      <td>0.021191</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>139</td>\n",
       "      <td>23</td>\n",
       "      <td>0.858025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game</th>\n",
       "      <td>{Sports}</td>\n",
       "      <td>0.038879</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>216</td>\n",
       "      <td>71</td>\n",
       "      <td>0.752613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play*</th>\n",
       "      <td>{Sports}</td>\n",
       "      <td>0.052453</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>268</td>\n",
       "      <td>112</td>\n",
       "      <td>0.705263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci*</th>\n",
       "      <td>{Sci/Tech}</td>\n",
       "      <td>0.016552</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>114</td>\n",
       "      <td>26</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techno*</th>\n",
       "      <td>{Sci/Tech}</td>\n",
       "      <td>0.027218</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>155</td>\n",
       "      <td>60</td>\n",
       "      <td>0.720930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer*</th>\n",
       "      <td>{Sci/Tech}</td>\n",
       "      <td>0.027320</td>\n",
       "      <td>0.011058</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>159</td>\n",
       "      <td>54</td>\n",
       "      <td>0.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software</th>\n",
       "      <td>{Sci/Tech}</td>\n",
       "      <td>0.030243</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>184</td>\n",
       "      <td>41</td>\n",
       "      <td>0.817778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>{Sci/Tech}</td>\n",
       "      <td>0.015376</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>76</td>\n",
       "      <td>25</td>\n",
       "      <td>0.752475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>{Sci/Tech, Business, Sports, World}</td>\n",
       "      <td>0.317022</td>\n",
       "      <td>0.053582</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>2071</td>\n",
       "      <td>774</td>\n",
       "      <td>0.727944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      polarity  coverage  overlaps  conflicts  \\\n",
       "money                               {Business}  0.008276  0.002437   0.001936   \n",
       "financ*                             {Business}  0.019655  0.005893   0.005188   \n",
       "dollar*                             {Business}  0.016591  0.003542   0.002908   \n",
       "war                                    {World}  0.011779  0.003213   0.001348   \n",
       "gov*                                   {World}  0.045078  0.010878   0.006270   \n",
       "minister*                              {World}  0.030031  0.007531   0.002821   \n",
       "conflict                               {World}  0.003041  0.001003   0.000102   \n",
       "footbal*                              {Sports}  0.013166  0.004945   0.000439   \n",
       "sport*                                {Sports}  0.021191  0.007045   0.001223   \n",
       "game                                  {Sports}  0.038879  0.014083   0.002375   \n",
       "play*                                 {Sports}  0.052453  0.016889   0.005063   \n",
       "sci*                                {Sci/Tech}  0.016552  0.002735   0.001309   \n",
       "techno*                             {Sci/Tech}  0.027218  0.008433   0.003174   \n",
       "computer*                           {Sci/Tech}  0.027320  0.011058   0.004459   \n",
       "software                            {Sci/Tech}  0.030243  0.009655   0.003346   \n",
       "web                                 {Sci/Tech}  0.015376  0.004067   0.001607   \n",
       "total      {Sci/Tech, Business, Sports, World}  0.317022  0.053582   0.019561   \n",
       "\n",
       "           correct  incorrect  precision  \n",
       "money           30         37   0.447761  \n",
       "financ*         80         55   0.592593  \n",
       "dollar*         87         37   0.701613  \n",
       "war             75         26   0.742574  \n",
       "gov*           170        174   0.494186  \n",
       "minister*      193         22   0.897674  \n",
       "conflict        18          4   0.818182  \n",
       "footbal*       107          7   0.938596  \n",
       "sport*         139         23   0.858025  \n",
       "game           216         71   0.752613  \n",
       "play*          268        112   0.705263  \n",
       "sci*           114         26   0.814286  \n",
       "techno*        155         60   0.720930  \n",
       "computer*      159         54   0.746479  \n",
       "software       184         41   0.817778  \n",
       "web             76         25   0.752475  \n",
       "total         2071        774   0.727944  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weak_labels.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14b2745-d3d0-4b83-8131-dc299a638214",
   "metadata": {},
   "source": [
    "From the above, we see that our rules cover around **30% of the original training set** with an **average precision of 0.72**, our hope is that the label and downstream models will improve both the recall and the precision of the final classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23dc1c6-9e5f-455f-b8b9-0466a062eda5",
   "metadata": {},
   "source": [
    "## 3. Denoise weak labels with Snorkel's Label Model\n",
    "\n",
    "The goal at this step is to denoise the weak labels we've just created using rules. There are several approaches to this problem using different statistical methods.\n",
    "\n",
    "In this tutorial, we're going to use Snorkel but you can actually use any other Label model or weak supervision method (see the [Weak supervision guide](../guides/weak-supervision.ipynb) for more details).\n",
    "\n",
    "For convenience, Rubrix defines a simple wrapper over Snorkel's Label Model so it's easier to use with Rubrix weak labels and datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27f7820-0144-4827-86b6-08f1fd190334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rubrix.labeling.text_classification.label_models:Metrics are only calculated over non-abstained predictions!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7448246725813266}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If Snorkel is not installed on your machine !pip install snorkel\n",
    "\n",
    "label_model = Snorkel(weak_labels)\n",
    "\n",
    "# Fit Label Model\n",
    "label_model.fit()\n",
    "\n",
    "# Test with labeled test set\n",
    "label_model.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c5862-903b-48c4-bf34-233a2430b2a7",
   "metadata": {},
   "source": [
    "## 3. Prepare our training set\n",
    "\n",
    "Now, we already have a \"denoised\" training set, which we can prepare for training a downstream model.\n",
    "\n",
    "The label model predict returns `TextClassificationRecord` objects with the `predictions` from the label model. \n",
    "\n",
    "We can either refine and review these records using the Rubrix Webapp, use them as is, or filter them by score for example.\n",
    "\n",
    "In this case, we assume the predictions are precise enough and use them without any revision.\n",
    "\n",
    "Our training set has ~38.000 records, which corresponds to all records where the label model has not abstained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c321871-3bfc-45b9-902b-4beb45f4ca13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan Baan launches Web services firm com Septem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Molson Indy Vancouver gets black flag  quot;Th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The football gods were on our side #39; Jason ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jags get offense clicking in second half Fred ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puzzle Over Low Galaxy Count Scientists from t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38080</th>\n",
       "      <td>Football legend Maradona rushed to hospital Fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38081</th>\n",
       "      <td>Head of British charity expelled from Sudan Th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38082</th>\n",
       "      <td>From SANs to SATAs, storage vendors continue p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38083</th>\n",
       "      <td>Billups Sits Out Because of Ankle Sprain (AP) ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38084</th>\n",
       "      <td>Judge Rules for Oracle in PeopleSoft Bid (Reut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38085 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Jan Baan launches Web services firm com Septem...      0\n",
       "1      Molson Indy Vancouver gets black flag  quot;Th...      1\n",
       "2      The football gods were on our side #39; Jason ...      1\n",
       "3      Jags get offense clicking in second half Fred ...      1\n",
       "4      Puzzle Over Low Galaxy Count Scientists from t...      0\n",
       "...                                                  ...    ...\n",
       "38080  Football legend Maradona rushed to hospital Fo...      1\n",
       "38081  Head of British charity expelled from Sudan Th...      3\n",
       "38082  From SANs to SATAs, storage vendors continue p...      0\n",
       "38083  Billups Sits Out Because of Ankle Sprain (AP) ...      1\n",
       "38084  Judge Rules for Oracle in PeopleSoft Bid (Reut...      0\n",
       "\n",
       "[38085 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = label_model.predict()\n",
    "\n",
    "# build a simple dataframe with text and the prediction with the highest score\n",
    "df_train = pd.DataFrame([\n",
    "    {\"text\": record.inputs[\"text\"], \"label\": label_model.weak_labels.label2int[record.prediction[0][0]]}\n",
    "    for record in records\n",
    "])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db0c41f9-bde8-4bc8-8406-a048e2e73aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the test set, we can retrieve the records with validated annotations (the original ag_news test set)\n",
    "df_test = rb.load(\"news\", query=\"status:Validated\")\n",
    "\n",
    "df_test['text'] = df_test.inputs.transform(lambda r: r['text'])\n",
    "df_test['annotation'] = df_test['annotation'].apply(\n",
    "    lambda r:label_model.weak_labels.label2int[r]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e6b973-fab5-43d0-994c-591b99835f90",
   "metadata": {},
   "source": [
    "## 4. Train a downstream model with scikit-learn\n",
    "\n",
    "Now, let's train our final model using `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e1aa9-68c9-4a65-bf52-ff5254cdd9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "classifier = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "classifier.fit(\n",
    "    X=df_train.text.tolist(), \n",
    "    y=df_train.label.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aac5b5ae-7c0d-48d6-800c-d95934b3d03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test accuracy: 0.8177631578947369'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = classifier.score(\n",
    "    X=df_test.text.tolist(), \n",
    "    y=label_model.weak_labels.annotation()\n",
    ")\n",
    "\n",
    "f\"Test accuracy: {accuracy}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24b07b-dd15-4362-a88c-d3611748736e",
   "metadata": {},
   "source": [
    "Not too bad! \n",
    "\n",
    "We have achieved around **0.81 accuracy** without even using a single example from the original `ag_news` train set and with a small set of rules (less than 30). Also, we've largely improved over the 0.74 accuracy of our Label Model.\n",
    "\n",
    "Finally, let's take a look at more detailed metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "609f169a-30ed-480e-8ab8-ae5af2c0a84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Sci/Tech       0.76      0.83      0.80      1900\n",
      "      Sports       0.86      0.98      0.91      1900\n",
      "    Business       0.89      0.56      0.69      1900\n",
      "       World       0.79      0.89      0.84      1900\n",
      "\n",
      "    accuracy                           0.82      7600\n",
      "   macro avg       0.82      0.82      0.81      7600\n",
      "weighted avg       0.82      0.82      0.81      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "labels = list(label_model.weak_labels.label2int.keys())[1:] # removes \"abstain\" label\n",
    "predicted = classifier.predict(df_test.text.tolist())\n",
    "\n",
    "print(metrics.classification_report(label_model.weak_labels.annotation(), predicted, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b8ffd-4918-462d-88b5-a6a60f7e9a4b",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "If you are interested in the topic of weak supervision check the [Weak supervision guide](../guides/weak-supervision.ipynb).\n",
    "\n",
    "### üìö [Rubrix documentation](https://docs.rubrix.ml) for more guides and tutorials.\n",
    "\n",
    "### üôã‚Äç‚ôÄÔ∏è Join the Rubrix community on [Slack](https://bit.ly/3o0Pfyk)\n",
    "\n",
    "### ‚≠ê Rubrix [Github repo](https://github.com/recognai/rubrix) to stay updated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
