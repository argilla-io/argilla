{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíæ  Monitor predictions in HTTP API endpoints\n",
    "\n",
    "In this tutorial, you'll learn to monitor the predictions of a FastAPI inference endpoint\n",
    "and log model predictions in a Rubrix dataset. \n",
    "\n",
    "\n",
    "This tutorial walks you through 4 basic steps:\n",
    "\n",
    "- üíæ Load the model you want to use.\n",
    "- üîÑ Convert model output to Rubrix format.\n",
    "- üíª Create a FastAPI endpoint.\n",
    "- ü§ñ Add middleware to automate logging to Rubrix\n",
    "\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "<img src=\"./img/automatic_fastapi_log/transformers_demo.gif\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\"/>\n",
    "<br><br>\n",
    "<img src=\"./img/automatic_fastapi_log/spacy_demo.gif\" alt=\"spaCy Log Demo\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Rubrix\n",
    "\n",
    "Rubrix, is a free and open-source tool to explore, annotate, and monitor data for NLP projects.\n",
    "\n",
    "If you are new to Rubrix, check out the ‚≠ê [Github repository](https://github.com/recognai/rubrix).\n",
    "\n",
    "If you have not installed and launched Rubrix, check the [Setup and Installation guide](../getting_started/setup&installation.rst).\n",
    "\n",
    "Once installed, you only need to import Rubrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install tutorial dependencies\n",
    "\n",
    "Apart from Rubrix, we'll need the following libraries:\n",
    " - `transformers`\n",
    " - `spaCy`\n",
    " - `uvicorn`\n",
    " - `FastAPI`\n",
    "\n",
    "And the following models:\n",
    " - `distilbert-base-uncased-finetuned-sst-2-english` : a sentiment-analysis model\n",
    " - `en_core_web_sm` : spaCy's trained pipeline for English\n",
    "\n",
    "To install all requirements, run the following commands :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy\n",
    "!pip install spacy\n",
    "# spaCy pipeline\n",
    "!python -m spacy download en_core_web_sm\n",
    "# FastAPI\n",
    "!pip install fastapi\n",
    "# transformers\n",
    "!pip install transformers\n",
    "# uvicorn\n",
    "!pip install uvicorn[standard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformer's pipeline will be downloaded in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models\n",
    "\n",
    "Let's get and load our model pretrained pipeline and apply it to one of our dataset records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import spacy\n",
    "\n",
    "transformers_pipeline = pipeline(\"sentiment-analysis\", return_all_scores=True)\n",
    "spacy_pipeline = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more informations about using the `transformers` library with Rubrix, check the tutorial [How to label your data and fine-tune a ü§ó sentiment classifier](01-labeling-finetuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model output\n",
    "Let's try the transformer's pipeline in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "batch = ['I really like rubrix!']\n",
    "predictions = transformers_pipeline(batch)\n",
    "pprint(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the `predictions` is a list containing lists of two elements : \n",
    "- The first dictionnary containing the `NEGATIVE` sentiment label and its score.\n",
    "- The second dictionnary containing the same data but for `POSITIVE` sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert output to Rubrix format\n",
    "To log the output to rubrix we should supply a list of dictionnaries, each dictonnary containing two keys:\n",
    "- `labels` : value is a list of strings, each string being the label of the sentiment.\n",
    "- `scores` : value is a list of floats, each float being the probability of the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubrix_format = [\n",
    "    {\n",
    "        \"labels\": [p[\"label\"] for p in prediction],\n",
    "        \"scores\": [p[\"score\"] for p in prediction],\n",
    "    }\n",
    "    for prediction in predictions\n",
    "]\n",
    "pprint(rubrix_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prediction endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from typing import List\n",
    "\n",
    "app_transformers = FastAPI()\n",
    "\n",
    "# prediction endpoint using transformers pipeline\n",
    "@app_transformers.post(\"/\")\n",
    "def predict_transformers(batch: List[str]):\n",
    "    predictions = transformers_pipeline(batch)\n",
    "    return [\n",
    "        {\n",
    "            \"labels\": [p[\"label\"] for p in prediction],\n",
    "            \"scores\": [p[\"score\"] for p in prediction],\n",
    "        }\n",
    "        for prediction in predictions\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Rubrix logging middleware to the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubrix.monitoring.asgi import RubrixLogHTTPMiddleware\n",
    "\n",
    "app_transformers.add_middleware(\n",
    "    RubrixLogHTTPMiddleware,\n",
    "    api_endpoint=\"/transformers/\", #the endpoint that will be logged\n",
    "    dataset=\"monitoring_transformers\", #your dataset name\n",
    "    # you could post-process the predict output with a custom record_mapper function\n",
    "    # record_mapper=custom_text_classification_mapper,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the same for spaCy\n",
    "We'll add a custom mapper to convert spaCy's output to `TokenClassificationRecord` format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "from rubrix.client.models import TokenClassificationRecord\n",
    "\n",
    "def custom_mapper(inputs, outputs):\n",
    "\tspaces_regex = re.compile(r\"\\s+\")\n",
    "\ttext = inputs\n",
    "\treturn TokenClassificationRecord(\n",
    "\t\ttext=text,\n",
    "\t\ttokens=spaces_regex.split(text),\n",
    "\t\tprediction=[\n",
    "\t\t\t(entity[\"label\"], entity[\"start\"], entity[\"end\"])\n",
    "\t\t\tfor entity in (\n",
    "\t\t\t\toutputs.get(\"entities\") if isinstance(outputs, dict) else outputs\n",
    "\t\t\t)\n",
    "\t\t],\n",
    "\t\tevent_timestamp=datetime.datetime.now(),\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastAPI application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_spacy = FastAPI()\n",
    "\n",
    "app_spacy.add_middleware(\n",
    "    RubrixLogHTTPMiddleware,\n",
    "    api_endpoint=\"/spacy/\",\n",
    "    dataset=\"monitoring_spacy\",\n",
    "    records_mapper=custom_mapper\n",
    ")\n",
    "\n",
    "# prediction endpoint using spacy pipeline\n",
    "@app_spacy.post(\"/\")\n",
    "def predict_spacy(batch: List[str]):\n",
    "    predictions = []\n",
    "    for text in batch:\n",
    "        doc = spacy_pipeline(text)  # spaCy Doc creation\n",
    "        # Entity annotations\n",
    "        entities = [\n",
    "            {\"label\": ent.label_, \"start\": ent.start_char, \"end\": ent.end_char}\n",
    "            for ent in doc.ents\n",
    "        ]\n",
    "\n",
    "        prediction = {\n",
    "            \"text\": text,\n",
    "            \"entities\": entities,\n",
    "        }\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\"message\": \"alive\"}\n",
    "\n",
    "app.mount(\"/transformers\", app_transformers)\n",
    "app.mount(\"/spacy\", app_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the appplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch the application, copy the whole code into a file named `main.py` and run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uvicorn main:app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/automatic_fastapi_log/transformers_demo.gif\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/automatic_fastapi_log/spacy_demo.gif\" alt=\"spaCy Log Demo\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this tutorial, we have learnt to automatically log model outputs into Rubrix, this can be used to continuosly and transparently monitor HTTP inference endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "### üìö [Rubrix documentation](https://docs.rubrix.ml) for more guides and tutorials.\n",
    "\n",
    "### üôã‚Äç‚ôÄÔ∏è Join the Rubrix community! A good place to start is the [discussion forum](https://github.com/recognai/rubrix/discussions).\n",
    "\n",
    "### ‚≠ê Rubrix [Github repo](https://github.com/recognai/rubrix) to stay updated."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
