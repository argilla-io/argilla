{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíæ Monitor predictions in HTTP API endpoints\n",
    "\n",
    "In this tutorial, you'll learn to monitor the predictions of a FastAPI inference endpoint\n",
    "and log model predictions in a Rubrix dataset. It will walk you through 4 basic steps:\n",
    "\n",
    "- üíæ Load the model you want to use.\n",
    "- üîÑ Convert model output to Rubrix format.\n",
    "- üíª Create a FastAPI endpoint.\n",
    "- ü§ñ Add middleware to automate logging to Rubrix\n",
    "\n",
    "<img src=\"../_static/tutorials/09-automatic_fastapi/transformers_demo.gif\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Models are often deployed via an HTTP API endpoint that is called by a client to obtain the model's predictions.\n",
    "With [FastAPI](https://fastapi.tiangolo.com/) and *Rubrix* you can easily monitor those predictions and log them to a *Rubrix* dataset.\n",
    "Due to its human-centric UX, *Rubrix* datasets can be comfortably viewed and explored by any team member of your organization.\n",
    "But *Rubrix* also provides automatically computed metrics, both of which help you to keep track of your predictor and spot potential issues early on. \n",
    "\n",
    "FastAPI and *Rubrix* allow you to deploy and monitor any model you like, but in this tutorial we will focus on the two most common frameworks in the NLP space: [spaCy](https://spacy.io/api/doc) and [transformers](https://huggingface.co/docs/transformers). Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Rubrix is a free and open-source tool to explore, annotate, and monitor data for NLP projects.\n",
    "\n",
    "If you are new to Rubrix, check out the ‚≠ê [Github repository](https://github.com/recognai/rubrix).\n",
    "\n",
    "If you have not installed and launched Rubrix yet, check the [Setup and Installation guide](../getting_started/setup&installation.rst).\n",
    "\n",
    "Apart from Rubrix, we'll need a few third party libraries that can be installed via pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fastapi uvicorn[standard] spacy transformers[torch] -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading models\n",
    "\n",
    "As a first step, let's load our models.\n",
    "For spacy we need to first download the model before we can instantiate a spacy pipeline with it.\n",
    "Here we use the small English model `en_core_web_sm`, but you can choose any available model on their [hub](https://spacy.io/usage/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_pipeline = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"text-classification\" pipeline by transformers download's the model for you and by default it will use the `distilbert-base-uncased-finetuned-sst-2-english` model.\n",
    "But you can instantiate the pipeline with any compatible model on their [hub](https://huggingface.co/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transformers_pipeline = pipeline(\"text-classification\", return_all_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about using the `transformers` library with Rubrix, check the tutorial [How to label your data and fine-tune a ü§ó sentiment classifier](01-labeling-finetuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model output\n",
    "Let's try the transformer's pipeline in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'NEGATIVE', 'score': 0.0003226407279726118},\n",
      "  {'label': 'POSITIVE', 'score': 0.9996774196624756}]]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "batch = ['I really like rubrix!']\n",
    "predictions = transformers_pipeline(batch)\n",
    "pprint(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the `predictions` is a list containing lists of two elements : \n",
    "- The first dictionary containing the `NEGATIVE` sentiment label and its score.\n",
    "- The second dictionary containing the same data but for `POSITIVE` sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert output to Rubrix format\n",
    "To log the output to Rubrix, we should supply a list of dictionaries, each dictionary containing two keys:\n",
    "- `labels` : value is a list of strings, each string being the label of the sentiment.\n",
    "- `scores` : value is a list of floats, each float being the probability of the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'labels': ['NEGATIVE', 'POSITIVE'],\n",
      "  'scores': [0.0003226407279726118, 0.9996774196624756]}]\n"
     ]
    }
   ],
   "source": [
    "rubrix_format = [\n",
    "    {\n",
    "        \"labels\": [p[\"label\"] for p in prediction],\n",
    "        \"scores\": [p[\"score\"] for p in prediction],\n",
    "    }\n",
    "    for prediction in predictions\n",
    "]\n",
    "pprint(rubrix_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create prediction endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from typing import List\n",
    "\n",
    "app_transformers = FastAPI()\n",
    "\n",
    "# prediction endpoint using transformers pipeline\n",
    "@app_transformers.post(\"/\")\n",
    "def predict_transformers(batch: List[str]):\n",
    "    predictions = transformers_pipeline(batch)\n",
    "    return [\n",
    "        {\n",
    "            \"labels\": [p[\"label\"] for p in prediction],\n",
    "            \"scores\": [p[\"score\"] for p in prediction],\n",
    "        }\n",
    "        for prediction in predictions\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add Rubrix logging middleware to the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubrix.monitoring.asgi import RubrixLogHTTPMiddleware\n",
    "\n",
    "app_transformers.add_middleware(\n",
    "    RubrixLogHTTPMiddleware,\n",
    "    api_endpoint=\"/transformers/\", #the endpoint that will be logged\n",
    "    dataset=\"monitoring_transformers\", #your dataset name\n",
    "    # you could post-process the predict output with a custom record_mapper function\n",
    "    # record_mapper=custom_text_classification_mapper,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Do the same for spaCy\n",
    "We'll add a custom mapper to convert spaCy's output to `TokenClassificationRecord` format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "from rubrix.client.models import TokenClassificationRecord\n",
    "\n",
    "def custom_mapper(inputs, outputs):\n",
    "    spaces_regex = re.compile(r\"\\s+\")\n",
    "    text = inputs\n",
    "    return TokenClassificationRecord(\n",
    "        text=text,\n",
    "        tokens=spaces_regex.split(text),\n",
    "        prediction=[\n",
    "            (entity[\"label\"], entity[\"start\"], entity[\"end\"])\n",
    "            for entity in (\n",
    "                outputs.get(\"entities\") if isinstance(outputs, dict) else outputs\n",
    "            )\n",
    "        ],\n",
    "        event_timestamp=datetime.datetime.now(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastAPI application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_spacy = FastAPI()\n",
    "\n",
    "app_spacy.add_middleware(\n",
    "    RubrixLogHTTPMiddleware,\n",
    "    api_endpoint=\"/spacy/\",\n",
    "    dataset=\"monitoring_spacy\",\n",
    "    records_mapper=custom_mapper\n",
    ")\n",
    "\n",
    "# prediction endpoint using spacy pipeline\n",
    "@app_spacy.post(\"/\")\n",
    "def predict_spacy(batch: List[str]):\n",
    "    predictions = []\n",
    "    for text in batch:\n",
    "        doc = spacy_pipeline(text)  # spaCy Doc creation\n",
    "        # Entity annotations\n",
    "        entities = [\n",
    "            {\"label\": ent.label_, \"start\": ent.start_char, \"end\": ent.end_char}\n",
    "            for ent in doc.ents\n",
    "        ]\n",
    "\n",
    "        prediction = {\n",
    "            \"text\": text,\n",
    "            \"entities\": entities,\n",
    "        }\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting it all together\n",
    "\n",
    "Now we can combine everything in order to see our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\"message\": \"alive\"}\n",
    "\n",
    "app.mount(\"/transformers\", app_transformers)\n",
    "app.mount(\"/spacy\", app_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch the application, copy the whole code into a file named `main.py` and run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uvicorn main:app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_static/tutorials/09-automatic_fastapi/transformers_demo.gif\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_static/tutorials/09-automatic_fastapi/spacy_demo.gif\" alt=\"spaCy Log Demo\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned to automatically log model outputs into Rubrix.\n",
    "This can be used to continuously and transparently monitor HTTP inference endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "‚≠ê Rubrix [Github repo](https://github.com/recognai/rubrix) to stay updated.\n",
    "\n",
    "üìö [Rubrix documentation](https://docs.rubrix.ml) for more guides and tutorials.\n",
    "\n",
    "üôã‚Äç‚ôÄÔ∏è Join the Rubrix community! A good place to start is the [discussion forum](https://github.com/recognai/rubrix/discussions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
