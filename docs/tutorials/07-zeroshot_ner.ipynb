{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44dca393-21cf-420c-a96c-3d08e2c17bea",
   "metadata": {},
   "source": [
    "# üî´ Zero-shot Named Entity Recognition with Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f188f15e-7922-4aee-b4a3-ff003d49dc86",
   "metadata": {},
   "source": [
    "## **TL;DR**: \n",
    "\n",
    "You can use Rubrix for analizing and validating the NER predictions from the new zero-shot model provided by the Flair NLP library. \n",
    "\n",
    "This is useful for quickly bootstrapping a training set (using Rubrix [*Annotation Mode*](../reference/rubrix_webapp_reference.rst#annotation-mode)) as well as integrating with weak-supervision workflows.\n",
    "\n",
    "![wnut zeroshot explore](https://github.com/recognai/rubrix-materials/raw/main/tutorials/zeroshot_ner/zeroshot_ner.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd782999-9234-4077-a28b-64a434ba6712",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52afc25f-24cd-4edb-a1dc-46776bf3886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets flair -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b710019-983d-43a4-84f6-7f8210b8cb48",
   "metadata": {},
   "source": [
    "## Setup Rubrix\n",
    "\n",
    "Rubrix, is a free and open-source tool to explore, annotate, and monitor data for NLP projects.\n",
    "\n",
    "If you are new to Rubrix, check out the [Github repository](https://github.com/recognai/rubrix) ‚≠ê.\n",
    "\n",
    "If you have not installed and launched Rubrix, check the [Setup and Installation guide](../getting_started/setup&installation.rst).\n",
    "\n",
    "Once installed, you only need to import Rubrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001a5472-b250-462d-8e0d-eafbe7f33f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc0dc5c-b925-4b77-85ac-1fab6f8c0994",
   "metadata": {},
   "source": [
    "## Load the `wnut_17` dataset\n",
    "\n",
    "In this example, we'll use a challenging NER dataset, the \"WNUT 17: Emerging and Rare entity recognition\" dataset, which focuses on unusual, previously-unseen entities in the context of emerging discussions. This dataset is useful for getting a sense of the quality of our zero-shot predictions.\n",
    "\n",
    "Let's load the test set from the Hugging Face Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdbb485-4b77-4261-87a2-9ede27e22167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wnut_17\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "620cdc33-69a6-4e35-b40e-b7d8f6dddbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnut_labels = ['corporation', 'creative-work', 'group', 'location', 'person', 'product']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142034f-5328-425f-bc06-81fcb589d132",
   "metadata": {},
   "source": [
    "## Configure Flair TARSTagger\n",
    "\n",
    "Now let's configure our NER model, following [Flair's  documentation](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_10_TRAINING_ZERO_SHOT_MODEL.md#use-case-2-zero-shot-named-entity-recognition-ner-with-tars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f6107-9512-4c49-9d8b-488d886bfa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TARSTagger\n",
    "from flair.data import Sentence\n",
    "\n",
    "# Load zero-shot NER tagger\n",
    "tars = TARSTagger.load('tars-ner')\n",
    "\n",
    "# Define labels for named entities using wnut labels\n",
    "labels = wnut_labels\n",
    "tars.add_and_switch_to_new_task('task 1', labels, label_type='ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a82c2-bf74-4eed-8b85-32d6e08e3dda",
   "metadata": {},
   "source": [
    "Let's test it with one example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b26122f5-a3a6-46ee-b85f-bdb4ec0c8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence(\" \".join(dataset[0]['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "731d6d4d-b8f9-4f24-8e12-0b54de81aa87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('location', 100, 107)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tars.predict(sentence)\n",
    "\n",
    "# Creating the prediction entity as a list of tuples (entity, start_char, end_char)\n",
    "prediction = [\n",
    "    (entity.get_labels()[0].value, entity.start_pos, entity.end_pos)\n",
    "    for entity in sentence.get_spans(\"ner\")\n",
    "]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63316fe3-00a4-413d-80d0-93d51acb7a2b",
   "metadata": {},
   "source": [
    "## Predict over `wnut_17` and log into `rubrix`\n",
    "\n",
    "Now, let's log the predictions in `rubrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec1235d-afd0-4b91-8de3-3dc3fc6b5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for record in dataset.select(range(100)):\n",
    "    input_text = \" \".join(record[\"tokens\"])\n",
    "    \n",
    "    sentence = Sentence(input_text)\n",
    "    tars.predict(sentence)\n",
    "    prediction = [\n",
    "        (entity.get_labels()[0].value, entity.start_pos, entity.end_pos)\n",
    "        for entity in sentence.get_spans(\"ner\")\n",
    "    ]\n",
    "    \n",
    "    # Building TokenClassificationRecord\n",
    "    records.append(\n",
    "        rb.TokenClassificationRecord(\n",
    "            text=input_text,\n",
    "            tokens=[token.text for token in sentence],\n",
    "            prediction=prediction,\n",
    "            prediction_agent=\"tars-ner\",\n",
    "        )\n",
    "    )\n",
    "    \n",
    "rb.log(records, name='tars_ner_wnut_17', metadata={\"split\": \"test\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
