{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubrix.init(api_url=os.environ[\"RUBRIX_API_URL\"], api_key=os.environ[\"RUBRIX_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('datasets/es_sum_mini.json', lines=True) ; df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorization dataset with full-text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i,r in df.iterrows():\n",
    "    records.append(\n",
    "        rubrix.TextClassificationRecord(\n",
    "            inputs={\"text\": r['text']},\n",
    "            annotation=r['topic'],\n",
    "            annotation_agent=\"dvilasuero\",\n",
    "            metadata={'url': r['url']},\n",
    "            event_timestamp=r['date'],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rubrix.log(records, dataset=\"ml_summarization_es_elpais_categories_long_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER predictions dataset with short text\n",
    "\n",
    "Not working yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Esto es una prueba sobre Mariano Rajoy, ex-presidente del PP, la loca de Pontevedra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in doc.ents:\n",
    "    print(e.start_char, e.end_char, e.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i,r in df[0:2].iterrows():\n",
    "    doc = nlp(r['summary'])\n",
    "    records.append(\n",
    "        rubrix.TokenClassificationRecord(\n",
    "            text=r['text'],\n",
    "            tokens=[t.text for t in doc],\n",
    "            prediction=[(e.label_, e.start_char, e.end_char) for e in doc.ents],\n",
    "            prediction_agent=\"spacy_v2_es\",\n",
    "            metadata={'url': r['url']},\n",
    "            event_timestamp=r['date'],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubrix.log(records, dataset=\"ml_summarization_es_elpais_entities_spacy_short\", tags={\"task\": \"ner\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix read dataset from pandas\n",
    "You can download the dataset from https://gitlab.lip6.fr/scialom/mlsum_data/-/raw/master/MLSUM/es_train.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
