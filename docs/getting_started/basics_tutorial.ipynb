{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5393fab0-2b6c-40d7-9fc5-419343e4ba26",
   "metadata": {},
   "source": [
    "# RUBRIX BASICS\n",
    "\n",
    "Here you will find some basic guidelines on how to get started with Rubrix.\n",
    "\n",
    "## HOW TO UPLOAD RECORDS\n",
    "\n",
    "In **Rubrix**, a dataset is a [collection of records](https://rubrix.readthedocs.io/en/stable/reference/webapp/dataset.html), and each one contains an input text. They might also have annotations, predictions, and/or some metadata. \n",
    "\n",
    "These datasets are used for the different **tasks** available in Rubrix (Text/Token Classification and Text2Text). For each task, datasets will be different. These are some examples:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fb22a-e24c-418a-83ea-c4ceb07f26df",
   "metadata": {},
   "source": [
    "### TEXT CLASSIFICATION\n",
    "\n",
    "***REGULAR TASKS**: Text Categorization, Sentiment Analysis, Semantic Textual Similarity, Natural Language Inference (NLI)...*\n",
    "\n",
    "This is an example of how you can upload records for **Text Classification tasks**. We used a [dataset](https://www.kaggle.com/datasets/databar/10k-snapchat-reviews) from Kaggle, which contains 10K reviews about the Snapchat app from App Store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4ae148b-4d91-49ef-a7d1-6073ce8f2077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userName</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>isEdited</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Savvanananahhh</td>\n",
       "      <td>4</td>\n",
       "      <td>For the most part I quite enjoy Snapchat it’s ...</td>\n",
       "      <td>False</td>\n",
       "      <td>10/4/20 6:01</td>\n",
       "      <td>Performance issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Idek 9-101112</td>\n",
       "      <td>3</td>\n",
       "      <td>I’m sorry to say it, but something is definite...</td>\n",
       "      <td>False</td>\n",
       "      <td>10/14/20 2:13</td>\n",
       "      <td>What happened?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>William Quintana</td>\n",
       "      <td>3</td>\n",
       "      <td>Snapchat update ruined my story organization! ...</td>\n",
       "      <td>False</td>\n",
       "      <td>7/31/20 19:54</td>\n",
       "      <td>STORY ORGANIZATION RUINED!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          userName  rating  \\\n",
       "0           0    Savvanananahhh       4   \n",
       "1           1     Idek 9-101112       3   \n",
       "2           2  William Quintana       3   \n",
       "\n",
       "                                              review  isEdited           date  \\\n",
       "0  For the most part I quite enjoy Snapchat it’s ...     False   10/4/20 6:01   \n",
       "1  I’m sorry to say it, but something is definite...     False  10/14/20 2:13   \n",
       "2  Snapchat update ruined my story organization! ...     False  7/31/20 19:54   \n",
       "\n",
       "                        title  \n",
       "0          Performance issues  \n",
       "1              What happened?  \n",
       "2  STORY ORGANIZATION RUINED!  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rubrix as rb\n",
    "\n",
    "#converting the CSV file into a Pandas Dataframe\n",
    "dataset_txt = pd.read_csv(\"snapchat.csv\") \n",
    "\n",
    "dataset_txt.head(3) #displaying the dataframe to see its columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe9946-9e0f-4be9-ade2-9884d9bda998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the column related to the text input\n",
    "data = dataset_txt.rename(columns={\"review\": \"text\"}) \n",
    "\n",
    "#rubrix is able to read the dataframe and identify the columns\n",
    "record_txt = rb.read_pandas(data, task=\"TextClassification\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c0cb7-f129-45e7-8784-88908d882104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging the records\n",
    "rb.log(record_txt, \"snapchat_reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59944e44-4202-4890-9a45-f99fc3fb2dd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TOKEN CLASSIFICATION\n",
    "\n",
    "***REGULAR TASKS**: Named Entity Recognition (NER), Part-of-speech tagging, Slot filling...*\n",
    "\n",
    "This **Token classification tasks** example shows how to create a new CSV from a dataframe with sample German sentences, to tokenize text with the [NLTK library](https://www.nltk.org/), and to save these tokens in a new column. We used this [dataset](https://www.kaggle.com/datasets/mldado/german-online-reviewsratings-of-organic-coffee), containing reviews of organic coffee in German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "502febcb-26f1-4832-8218-4f029ebed697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>brand</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Wenn ich Bohnenkaffee trinke (auf Arbeit trink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Für mich ist dieser Kaffee ideal. Die Grundvor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Ich persönlich bin insbesondere von dem Geschm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        brand  rating  \\\n",
       "0           0  GEPA Kaffee       5   \n",
       "1           1  GEPA Kaffee       5   \n",
       "2           2  GEPA Kaffee       5   \n",
       "\n",
       "                                              review  \n",
       "0  Wenn ich Bohnenkaffee trinke (auf Arbeit trink...  \n",
       "1  Für mich ist dieser Kaffee ideal. Die Grundvor...  \n",
       "2  Ich persönlich bin insbesondere von dem Geschm...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "dataset_tok = pd.read_csv(\"kaffee_reviews.csv\")[:50] \n",
    "\n",
    "dataset_tok.head(3) #displaying the dataset to see the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3705ea8d-9a4d-4bd2-9935-86304d6c21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using this function to delete unnecessary columns for this task\n",
    "dataset_tok = dataset_tok.drop(['brand', 'rating'], axis=1) \n",
    "\n",
    "#renaming the text column\n",
    "dataset_tok = dataset_tok.rename(columns={\"review\": \"text\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1f1c02-f6f5-4939-890e-29e5db31404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#creating a new column for saving the tokenized text\n",
    "dataset_tok['tokens'] = dataset_tok.apply(lambda row: nltk.word_tokenize(row['text']), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ff337-7b12-48fc-b8a1-a829a7800d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rubrix is able to read the dataframe and identify the columns\n",
    "\n",
    "record_tok = rb.read_pandas(dataset_tok, task=\"TokenClassification\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee85f1-1a37-4850-9bda-c4e54aa5db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.log(record_tok, \"coffee-reviews_de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66683c8-9ed5-4ab9-9937-39eeac9ccab0",
   "metadata": {},
   "source": [
    "### TEXT2TEXT\n",
    "\n",
    "***REGULAR TASKS**: Machine translation, Text summarization, Paraphrase generation...*\n",
    "\n",
    "You can see here how you can easily upload records for **Text2Text tasks**. With this [HuggingFace dataset](https://huggingface.co/datasets/europa_ecdc_tm), containing texts from the European Centre for Disease Prevention and Control (ECDC), and the [map](https://huggingface.co/docs/datasets/process#map) function, it can be easily done.\n",
    "\n",
    "In this case, only the chosen **source language** (English) is uploaded, as the **target language** (French) would be the annotations (or the predicted output, depending on the task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbce85f-200e-4b54-9650-308395b81770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"europa_ecdc_tm\", 'en2fr', split=\"train[0:100]\")\n",
    "\n",
    "dataset.to_pandas().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b27d93ad-86f0-4d6c-a31f-5cc1d55235a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frphrase(example):\n",
    "    example['text'] = example['translation']['en']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c29b34-df79-4f37-930b-4e54c25a320e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454bdcef06784c1aa33bb7fd90e1ae8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Vaccination against hepatitis C is not yet available.',\n",
       " 'HIV infection',\n",
       " 'The human immunodeficiency virus (HIV) remains one of the most important communicable diseases in Europe.',\n",
       " 'It is an infection associated with serious disease, persistently high costs of treatment and care, significant number of deaths and shortened life expectancy.',\n",
       " 'HIV is a virus, which attacks the immune system and causes a lifelong severe illness with a long incubation period.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_dataset = dataset.map(extract_frphrase)\n",
    "updated_dataset['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb102c-2c02-4368-9dec-a0c014273de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecdc_en = rb.read_datasets(updated_dataset, task=\"Text2Text\") \n",
    "\n",
    "rb.log(ecdc_en, \"ecdc_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61895f3-f7c9-44a7-8305-1b5f9af1ed20",
   "metadata": {
    "tags": []
   },
   "source": [
    "## HOW TO ANNOTATE RECORDS\n",
    "\n",
    "When it comes to annotating records, **Rubrix** offers two ways to do this: manually in the UI, or by uploading the annotations of the datasets themselves.  \n",
    "\n",
    "### UI ANNOTATION\n",
    "\n",
    "**Rubrix** allows users to **manually annotate** records through its intuitive UI. The annotation process is customized and varies depending on the task to be performed, and this annotations can be used to obtain predictions and to train a model as well. You can learn more about **annotation** with Rubrix [here](https://rubrix.readthedocs.io/en/master/reference/webapp/annotate_records.html#annotate-records).\n",
    "\n",
    "If you want to upload the annotations via **Rubrix**, there are different ways to do so. Here you will find some simple examples of how to upload annotated records for each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674b4d02-c408-41b3-a651-e43d7d8c6f94",
   "metadata": {},
   "source": [
    "### ANNOTATED DATASETS   \n",
    "### TEXT CLASSIFICATION\n",
    "\n",
    "In this example, the chosen dataset is available in [Kaggle](https://www.kaggle.com/datasets/ishantjuyal/emotions-in-text), and it is an annotated dataset for **multilabel text classification**, which deals with text and different emotions. Taking emotions as the annotations, both **text** and **annotations** can be easily uploaded with the `rb.read_pandas`function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0219a204-a45b-43a5-9bbc-a4763905de31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rubrix as rb\n",
    "\n",
    "#converting the CSV file into a Pandas Dataframe\n",
    "datasetxt = pd.read_csv(\"Emotion_final.csv\") \n",
    "\n",
    "datasetxt.head(5) #displaying the dataframe to see its columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a80c353a-6043-4600-b1e1-632532855b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns related to the text and the annotations to upload it with Rubrix\n",
    "emotions = datasetxt.rename(columns={\"Text\": \"text\", \n",
    "                                   \"Emotion\": \"annotation\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2062bb9-28b7-4593-9c04-96048f47a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rubrix now identify both columns\n",
    "emotions = rb.read_pandas(emotions, task=\"TextClassification\") \n",
    "\n",
    "rb.log(emotions, \"emotions_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaee9b6-1fb6-4c0a-a27d-d0dfb4ff1801",
   "metadata": {},
   "source": [
    "### TOKEN CLASSIFICATION\n",
    "\n",
    "In this case, we are using [GermaNER](https://huggingface.co/datasets/germaner), a dataset from **HuggingFace** for Named Entity Recognition tasks in German. In this case, the text has been already tokenized and we need to identify the **NER tags** to upload the annotated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71904a7-128a-428d-8d78-d10727ec8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# a split is necessary to upload the records\n",
    "dataset_de = load_dataset(\"germaner\", split=\"train[0:100]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f58a12f0-ac1d-4be4-95c3-c06d0ff2e372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom...</td>\n",
       "      <td>[3, 8, 8, 8, 1, 8, 8, 8, 8, 3, 8, 8, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Firmengründer, Wolf, Peter, Bree, arbeitete, ...</td>\n",
       "      <td>[8, 3, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am,...</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                             tokens  \\\n",
       "0  0  [Schartau, sagte, dem, \", Tagesspiegel, \", vom...   \n",
       "1  1  [Firmengründer, Wolf, Peter, Bree, arbeitete, ...   \n",
       "2  2  [Ob, sie, dabei, nach, dem, Runden, Tisch, am,...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  [3, 8, 8, 8, 1, 8, 8, 8, 8, 3, 8, 8, 8, 8, 8, ...  \n",
       "1  [8, 3, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...  \n",
       "2  [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, ...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the 3 first results\n",
    "dataset_de.to_pandas().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb87dcb-014d-4a2d-922f-bd19031471e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying the columns for the read_pandas function\n",
    "def data_tokens(example):\n",
    "    example['tokens'] = example['tokens']\n",
    "    example['ner_tags'] = example['ner_tags']\n",
    "    return example\n",
    "\n",
    "datatok = dataset_de.map(data_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1a5d5-de02-4be5-8174-198e57ed00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "# as we already have a tokens and a tag column, rubrix can easily read this information\n",
    "datatok = rb.read_datasets(datatok, task=\"TokenClassification\", tokens=\"tokens\", tags=\"ner_tags\") \n",
    "\n",
    "rb.log(datatok, \"germa_ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f24185-dbd4-47d0-a78c-a3dcf6196497",
   "metadata": {},
   "source": [
    "### TEXT2TEXT \n",
    "\n",
    "For this example, we are using the same [dataset](https://huggingface.co/datasets/europa_ecdc_tm) as in the previous **Text2Text task**. \n",
    "\n",
    "Now, the annotations (which are the **target language**, French) can be easily uploaded by just modifying the previous function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e9f4c-0776-433b-a2e5-c0ba10d21c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"europa_ecdc_tm\", 'en2fr', split=\"train[0:100]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de058d6b-2930-4335-b77b-b6926a3e81e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'en': 'Vaccination against hepatitis C is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': 'HIV infection', 'fr': 'Infection à VIH'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': 'The human immunodeficiency virus (HIV)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         translation\n",
       "0  {'en': 'Vaccination against hepatitis C is not...\n",
       "1   {'en': 'HIV infection', 'fr': 'Infection à VIH'}\n",
       "2  {'en': 'The human immunodeficiency virus (HIV)..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the first 3 columns\n",
    "dataset.to_pandas().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3bd18f-fbf0-4a0e-89d9-d3fb522526f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we add the column corresponding to the target language\n",
    "def extract_phrase(example):\n",
    "    example['text'] = example['translation']['en']\n",
    "    example['annotation'] = example['translation']['fr']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b18f5-7d6a-48d6-af54-bfbf7cdc7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset= dataset.map(extract_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab621975-2d54-4604-8aa4-b11f0708a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "ecdc_en_fr = rb.read_datasets(updated_dataset, task=\"Text2Text\") \n",
    "\n",
    "rb.log(ecdc_en_fr, \"ecdc_en_fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53103248-0a8a-4640-a6fc-13cb0d9f4985",
   "metadata": {},
   "source": [
    "## HOW TO ADD MODEL PREDICTIONS\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832cf28-d3b2-46f2-b626-ff68fb51b6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
