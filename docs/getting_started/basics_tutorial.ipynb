{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5393fab0-2b6c-40d7-9fc5-419343e4ba26",
   "metadata": {},
   "source": [
    "# Rubrix Basics\n",
    "\n",
    "Here you will find some basic guidelines on how to get started with Rubrix.\n",
    "\n",
    "## How to upload datasets\n",
    "\n",
    "In **Rubrix**, a dataset is a [collection of records](https://rubrix.readthedocs.io/en/stable/reference/webapp/dataset.html), each one containing an input text. \n",
    "\n",
    "This \"collection of records\" can be different depending on the the **task** to be performed **(Text, Token Classification and Text2Text)**, and might contain features such as:\n",
    "\n",
    "- Annotations (the labels for each element of a dataset),\n",
    "- Predictions (the results obtained when a model is applied to a dataset), and/or\n",
    "- Metadata (reference data to identify elements on a dataset). \n",
    "\n",
    "Rubrix is not only **compatible** with most of NLP libraries, but also is able to work and preprocess any format (.CSV, JSON, HuggingFace datasets...). \n",
    "\n",
    "Let's see how you can upload a dataset to start working with **Rubrix**. After this, you can explore or annotate datasets, apply weak supervision rules, obtain predictions or even training a model. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fb22a-e24c-418a-83ea-c4ceb07f26df",
   "metadata": {},
   "source": [
    "### Text classification\n",
    "\n",
    "***Regular tasks**: Text Categorization, Sentiment Analysis, Semantic Textual Similarity, Natural Language Inference (NLI)...*\n",
    "\n",
    "These tasks focus on categorizing sentences or documents into one or more groups. When we only deal with a category, it is **single-label text classification**, but when we deal with more than one, then we are talking about **multi-label text classification**. In addition to deal with different tasks, **Rubrix** also provides some interesting features, like the **Define rules mode** or the available **metrics** (see next section).\n",
    "\n",
    "In this example, the chosen [dataset](https://www.kaggle.com/datasets/databar/10k-snapchat-reviews) contains 10K reviews about the Snapchat app from App Store. This dataset could be used for tasks such as **sentiment analysis**, or **text categorization**. \n",
    "\n",
    "After retrieving the dataset from Kaggle and identifying the column that contains the **text input**, the dataset can be easily uploaded. After this, **100 records** will be available in the **Rubrix UI**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ae148b-4d91-49ef-a7d1-6073ce8f2077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userName</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>isEdited</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Savvanananahhh</td>\n",
       "      <td>4</td>\n",
       "      <td>For the most part I quite enjoy Snapchat it’s ...</td>\n",
       "      <td>False</td>\n",
       "      <td>10/4/20 6:01</td>\n",
       "      <td>Performance issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Idek 9-101112</td>\n",
       "      <td>3</td>\n",
       "      <td>I’m sorry to say it, but something is definite...</td>\n",
       "      <td>False</td>\n",
       "      <td>10/14/20 2:13</td>\n",
       "      <td>What happened?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>William Quintana</td>\n",
       "      <td>3</td>\n",
       "      <td>Snapchat update ruined my story organization! ...</td>\n",
       "      <td>False</td>\n",
       "      <td>7/31/20 19:54</td>\n",
       "      <td>STORY ORGANIZATION RUINED!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          userName  rating  \\\n",
       "0           0    Savvanananahhh       4   \n",
       "1           1     Idek 9-101112       3   \n",
       "2           2  William Quintana       3   \n",
       "\n",
       "                                              review  isEdited           date  \\\n",
       "0  For the most part I quite enjoy Snapchat it’s ...     False   10/4/20 6:01   \n",
       "1  I’m sorry to say it, but something is definite...     False  10/14/20 2:13   \n",
       "2  Snapchat update ruined my story organization! ...     False  7/31/20 19:54   \n",
       "\n",
       "                        title  \n",
       "0          Performance issues  \n",
       "1              What happened?  \n",
       "2  STORY ORGANIZATION RUINED!  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rubrix as rb\n",
    "\n",
    "#converting the CSV file into a Pandas Dataframe. This dataset has been limited to 100 results.\n",
    "dataset_txt = pd.read_csv(\"snapchat.csv\")[:100]\n",
    "\n",
    "dataset_txt.head(3) #displaying the dataframe to see the first three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe9946-9e0f-4be9-ade2-9884d9bda998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the column related to the text input\n",
    "data = dataset_txt.rename(columns={\"review\": \"text\"}) \n",
    "#to be processed with the rb.read_pandas function, the text column must be named with the same name\n",
    "\n",
    "#rubrix is able to read the dataframe and to identify the columns\n",
    "record_txt = rb.read_pandas(data, task=\"TextClassification\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c0cb7-f129-45e7-8784-88908d882104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging the records\n",
    "rb.log(record_txt, \"snapchat_reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59944e44-4202-4890-9a45-f99fc3fb2dd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Token Classification\n",
    "\n",
    "**Regular tasks**: Named Entity Recognition (NER), Part-of-speech tagging, Slot filling...*\n",
    "\n",
    "The aim of **Token Classification tasks** is to divide the text into **tokens** to put them **labels**. This process is called **tokenize**, and consists of dividing the text into tokens, which are **units of text**. Rubrix can handle different **token classification tasks**, being **Named Entity Recognition (NER)** one of the most remarkable, as its UI is particularly useful for this purpose.\n",
    "\n",
    "This example shows how to tokenize the **input text** from this [Kaggle dataset](https://www.kaggle.com/datasets/mldado/german-online-reviewsratings-of-organic-coffee), which contains reviews of organic coffee in German. After this tokenization, the dataset is ready to be uploaded.\n",
    "\n",
    "In this case, the **tokenization** has been made with **spaCy**- however, there are other libraries such as  [NLTK](https://www.nltk.org/) or [HuggingFace](https://huggingface.co/docs/transformers/main_classes/tokenizer) that also work for this process. The most important thing is to obtain a **tokenized text**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "502febcb-26f1-4832-8218-4f029ebed697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>brand</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Wenn ich Bohnenkaffee trinke (auf Arbeit trink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Für mich ist dieser Kaffee ideal. Die Grundvor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Ich persönlich bin insbesondere von dem Geschm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        brand  rating  \\\n",
       "0           0  GEPA Kaffee       5   \n",
       "1           1  GEPA Kaffee       5   \n",
       "2           2  GEPA Kaffee       5   \n",
       "\n",
       "                                              review  \n",
       "0  Wenn ich Bohnenkaffee trinke (auf Arbeit trink...  \n",
       "1  Für mich ist dieser Kaffee ideal. Die Grundvor...  \n",
       "2  Ich persönlich bin insbesondere von dem Geschm...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "dataset_tok = pd.read_csv(\"kaffee_reviews.csv\")[:50] \n",
    "\n",
    "dataset_tok.head(3) #displaying the dataset to see the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3705ea8d-9a4d-4bd2-9935-86304d6c21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is better to leave just the text column\n",
    "dataset_tok = dataset_tok.drop(['brand', 'rating'], axis=1) \n",
    "\n",
    "#renaming the text column in order to upload the dataset to Rubrix\n",
    "dataset_tok = dataset_tok.rename(columns={\"review\": \"text\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1f1c02-f6f5-4939-890e-29e5db31404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#creating a new column for saving the tokenized text\n",
    "dataset_tok['tokens'] = dataset_tok.apply(lambda row: nltk.word_tokenize(row['text']), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ff337-7b12-48fc-b8a1-a829a7800d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rubrix is able to read the dataframe and identify the columns\n",
    "\n",
    "record_tok = rb.read_pandas(dataset_tok, task=\"TokenClassification\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee85f1-1a37-4850-9bda-c4e54aa5db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now record can be logged into Rubrix\n",
    "rb.log(record_tok, \"coffee-reviews_de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66683c8-9ed5-4ab9-9937-39eeac9ccab0",
   "metadata": {},
   "source": [
    "### Text2Text\n",
    "\n",
    "***Regular tasks***: Machine translation, Text summarization, Paraphrase generation...*\n",
    "\n",
    "These tasks are, basically, **text generation tasks**. They normally require a **text input** to provide an **output**, which can be a translation or a summary, for instance.\n",
    "\n",
    "To generate new text we need a **text input**, so identifying the text in the dataset is key. As this example is made with a HuggingFace dataset, the process is slightly different from the previous ones. In this case, the text input will be retrieved thanks to the [map function](https://huggingface.co/docs/datasets/process#map).\n",
    "\n",
    "This [dataset](https://huggingface.co/datasets/europa_ecdc_tm), aimed for **Machine Translation tasks**, contains texts from the European Centre for Disease Prevention and Control (ECDC), and only the chosen **source language** (English) will be uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfbce85f-200e-4b54-9650-308395b81770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 16:31:05.901 | WARNING  | datasets.builder:download_and_prepare:531 - Reusing dataset europa_ecdc_tm (/Users/leire/.cache/huggingface/datasets/europa_ecdc_tm/en2fr/1.0.0/67a1105f6b3ff701a9dd2f0462c2b368a8c82b524786b97005b6e63edabb7961)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'en': 'Vaccination against hepatitis C is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': 'HIV infection', 'fr': 'Infection à VIH'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': 'The human immunodeficiency virus (HIV)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         translation\n",
       "0  {'en': 'Vaccination against hepatitis C is not...\n",
       "1   {'en': 'HIV infection', 'fr': 'Infection à VIH'}\n",
       "2  {'en': 'The human immunodeficiency virus (HIV)..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "#retrieving the dataset from HuggingFace, with its language configuration and the desired split\n",
    "dataset = load_dataset(\"europa_ecdc_tm\", 'en2fr', split=\"train[0:100]\")\n",
    "\n",
    "dataset.to_pandas().head(3) #converting the HF dataset into a dataframe to read its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b27d93ad-86f0-4d6c-a31f-5cc1d55235a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will help the map function to retrieve the text input \n",
    "def extract_frphrase(example):\n",
    "    example['text'] = example['translation']['en'] #English as the source language\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c29b34-df79-4f37-930b-4e54c25a320e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454bdcef06784c1aa33bb7fd90e1ae8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Vaccination against hepatitis C is not yet available.',\n",
       " 'HIV infection',\n",
       " 'The human immunodeficiency virus (HIV) remains one of the most important communicable diseases in Europe.',\n",
       " 'It is an infection associated with serious disease, persistently high costs of treatment and care, significant number of deaths and shortened life expectancy.',\n",
       " 'HIV is a virus, which attacks the immune system and causes a lifelong severe illness with a long incubation period.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the map function shows the text input\n",
    "\n",
    "updated_dataset = dataset.map(extract_frphrase)\n",
    "updated_dataset['text'][:5] #displaying the first 5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb102c-2c02-4368-9dec-a0c014273de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the read_datasets function (similar to read_pandas) is able to process the data\n",
    "ecdc_en = rb.read_datasets(updated_dataset, task=\"Text2Text\") \n",
    "\n",
    "#uploading the datasets\n",
    "rb.log(ecdc_en, \"ecdc_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61895f3-f7c9-44a7-8305-1b5f9af1ed20",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How to annotate datasets\n",
    "\n",
    "When it comes to annotating records, **Rubrix** offers two ways to do this: manually in the UI, or via the client by uploading an annotated dataset. \n",
    "\n",
    "### UI annotation\n",
    "\n",
    "**Rubrix** allows users to **manually annotate** records through its intuitive UI. The annotation process is customized and varies depending on the task to be performed, and these annotations can be used to obtain predictions, and to train a model as well. Click [here](https://rubrix.readthedocs.io/en/master/reference/webapp/annotate_records.html#annotate-records) to learn more about **annotation** with Rubrix ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cadf8a-39b5-45ff-a905-be2f9045ba1e",
   "metadata": {},
   "source": [
    "### Text classification\n",
    "\n",
    "#### Manual annotation\n",
    "\n",
    "After uploading a dataset (plain or annotated) to **Rubrix**, users can use the UI to **manually annotate** records. \n",
    "\n",
    "Taking the previous Text Classification example, users could **create one or more labels** with the **\"Create label\"** button in order to manually annotate the dataset:\n",
    "\n",
    "![image](../_static/reference/getting_started/createlabel_text.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c74ff9-0fa9-41f7-93d0-1f4718782654",
   "metadata": {},
   "source": [
    "When labels are ready, the dataset is ready to be annotated. There are features like **bulk annotation**, which can ease the workload:\n",
    "\n",
    "#VIDEO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b04b82-534a-48a1-b0ac-608ab7dbc2d2",
   "metadata": {},
   "source": [
    "#### Rules in UI\n",
    "\n",
    "_Click [here](https://rubrix.readthedocs.io/en/master/reference/webapp/define_rules.html) to read more about the Define rules mode._\n",
    "\n",
    "The **Define rules mode** is also a good method to quickly annotate these kind of datasets with noisy labels, as it is a \"semiautomatic\" system. These rules apply a specific set of labels to the records that match a given query. Besides, some **metrics** will be available for the created rule.\n",
    "\n",
    "This is an easy example. The chosen dataset, available in [Kaggle](https://www.kaggle.com/datasets/ishantjuyal/emotions-in-text), is an annotated dataset for **multilabel text classification**, which deals with texts and different emotions.\n",
    "\n",
    "#VIDEO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b2b70-5564-434b-85b1-a377214f02ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Weak supervision\n",
    "\n",
    "_Click [here](https://rubrix.readthedocs.io/en/master/guides/weak-supervision.html) to read more about Weak Supervision with Rubrix._\n",
    "\n",
    "This feature is related to the **Define rules mode**. When saving one or more rules, it is possible to see the information by clicking on the **Manage rules** button.\n",
    "\n",
    "![image](../_static/reference/getting_started/managerules_text.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671d0ff-6bf9-4cec-84c9-f3463c660aa8",
   "metadata": {},
   "source": [
    "By using this feature, it is possible to **annotate** in a rapid, efficient way and to easily obtain information about the labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462f965-e160-43fc-ad78-9f21a82c4b70",
   "metadata": {},
   "source": [
    "### Token classification\n",
    "\n",
    "#### Manual annotation\n",
    "\n",
    "When dealing with **Token classification** datasets, the manual annotation is particularly interesting. It is possible not only to **bulk annotate** or create new labels, but the UI is also useful to easily annotate, as the video shows:\n",
    "\n",
    "<video width=\"100%\" controls><source src=../_static/reference/getting_started/ner_annotation.mp4 type=\"video/mp4\"></video> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82666c3-9b3c-449d-925a-c99bb1797ff6",
   "metadata": {},
   "source": [
    "Note that these features are available for both annotated and plain datasets, and that the **Metrics sidebar** can also provide good insights of the data:\n",
    "\n",
    "![image](../_static/reference/getting_started/token_annotation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6797ca1-6fdd-4684-89f5-49d67430f29b",
   "metadata": {},
   "source": [
    "### Text2Text\n",
    "\n",
    "#### Manual annotation\n",
    "\n",
    "Again, it is also possible to annotate **preannotated** or **plain** datasets for **Text2Text** tasks. In this case, the **annotation** is inside a text box that can be modified:\n",
    "\n",
    "#VIDEO (TBD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e732aea3-5fb8-485d-a722-6951160459eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
