{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5393fab0-2b6c-40d7-9fc5-419343e4ba26",
   "metadata": {},
   "source": [
    "# RUBRIX BASICS\n",
    "\n",
    "Here you will find some basic guidelines on how to get started with Rubrix.\n",
    "\n",
    "## HOW TO UPLOAD RECORDS\n",
    "\n",
    "In **Rubrix**, a dataset is a [collection of records](https://rubrix.readthedocs.io/en/stable/reference/webapp/dataset.html), and each one contains an input text. They might also have annotations, predictions, and/or some metadata. \n",
    "\n",
    "These datasets are used for the different **tasks** available in Rubrix (Text/Token Classification and Text2Text). For each task, datasets will be different. These are some examples:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fb22a-e24c-418a-83ea-c4ceb07f26df",
   "metadata": {},
   "source": [
    "### TEXT CLASSIFICATION\n",
    "\n",
    "***REGULAR TASKS**: Text Categorization, Sentiment Analysis, Semantic Textual Similarity, Natural Language Inference (NLI)...*\n",
    "\n",
    "This is an example of how you can upload records for **Text Classification tasks**. We used a [dataset](https://www.kaggle.com/datasets/databar/10k-snapchat-reviews) from Kaggle, which contains 10K reviews about the Snapchat app from App Store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ae148b-4d91-49ef-a7d1-6073ce8f2077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userName</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>isEdited</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Savvanananahhh</td>\n",
       "      <td>4</td>\n",
       "      <td>For the most part I quite enjoy Snapchat it‚Äôs ...</td>\n",
       "      <td>False</td>\n",
       "      <td>10/4/20 6:01</td>\n",
       "      <td>Performance issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Idek 9-101112</td>\n",
       "      <td>3</td>\n",
       "      <td>I‚Äôm sorry to say it, but something is definite...</td>\n",
       "      <td>False</td>\n",
       "      <td>10/14/20 2:13</td>\n",
       "      <td>What happened?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>William Quintana</td>\n",
       "      <td>3</td>\n",
       "      <td>Snapchat update ruined my story organization! ...</td>\n",
       "      <td>False</td>\n",
       "      <td>7/31/20 19:54</td>\n",
       "      <td>STORY ORGANIZATION RUINED!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>an gonna be unkownüòè</td>\n",
       "      <td>5</td>\n",
       "      <td>I really love the app for how long i have been...</td>\n",
       "      <td>False</td>\n",
       "      <td>4/22/21 14:10</td>\n",
       "      <td>The app is great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>gzhangziqi</td>\n",
       "      <td>1</td>\n",
       "      <td>This is super frustrating. I was in the middle...</td>\n",
       "      <td>False</td>\n",
       "      <td>10/2/20 13:58</td>\n",
       "      <td>Locked me out, customer service not helping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>9555</td>\n",
       "      <td>geekygirl17</td>\n",
       "      <td>1</td>\n",
       "      <td>I used to love using Snapchat and now I hardly...</td>\n",
       "      <td>False</td>\n",
       "      <td>6/24/19 0:58</td>\n",
       "      <td>Major issue...not that it will get fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9556</th>\n",
       "      <td>9556</td>\n",
       "      <td>changemaker kkdd</td>\n",
       "      <td>2</td>\n",
       "      <td>Well, I did deleted it because there was some ...</td>\n",
       "      <td>False</td>\n",
       "      <td>6/23/19 13:42</td>\n",
       "      <td>I got then deleted it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9557</th>\n",
       "      <td>9557</td>\n",
       "      <td>teekay2much</td>\n",
       "      <td>4</td>\n",
       "      <td>Every time I upload a photo or video to my sto...</td>\n",
       "      <td>False</td>\n",
       "      <td>6/3/19 3:35</td>\n",
       "      <td>Story problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558</th>\n",
       "      <td>9558</td>\n",
       "      <td>whoratheexplora</td>\n",
       "      <td>4</td>\n",
       "      <td>Love this app, but since he update I can‚Äôt upl...</td>\n",
       "      <td>False</td>\n",
       "      <td>6/3/19 3:26</td>\n",
       "      <td>Bugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>9559</td>\n",
       "      <td>Anthony romanempire21</td>\n",
       "      <td>3</td>\n",
       "      <td>Love Snapchat but for some reason when I post ...</td>\n",
       "      <td>False</td>\n",
       "      <td>6/3/19 2:24</td>\n",
       "      <td>Posting to snap story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9560 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0               userName  rating  \\\n",
       "0              0         Savvanananahhh       4   \n",
       "1              1          Idek 9-101112       3   \n",
       "2              2       William Quintana       3   \n",
       "3              3    an gonna be unkownüòè       5   \n",
       "4              4             gzhangziqi       1   \n",
       "...          ...                    ...     ...   \n",
       "9555        9555            geekygirl17       1   \n",
       "9556        9556       changemaker kkdd       2   \n",
       "9557        9557            teekay2much       4   \n",
       "9558        9558        whoratheexplora       4   \n",
       "9559        9559  Anthony romanempire21       3   \n",
       "\n",
       "                                                 review  isEdited  \\\n",
       "0     For the most part I quite enjoy Snapchat it‚Äôs ...     False   \n",
       "1     I‚Äôm sorry to say it, but something is definite...     False   \n",
       "2     Snapchat update ruined my story organization! ...     False   \n",
       "3     I really love the app for how long i have been...     False   \n",
       "4     This is super frustrating. I was in the middle...     False   \n",
       "...                                                 ...       ...   \n",
       "9555  I used to love using Snapchat and now I hardly...     False   \n",
       "9556  Well, I did deleted it because there was some ...     False   \n",
       "9557  Every time I upload a photo or video to my sto...     False   \n",
       "9558  Love this app, but since he update I can‚Äôt upl...     False   \n",
       "9559  Love Snapchat but for some reason when I post ...     False   \n",
       "\n",
       "               date                                        title  \n",
       "0      10/4/20 6:01                           Performance issues  \n",
       "1     10/14/20 2:13                               What happened?  \n",
       "2     7/31/20 19:54                   STORY ORGANIZATION RUINED!  \n",
       "3     4/22/21 14:10                             The app is great  \n",
       "4     10/2/20 13:58  Locked me out, customer service not helping  \n",
       "...             ...                                          ...  \n",
       "9555   6/24/19 0:58     Major issue...not that it will get fixed  \n",
       "9556  6/23/19 13:42                       I got then deleted it.  \n",
       "9557    6/3/19 3:35                                Story problem  \n",
       "9558    6/3/19 3:26                                         Bugs  \n",
       "9559    6/3/19 2:24                        Posting to snap story  \n",
       "\n",
       "[9560 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rubrix as rb\n",
    "\n",
    "#converting the CSV file into a Pandas Dataframe\n",
    "dataset_txt = pd.read_csv(\"snapchat.csv\") \n",
    "\n",
    "dataset_txt #displaying the dataframe to see its columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69fe9946-9e0f-4be9-ade2-9884d9bda998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 13:22:22.869 | WARNING  | rubrix.client.datasets:from_pandas:263 - Following columns are not supported by the TextClassificationRecord model and are ignored: ['Unnamed: 0', 'userName', 'rating', 'isEdited', 'date', 'title']\n"
     ]
    }
   ],
   "source": [
    "#renaming the column related to the text input\n",
    "data = dataset_txt.rename(columns={\"review\": \"text\"}) \n",
    "\n",
    "#rubrix is able to read the dataframe and identify the columns\n",
    "record_txt = rb.read_pandas(data, task=\"TextClassification\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1c0cb7-f129-45e7-8784-88908d882104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1200edcb38644a088ab75e2d4560d8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9560 records logged to http://localhost:6900/datasets/rubrix/snapchat_reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='snapchat_reviews', processed=9560, failed=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logging the records\n",
    "rb.log(record_txt, \"snapchat_reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59944e44-4202-4890-9a45-f99fc3fb2dd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TOKEN CLASSIFICATION\n",
    "\n",
    "***REGULAR TASKS**: Named Entity Recognition (NER), Part-of-speech tagging, Slot filling...*\n",
    "\n",
    "This **Token classification tasks** example shows how to create a new CSV from a dataframe with sample German sentences, to tokenize text with the [NLTK library](https://www.nltk.org/), and to save these tokens in a new column. We used this [dataset](https://www.kaggle.com/datasets/mldado/german-online-reviewsratings-of-organic-coffee), containing reviews of organic coffee in German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "502febcb-26f1-4832-8218-4f029ebed697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>brand</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Wenn ich Bohnenkaffee trinke (auf Arbeit trink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>F√ºr mich ist dieser Kaffee ideal. Die Grundvor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Ich pers√∂nlich bin insbesondere von dem Geschm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>ganz abgesehen vom geschmack legt gepa inzwisc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Seit Jahren kaufe ich am liebsten den Kaffee u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Ca. 10 Jahre lang war f√ºr mich dieser ‚Äì rechts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Heute habe ich meine Kaffeegewohnheiten etwas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Mir schmeckt der GEPA Espresso super. Ich trin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Dieser Gepa Kaffee ist sehr bek√∂mmlich und sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>GEPA Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Aufgrund langfristiger Medikamenteneinnahme wu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Caf√© Chavalo</td>\n",
       "      <td>5</td>\n",
       "      <td>Durch Zufall bin ich auf der Suche nach Bio-Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Caf√© Chavalo</td>\n",
       "      <td>5</td>\n",
       "      <td>Ein Leipziger Original und nur zu empfehlen. M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Caf√© Chavalo</td>\n",
       "      <td>5</td>\n",
       "      <td>Dieser leckere Espresso ist ein Genuss. Und da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>WeltPartner Bio- &amp; Fairtrade-Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Besonders gut finde ich, dass ausschlie√ülich K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>WeltPartner Bio- &amp; Fairtrade-Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>‚Ä¶Cafe Sidamo von WeltPartner ‚Äì ich trinke ihn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>WeltPartner Bio- &amp; Fairtrade-Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Ich bin gro√üer Fan des WeltPartner Kaffees. Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>WeltPartner Bio- &amp; Fairtrade-Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Seit gut einem Jahr trinke ich Kaffee von Welt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Gustoni Caf√© und Espresso</td>\n",
       "      <td>5</td>\n",
       "      <td>;Mit dem Kauf unserer neuen Espressomaschine h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Edeka Caff√© Crema</td>\n",
       "      <td>5</td>\n",
       "      <td>wir haben so einige fairtrade-bio-Kaffeesorten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Edeka Caff√© Crema</td>\n",
       "      <td>5</td>\n",
       "      <td>und geschmackvoll. Ein wunderbarer Kaffeegenus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Edeka Caff√© Crema</td>\n",
       "      <td>5</td>\n",
       "      <td>Seit wir einen Kaffeevollautomaten haben, bin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Altomayo Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>der kaffe ist sehr rund im aroma, noch besser ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Zotter Kaffee Mi(s)Chung</td>\n",
       "      <td>5</td>\n",
       "      <td>Der Kaffee ist leider- sage ich gleich vornewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Naturata Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Dieser Getreidekaffee ist ein wunderbarer Kaff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Zotter Kaffee Mi(s)Chung</td>\n",
       "      <td>5</td>\n",
       "      <td>Vom nicht Kaffee Trinker zum Kaffee Liebhaber ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Zotter Kaffee Mi(s)Chung</td>\n",
       "      <td>5</td>\n",
       "      <td>Ein wunderbarer Kaffee. Qualit√§t, Mischung und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Lebensbaum Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Wir haben vor ein paar Wochen den Gourmet-Kaff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Basic Espresso</td>\n",
       "      <td>5</td>\n",
       "      <td>Ich kaufe mir den fairen Bio Basic Kaffee rege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Rewe Bio R√∂stkaffee</td>\n",
       "      <td>1</td>\n",
       "      <td>Da es unsere Sorte grad nicht gab, haben wir d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Tchibo Barista</td>\n",
       "      <td>1</td>\n",
       "      <td>Daf√ºr, dass der Kaffee laut Fernsehwerbung ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Naturata Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>super lecker! das gute an diesem Getreidekaffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Naturata Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Der Alnatura Getreidekaffee ist die perfekte A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Lebensbaum Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>‚ÄöGourmet Kaffee‚Äò ist unter den Lebensbaum Kaff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Lebensbaum Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Ich habe diesen Kaffee mal zu Besuch bei einer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>Lebensbaum Kaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Kein Tag kann besser anfangen als mit einer Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>Alnatura Kaffee</td>\n",
       "      <td>4</td>\n",
       "      <td>Einer meiner Lieblingskaffees. Voller Geschmac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Rewe Bio R√∂stkaffee</td>\n",
       "      <td>1</td>\n",
       "      <td>Ich nutze von REWE Bio R√∂stkaffee Fairtrade di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Rewe Bio R√∂stkaffee</td>\n",
       "      <td>1</td>\n",
       "      <td>Naturland von Rewe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Rewe Bio R√∂stkaffee</td>\n",
       "      <td>1</td>\n",
       "      <td>Naturland gibt auf ihrer Internetseite an, das...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>Rapunzel Gusto Kaffee &amp; Chicco Getreidekaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Gerade abends trinke ich gerne mal einen Getre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>One World Bio Caff√© Crema</td>\n",
       "      <td>3</td>\n",
       "      <td>Hatten die Bohnen im Blindtest im B√ºro im Voll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>Kaffa Wildkaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Eine gro√üe Auswahl an wirklich k√∂stlichen Kaff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>Rewe Bio R√∂stkaffee</td>\n",
       "      <td>1</td>\n",
       "      <td>Fairtrade Logo = Armut light &amp;amp; keine Trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>Rewe Bio R√∂stkaffee</td>\n",
       "      <td>1</td>\n",
       "      <td>Kaffeeb√∂rse in Nairobi: F√ºr Fairtrade Kaffee g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>Rewe Bio R√∂stkaffee</td>\n",
       "      <td>1</td>\n",
       "      <td>siehe dazu in Zeit-Online Fairtrade: Wenn Kaff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Rapunzel Gusto Kaffee &amp; Chicco Getreidekaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Ein schonender, magenfreundlicher und reizarme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>Rapunzel Gusto Kaffee &amp; Chicco Getreidekaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Ich bin total begeistert, er ist echt magenfre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>Rapunzel Gusto Kaffee &amp; Chicco Getreidekaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>Sehr milder, vollmundiger Geschmack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Rapunzel Gusto Kaffee &amp; Chicco Getreidekaffee</td>\n",
       "      <td>5</td>\n",
       "      <td>ich kann den epressso nur √ºber den gr√ºnen klee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>One World Bio Caff√© Crema</td>\n",
       "      <td>3</td>\n",
       "      <td>Wir sind mit dem Kaffee sehr zufrieden, wir ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                          brand  rating  \\\n",
       "0            0                                    GEPA Kaffee       5   \n",
       "1            1                                    GEPA Kaffee       5   \n",
       "2            2                                    GEPA Kaffee       5   \n",
       "3            3                                    GEPA Kaffee       5   \n",
       "4            4                                    GEPA Kaffee       5   \n",
       "5            5                                    GEPA Kaffee       5   \n",
       "6            6                                    GEPA Kaffee       5   \n",
       "7            7                                    GEPA Kaffee       5   \n",
       "8            8                                    GEPA Kaffee       5   \n",
       "9            9                                    GEPA Kaffee       5   \n",
       "10          10                                   Caf√© Chavalo       5   \n",
       "11          11                                   Caf√© Chavalo       5   \n",
       "12          12                                   Caf√© Chavalo       5   \n",
       "13          13            WeltPartner Bio- & Fairtrade-Kaffee       5   \n",
       "14          14            WeltPartner Bio- & Fairtrade-Kaffee       5   \n",
       "15          15            WeltPartner Bio- & Fairtrade-Kaffee       5   \n",
       "16          16            WeltPartner Bio- & Fairtrade-Kaffee       5   \n",
       "17          17                      Gustoni Caf√© und Espresso       5   \n",
       "18          18                              Edeka Caff√© Crema       5   \n",
       "19          19                              Edeka Caff√© Crema       5   \n",
       "20          20                              Edeka Caff√© Crema       5   \n",
       "21          21                                Altomayo Kaffee       5   \n",
       "22          22                       Zotter Kaffee Mi(s)Chung       5   \n",
       "23          23                                Naturata Kaffee       5   \n",
       "24          24                       Zotter Kaffee Mi(s)Chung       5   \n",
       "25          25                       Zotter Kaffee Mi(s)Chung       5   \n",
       "26          26                              Lebensbaum Kaffee       5   \n",
       "27          27                                 Basic Espresso       5   \n",
       "28          28                            Rewe Bio R√∂stkaffee       1   \n",
       "29          29                                 Tchibo Barista       1   \n",
       "30          30                                Naturata Kaffee       5   \n",
       "31          31                                Naturata Kaffee       5   \n",
       "32          32                              Lebensbaum Kaffee       5   \n",
       "33          33                              Lebensbaum Kaffee       5   \n",
       "34          34                              Lebensbaum Kaffee       5   \n",
       "35          35                                Alnatura Kaffee       4   \n",
       "36          36                            Rewe Bio R√∂stkaffee       1   \n",
       "37          37                            Rewe Bio R√∂stkaffee       1   \n",
       "38          38                            Rewe Bio R√∂stkaffee       1   \n",
       "39          39  Rapunzel Gusto Kaffee & Chicco Getreidekaffee       5   \n",
       "40          40                      One World Bio Caff√© Crema       3   \n",
       "41          41                               Kaffa Wildkaffee       5   \n",
       "42          42                            Rewe Bio R√∂stkaffee       1   \n",
       "43          43                            Rewe Bio R√∂stkaffee       1   \n",
       "44          44                            Rewe Bio R√∂stkaffee       1   \n",
       "45          45  Rapunzel Gusto Kaffee & Chicco Getreidekaffee       5   \n",
       "46          46  Rapunzel Gusto Kaffee & Chicco Getreidekaffee       5   \n",
       "47          47  Rapunzel Gusto Kaffee & Chicco Getreidekaffee       5   \n",
       "48          48  Rapunzel Gusto Kaffee & Chicco Getreidekaffee       5   \n",
       "49          49                      One World Bio Caff√© Crema       3   \n",
       "\n",
       "                                               review  \n",
       "0   Wenn ich Bohnenkaffee trinke (auf Arbeit trink...  \n",
       "1   F√ºr mich ist dieser Kaffee ideal. Die Grundvor...  \n",
       "2   Ich pers√∂nlich bin insbesondere von dem Geschm...  \n",
       "3   ganz abgesehen vom geschmack legt gepa inzwisc...  \n",
       "4   Seit Jahren kaufe ich am liebsten den Kaffee u...  \n",
       "5   Ca. 10 Jahre lang war f√ºr mich dieser ‚Äì rechts...  \n",
       "6   Heute habe ich meine Kaffeegewohnheiten etwas ...  \n",
       "7   Mir schmeckt der GEPA Espresso super. Ich trin...  \n",
       "8   Dieser Gepa Kaffee ist sehr bek√∂mmlich und sch...  \n",
       "9   Aufgrund langfristiger Medikamenteneinnahme wu...  \n",
       "10  Durch Zufall bin ich auf der Suche nach Bio-Ka...  \n",
       "11  Ein Leipziger Original und nur zu empfehlen. M...  \n",
       "12  Dieser leckere Espresso ist ein Genuss. Und da...  \n",
       "13  Besonders gut finde ich, dass ausschlie√ülich K...  \n",
       "14  ‚Ä¶Cafe Sidamo von WeltPartner ‚Äì ich trinke ihn ...  \n",
       "15  Ich bin gro√üer Fan des WeltPartner Kaffees. Me...  \n",
       "16  Seit gut einem Jahr trinke ich Kaffee von Welt...  \n",
       "17  ;Mit dem Kauf unserer neuen Espressomaschine h...  \n",
       "18  wir haben so einige fairtrade-bio-Kaffeesorten...  \n",
       "19  und geschmackvoll. Ein wunderbarer Kaffeegenus...  \n",
       "20  Seit wir einen Kaffeevollautomaten haben, bin ...  \n",
       "21  der kaffe ist sehr rund im aroma, noch besser ...  \n",
       "22  Der Kaffee ist leider- sage ich gleich vornewe...  \n",
       "23  Dieser Getreidekaffee ist ein wunderbarer Kaff...  \n",
       "24  Vom nicht Kaffee Trinker zum Kaffee Liebhaber ...  \n",
       "25  Ein wunderbarer Kaffee. Qualit√§t, Mischung und...  \n",
       "26  Wir haben vor ein paar Wochen den Gourmet-Kaff...  \n",
       "27  Ich kaufe mir den fairen Bio Basic Kaffee rege...  \n",
       "28  Da es unsere Sorte grad nicht gab, haben wir d...  \n",
       "29  Daf√ºr, dass der Kaffee laut Fernsehwerbung ext...  \n",
       "30  super lecker! das gute an diesem Getreidekaffe...  \n",
       "31  Der Alnatura Getreidekaffee ist die perfekte A...  \n",
       "32  ‚ÄöGourmet Kaffee‚Äò ist unter den Lebensbaum Kaff...  \n",
       "33  Ich habe diesen Kaffee mal zu Besuch bei einer...  \n",
       "34  Kein Tag kann besser anfangen als mit einer Ta...  \n",
       "35  Einer meiner Lieblingskaffees. Voller Geschmac...  \n",
       "36  Ich nutze von REWE Bio R√∂stkaffee Fairtrade di...  \n",
       "37                                 Naturland von Rewe  \n",
       "38  Naturland gibt auf ihrer Internetseite an, das...  \n",
       "39  Gerade abends trinke ich gerne mal einen Getre...  \n",
       "40  Hatten die Bohnen im Blindtest im B√ºro im Voll...  \n",
       "41  Eine gro√üe Auswahl an wirklich k√∂stlichen Kaff...  \n",
       "42  Fairtrade Logo = Armut light &amp; keine Trans...  \n",
       "43  Kaffeeb√∂rse in Nairobi: F√ºr Fairtrade Kaffee g...  \n",
       "44  siehe dazu in Zeit-Online Fairtrade: Wenn Kaff...  \n",
       "45  Ein schonender, magenfreundlicher und reizarme...  \n",
       "46  Ich bin total begeistert, er ist echt magenfre...  \n",
       "47                Sehr milder, vollmundiger Geschmack  \n",
       "48  ich kann den epressso nur √ºber den gr√ºnen klee...  \n",
       "49  Wir sind mit dem Kaffee sehr zufrieden, wir ma...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "dataset_tok = pd.read_csv(\"kaffee_reviews.csv\")[:50] \n",
    "\n",
    "dataset_tok #displaying the dataset to see the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3705ea8d-9a4d-4bd2-9935-86304d6c21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using this function to delete unnecessary columns for this task\n",
    "dataset_tok = dataset_tok.drop(['brand', 'rating'], axis=1) \n",
    "\n",
    "#renaming the text column\n",
    "dataset_tok = dataset_tok.rename(columns={\"review\": \"text\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d1f1c02-f6f5-4939-890e-29e5db31404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#creating a new column for saving the tokenized text\n",
    "dataset_tok['tokens'] = dataset_tok.apply(lambda row: nltk.word_tokenize(row['text']), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e4ff337-7b12-48fc-b8a1-a829a7800d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 13:24:13.303 | WARNING  | rubrix.client.datasets:from_pandas:263 - Following columns are not supported by the TokenClassificationRecord model and are ignored: ['Unnamed: 0']\n"
     ]
    }
   ],
   "source": [
    "#rubrix is able to read the dataframe and identify the columns\n",
    "\n",
    "record_tok = rb.read_pandas(dataset_tok, task=\"TokenClassification\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dee85f1-1a37-4850-9bda-c4e54aa5db03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d5f1907a574fc49800b0f9124cc070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 records logged to http://localhost:6900/datasets/rubrix/coffee-reviews_de\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='coffee-reviews_de', processed=50, failed=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb.log(record_tok, \"coffee-reviews_de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66683c8-9ed5-4ab9-9937-39eeac9ccab0",
   "metadata": {},
   "source": [
    "### TEXT2TEXT\n",
    "\n",
    "***REGULAR TASKS**: Machine translation, Text summarization, Paraphrase generation...*\n",
    "\n",
    "You can see here how you can easily upload records for **Text2Text tasks**. With this [HuggingFace dataset](https://huggingface.co/datasets/bible_para/viewer/en-fr/train), containing biblical phrases in English and French, and the [map](https://huggingface.co/docs/datasets/process#map) function, it can be easily done.\n",
    "\n",
    "In this case, only the chosen **source language** (French) is uploaded, as the **target language** would be the predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfbce85f-200e-4b54-9650-308395b81770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:16:57.565 | WARNING  | datasets.builder:download_and_prepare:531 - Reusing dataset bible_para (/Users/leire/.cache/huggingface/datasets/bible_para/en-fr/1.0.0/b6cc20bcbfb0299beeba1dcc80a8420b975938ca0eef75b3ed30b50df7d950b1)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bible_para\", 'en-fr', split=\"train[0:100]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b27d93ad-86f0-4d6c-a31f-5cc1d55235a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frphrase(example):\n",
    "    example['text'] = example['translation']['en']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "77c29b34-df79-4f37-930b-4e54c25a320e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6f61a208d94a9e914f2700d8a5209f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['In the beginning God created the heavens and the earth.',\n",
       " \"Now the earth was formless and empty. Darkness was on the surface of the deep. God's Spirit was hovering over the surface of the waters.\",\n",
       " 'God said, \"Let there be light,\" and there was light.',\n",
       " 'God saw the light, and saw that it was good. God divided the light from the darkness.',\n",
       " 'God called the light \"day,\" and the darkness he called \"night.\" There was evening and there was morning, one day.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_dataset = dataset.map(extract_frphrase)\n",
    "updated_dataset['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7cb102c-2c02-4368-9dec-a0c014273de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:17:07.063 | WARNING  | rubrix.client.datasets:from_datasets:199 - Following columns are not supported by the Text2TextRecord model and are ignored: ['translation']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b8f84306cc4f67a4f365e9489e1195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 records logged to http://localhost:6900/datasets/rubrix/bible_en-fr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='bible_en-fr', processed=100, failed=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_fr_en = rb.read_datasets(updated_dataset, task=\"Text2Text\") \n",
    "\n",
    "rb.log(bible_fr_en, \"bible_en-fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61895f3-f7c9-44a7-8305-1b5f9af1ed20",
   "metadata": {
    "tags": []
   },
   "source": [
    "## HOW TO ANNOTATE RECORDS\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674b4d02-c408-41b3-a651-e43d7d8c6f94",
   "metadata": {},
   "source": [
    "### TEXT CLASSIFICATION\n",
    "\n",
    "In this example, the chosen dataset is available in [Kaggle](https://www.kaggle.com/datasets/ishantjuyal/emotions-in-text), and it is an annotated dataset for **multilabel text classification**, which deals with text and different emotions. Taking emotions as the annotations, both **text** and **annotations** can be easily uploaded with the `rb.read_pandas`function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0219a204-a45b-43a5-9bbc-a4763905de31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21454</th>\n",
       "      <td>Melissa stared at her friend in dism</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21455</th>\n",
       "      <td>Successive state elections have seen the gover...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21456</th>\n",
       "      <td>Vincent was irritated but not dismay</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21457</th>\n",
       "      <td>Kendall-Hume turned back to face the dismayed ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21458</th>\n",
       "      <td>I am dismayed , but not surpris</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21459 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion\n",
       "0                                i didnt feel humiliated  sadness\n",
       "1      i can go from feeling so hopeless to so damned...  sadness\n",
       "2       im grabbing a minute to post i feel greedy wrong    anger\n",
       "3      i am ever feeling nostalgic about the fireplac...     love\n",
       "4                                   i am feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "21454               Melissa stared at her friend in dism     fear\n",
       "21455  Successive state elections have seen the gover...     fear\n",
       "21456               Vincent was irritated but not dismay     fear\n",
       "21457  Kendall-Hume turned back to face the dismayed ...     fear\n",
       "21458                    I am dismayed , but not surpris     fear\n",
       "\n",
       "[21459 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rubrix as rb\n",
    "\n",
    "#converting the CSV file into a Pandas Dataframe\n",
    "datasetxt = pd.read_csv(\"Emotion_final.csv\") \n",
    "\n",
    "datasetxt #displaying the dataframe to see its columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a80c353a-6043-4600-b1e1-632532855b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns related to the text and the annotations to upload it with Rubrix\n",
    "dataset1 = datasetxt.rename(columns={\"Text\": \"text\", \n",
    "                                   \"Emotion\": \"annotation\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2062bb9-28b7-4593-9c04-96048f47a6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471da91176ae4cd8ab1cfe9bb7f7dd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21459 records logged to http://localhost:6900/datasets/rubrix/dataset_emotion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='dataset_emotion', processed=21459, failed=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rubrix now identify both columns\n",
    "record1 = rb.read_pandas(dataset1, task=\"TextClassification\") \n",
    "\n",
    "rb.log(record1, \"dataset_emotion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaee9b6-1fb6-4c0a-a27d-d0dfb4ff1801",
   "metadata": {},
   "source": [
    "### TOKEN CLASSIFICATION\n",
    "\n",
    "In this case, we are using [GermaNER](https://huggingface.co/datasets/germaner), a dataset from **HuggingFace** for Named Entity Recognition tasks in German. In this case, the text has been already tokenized and we need to identify the **NER tags** to upload the annotated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71904a7-128a-428d-8d78-d10727ec8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# a split is necessary to upload the records\n",
    "dataset_de = load_dataset(\"germaner\", split=\"train[0:100]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f58a12f0-ac1d-4be4-95c3-c06d0ff2e372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Schartau, sagte, dem, \", Tagesspiegel, \", vom...</td>\n",
       "      <td>[3, 8, 8, 8, 1, 8, 8, 8, 8, 3, 8, 8, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Firmengr√ºnder, Wolf, Peter, Bree, arbeitete, ...</td>\n",
       "      <td>[8, 3, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Ob, sie, dabei, nach, dem, Runden, Tisch, am,...</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                             tokens  \\\n",
       "0  0  [Schartau, sagte, dem, \", Tagesspiegel, \", vom...   \n",
       "1  1  [Firmengr√ºnder, Wolf, Peter, Bree, arbeitete, ...   \n",
       "2  2  [Ob, sie, dabei, nach, dem, Runden, Tisch, am,...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  [3, 8, 8, 8, 1, 8, 8, 8, 8, 3, 8, 8, 8, 8, 8, ...  \n",
       "1  [8, 3, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...  \n",
       "2  [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, ...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_de.to_pandas().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1aa1a5d5-de02-4be5-8174-198e57ed00b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:37:23.820 | WARNING  | datasets.arrow_dataset:_map_single:2320 - Loading cached processed dataset at /Users/leire/.cache/huggingface/datasets/germa_ner/default/0.9.1/98610f255094d6f67f37c379e5e9f0800322705df916299ddd09ac6dab80bbe8/cache-60e11fe6c3d96d92.arrow\n",
      "2022-05-10 15:37:23.856 | WARNING  | datasets.arrow_dataset:_map_single:2320 - Loading cached processed dataset at /Users/leire/.cache/huggingface/datasets/germa_ner/default/0.9.1/98610f255094d6f67f37c379e5e9f0800322705df916299ddd09ac6dab80bbe8/cache-5ea03d00632d7744.arrow\n",
      "2022-05-10 15:37:23.866 | WARNING  | rubrix.client.datasets:from_datasets:199 - Following columns are not supported by the TokenClassificationRecord model and are ignored: ['ner_tags']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b65a96990746e08843478f77be0a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 records logged to http://localhost:6900/datasets/rubrix/germa_ner\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='germa_ner', processed=100, failed=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "datatok = rb.read_datasets(dataset_tok, task=\"TokenClassification\", tokens=\"tokens\", tags=\"ner_tags\") \n",
    "\n",
    "rb.log(datatok, \"germa_ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f24185-dbd4-47d0-a78c-a3dcf6196497",
   "metadata": {},
   "source": [
    "### TEXT2TEXT \n",
    "\n",
    "For this example, we are using the same [dataset](https://huggingface.co/datasets/bible_para/viewer/en-fr/train) as in the previous **Text2Text task**. \n",
    "\n",
    "Now, the annotations (which are the target language, French) can be easily uploaded after being identified, by just modifying the previous function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b30e9f4c-0776-433b-a2e5-c0ba10d21c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:17:39.042 | WARNING  | datasets.builder:download_and_prepare:531 - Reusing dataset bible_para (/Users/leire/.cache/huggingface/datasets/bible_para/en-fr/1.0.0/b6cc20bcbfb0299beeba1dcc80a8420b975938ca0eef75b3ed30b50df7d950b1)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bible_para\", 'en-fr', split=\"train[0:100]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d3bd18f-fbf0-4a0e-89d9-d3fb522526f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phrase(example):\n",
    "    example['text'] = example['translation']['en']\n",
    "    example['annotation'] = example['translation']['fr']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e6b18f5-7d6a-48d6-af54-bfbf7cdc7a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:17:39.075 | WARNING  | datasets.arrow_dataset:_map_single:2320 - Loading cached processed dataset at /Users/leire/.cache/huggingface/datasets/bible_para/en-fr/1.0.0/b6cc20bcbfb0299beeba1dcc80a8420b975938ca0eef75b3ed30b50df7d950b1/cache-4fe3590f1c43a44f.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'translation', 'text', 'annotation'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_dataset = dataset.map(extract_phrase)\n",
    "\n",
    "updated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab621975-2d54-4604-8aa4-b11f0708a165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:17:39.558 | WARNING  | rubrix.client.datasets:from_datasets:199 - Following columns are not supported by the Text2TextRecord model and are ignored: ['translation']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbef47d2b114ffe89643eee0210ef1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 records logged to http://localhost:6900/datasets/rubrix/bible_fr-en\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='bible_fr-en', processed=100, failed=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "bible_fr_en = rb.read_datasets(updated_dataset, task=\"Text2Text\") \n",
    "\n",
    "rb.log(bible_fr_en, \"bible_fr-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359ac27-59d8-4ab4-997c-2f0b6be6d282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
