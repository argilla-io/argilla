{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b4e56f-bc88-44a7-a235-fb88ae0dfb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, ElectraForSequenceClassification\n",
    "import pandas as pd\n",
    "import rubrix as rb\n",
    "from rubrix.labeling.text_classification import Rule, WeakLabels\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "from weasel.datamodules.base_datamodule import AbstractWeaselDataset, AbstractDownstreamDataset\n",
    "from weasel.models.downstream_models.base_model import DownstreamBaseModel\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Union, List\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0649a-9c21-4384-bb49-cdb27df90fe1",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5894c93f-2643-4a6b-bfc9-4aed903c4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../tutorials/data/yt_comments_train.csv')\n",
    "test_df = pd.read_csv('../tutorials/data/yt_comments_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ff15f-c933-4699-8166-bdcaf46ae48d",
   "metadata": {},
   "source": [
    "## upload records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589d3116-2f0c-423a-958d-440b05756aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.delete(\"weak_supervision_yt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c73f086-aa53-454f-8e13-a02712d95618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='weak_supervision_yt', processed=1836, failed=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unlabelled data\n",
    "records = [\n",
    "    rb.TextClassificationRecord(\n",
    "        inputs=row.text,\n",
    "        metadata={\"video\":row.video, \"author\": row.author},\n",
    "        id=i,\n",
    "    )\n",
    "    for i,row in train_df.iterrows()\n",
    "]\n",
    "\n",
    "# labelled data for testing\n",
    "last = len(records)\n",
    "labels = [\"HAM\", \"SPAM\"]\n",
    "\n",
    "\n",
    "records += [\n",
    "    rb.TextClassificationRecord(\n",
    "        inputs=row.text,\n",
    "        annotation=labels[row.label],\n",
    "        metadata={\"video\":row.video, \"author\": row.author},\n",
    "        id=last+i\n",
    "    )\n",
    "    for i, row in test_df.iterrows()\n",
    "]\n",
    "rb.log(records, name=\"weak_supervision_yt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7263d83-e8b0-4f28-bec8-2730921a6f27",
   "metadata": {},
   "source": [
    "## define rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8acc20-c55d-4d51-bd96-84cf2b8ddd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules defined as Elasticsearch queries\n",
    "check_out = Rule(query=\"check out\", label=\"SPAM\")\n",
    "plz = Rule(query=\"plz OR please\", label=\"SPAM\")\n",
    "subscribe = Rule(query=\"subscribe\", label=\"SPAM\")\n",
    "my = Rule(query=\"my\", label=\"SPAM\")\n",
    "song = Rule(query=\"song\", label=\"HAM\")\n",
    "love = Rule(query=\"love\", label=\"HAM\")\n",
    "\n",
    "# Rules defined as Python labeling functions\n",
    "def contains_http(record: rb.TextClassificationRecord):\n",
    "    if \"http\" in record.inputs[\"text\"]:\n",
    "        return \"SPAM\"\n",
    "\n",
    "def short_comment(record: rb.TextClassificationRecord):\n",
    "    return \"HAM\" if len(record.inputs[\"text\"].split()) < 5 else None\n",
    "\n",
    "def regex_check_out(record: rb.TextClassificationRecord):\n",
    "    return \"SPAM\" if re.search(r\"check.*out\", record.inputs[\"text\"], flags=re.I) else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803a296e-045c-4b20-8e92-b1d62e642ddc",
   "metadata": {},
   "source": [
    "## compute weak labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ace59b2-9583-4575-918d-f6ab0d564689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7f39ffee584f71abc1bf40b0a3c2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing rules:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bea264695d44dc9c2a2cc92d8c6805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying rules:   0%|          | 0/1836 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>coverage</th>\n",
       "      <th>overlaps</th>\n",
       "      <th>conflicts</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check out</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.242919</td>\n",
       "      <td>0.235839</td>\n",
       "      <td>0.029956</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plz OR please</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.090414</td>\n",
       "      <td>0.081155</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subscribe</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.106754</td>\n",
       "      <td>0.083878</td>\n",
       "      <td>0.028867</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.049564</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <td>{HAM}</td>\n",
       "      <td>0.132898</td>\n",
       "      <td>0.079521</td>\n",
       "      <td>0.033769</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>{HAM}</td>\n",
       "      <td>0.092048</td>\n",
       "      <td>0.070261</td>\n",
       "      <td>0.031590</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_http</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.106209</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.049564</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_comment</th>\n",
       "      <td>{HAM}</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.110566</td>\n",
       "      <td>0.064270</td>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_check_out</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.226580</td>\n",
       "      <td>0.226035</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>{SPAM, HAM}</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.448802</td>\n",
       "      <td>0.120915</td>\n",
       "      <td>338</td>\n",
       "      <td>30</td>\n",
       "      <td>0.918478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    polarity  coverage  overlaps  conflicts  correct  \\\n",
       "check out             {SPAM}  0.242919  0.235839   0.029956       45   \n",
       "plz OR please         {SPAM}  0.090414  0.081155   0.019608       20   \n",
       "subscribe             {SPAM}  0.106754  0.083878   0.028867       30   \n",
       "my                    {SPAM}  0.190632  0.166667   0.049564       41   \n",
       "song                   {HAM}  0.132898  0.079521   0.033769       39   \n",
       "love                   {HAM}  0.092048  0.070261   0.031590       28   \n",
       "contains_http         {SPAM}  0.106209  0.073529   0.049564        6   \n",
       "short_comment          {HAM}  0.245098  0.110566   0.064270       84   \n",
       "regex_check_out       {SPAM}  0.226580  0.226035   0.027778       45   \n",
       "total            {SPAM, HAM}  0.754902  0.448802   0.120915      338   \n",
       "\n",
       "                 incorrect  precision  \n",
       "check out                0   1.000000  \n",
       "plz OR please            0   1.000000  \n",
       "subscribe                0   1.000000  \n",
       "my                       6   0.872340  \n",
       "song                     9   0.812500  \n",
       "love                     7   0.800000  \n",
       "contains_http            0   1.000000  \n",
       "short_comment            8   0.913043  \n",
       "regex_check_out          0   1.000000  \n",
       "total                   30   0.918478  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bundle our rules in a list\n",
    "rules = [check_out, plz, subscribe, my, song, love, contains_http, short_comment, regex_check_out]\n",
    "\n",
    "# apply the rules to a dataset to obtain the weak labels\n",
    "weak_labels = WeakLabels(\n",
    "    rules=rules, \n",
    "    dataset=\"weak_supervision_yt\"\n",
    ")\n",
    "\n",
    "# show some stats about the rules, see the `summary()` docstring for details\n",
    "weak_labels.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60b2fb3-ab05-46be-9603-3342ac9049ea",
   "metadata": {},
   "source": [
    "## baseline: snorkel's LabelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "340a1943-fac0-446e-a59f-6f9e1038f564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9043062200956937}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "# train our label model\n",
    "label_model = LabelModel()\n",
    "label_model.fit(L_train=weak_labels.matrix(has_annotation=False), n_epochs=500, log_freq=100, seed=123)\n",
    "\n",
    "# check its performance\n",
    "label_model.score(L=weak_labels.matrix(has_annotation=True), Y=weak_labels.annotation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823f8385-d46b-47e3-8c86-58e9c7f21543",
   "metadata": {},
   "source": [
    "## weasel: define datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c0ad0ae-5d52-4a1b-9fe2-d664e2d5016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(AbstractWeaselDataset):\n",
    "    def __init__(self, L: Union[np.ndarray, torch.Tensor], inputs):\n",
    "        super().__init__(L, None)\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        if self.L.shape[0] != len(self.inputs):\n",
    "            raise ValueError(\"L and inputs have different number of samples\")\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        return self.L[item], self.inputs[item]\n",
    "    \n",
    "\n",
    "class TestDataset(AbstractDownstreamDataset):\n",
    "    def __init__(self, inputs, Y: Union[np.ndarray, torch.Tensor]):\n",
    "        super().__init__(None, Y)\n",
    "        self.inputs = inputs\n",
    "        \n",
    "        if len(self.Y) != len(self.inputs):\n",
    "            raise ValueError(\"inputs and Y have different number of samples\")\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        return self.inputs[item], self.Y[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46525d3d-01e5-4d98-a50a-aef2e8ba81af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "284b7b12-5bf9-42d9-91ca-d7de582f2bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TrainDataset(\n",
    "    L=weak_labels.matrix(has_annotation=False), \n",
    "    inputs=[tokenizer(rec.inputs[\"text\"], truncation=True) \n",
    "          for rec in weak_labels.records(has_annotation=False)], \n",
    ")\n",
    "\n",
    "test_ds = TestDataset(\n",
    "    inputs=[tokenizer(rec.inputs[\"text\"], truncation=True)\n",
    "          for rec in weak_labels.records(has_annotation=True)],\n",
    "    Y=weak_labels.annotation(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84f5f120-6984-4d26-a659-0bdf15df848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self._tokenizer = tokenizer\n",
    "    def __call__(self, batch):\n",
    "        L = torch.stack([b[0] for b in batch])\n",
    "        inputs = {key: [b[1][key] for b in batch] for key in batch[0][1]}\n",
    "        return L, self._tokenizer.pad(inputs, return_tensors=\"pt\")\n",
    "\n",
    "    \n",
    "class TestCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self._tokenizer = tokenizer\n",
    "    def __call__(self, batch):\n",
    "        Y = torch.stack([b[1] for b in batch])\n",
    "        inputs = {key: [b[0][key] for b in batch] for key in batch[0][0]}\n",
    "        return self._tokenizer.pad(inputs, return_tensors=\"pt\"), Y\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    collate_fn=TrainCollator(tokenizer),\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_ds,\n",
    "    collate_fn=TestCollator(tokenizer),\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce5a23-a75d-4aed-b465-59b05773e8cd",
   "metadata": {},
   "source": [
    "## define end model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32017ac5-2b82-4ae8-ae24-311fcb4ec71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEndModel(DownstreamBaseModel):\n",
    "    def __init__(self, name: str = \"google/electra-small-discriminator\", num_labels: int = 2):\n",
    "        super().__init__()\n",
    "        self.out_dim = num_labels\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(name, num_labels=num_labels)\n",
    "        \n",
    "    def forward(self, kwargs):\n",
    "        model_output = self.model(**kwargs)\n",
    "        return model_output[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5274fc2-094f-4fbb-9fd4-f61456f1e41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "end_model = TransformerEndModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8195c75-38ba-4691-81d9-2dcd4e63e5db",
   "metadata": {},
   "source": [
    "## join end model and weasel's label model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8465f810-a96a-4dbc-b72a-ed3e4cde7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weasel.models import Weasel\n",
    "weasel = Weasel(\n",
    "    end_model=end_model,\n",
    "    num_LFs=len(weak_labels.rules),\n",
    "    n_classes=2,\n",
    "    encoder={'hidden_dims': [32, 10]},\n",
    "    optim_encoder={'name': 'adam', 'lr': 1e-4},\n",
    "    optim_end_model={'name': 'adam', 'lr': 5e-5}  # different way of getting the same optim with Hydra\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5678e057-5d8e-48a0-82de-59093f3a2bc9",
   "metadata": {},
   "source": [
    "## train the joint model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dadf234-631c-413e-878a-7e1ead8d4669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor=\"Val/accuracy\", mode=\"max\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,  # >= 1 to use GPU(s)\n",
    "    max_epochs=3,  # since just for illustratory purposes\n",
    "    logger=False,\n",
    "    deterministic=True,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f55e4ce9-cf43-4cd1-b0da-ec2e6f016ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | end_model     | TransformerEndModel | 13.5 M\n",
      "1 | encoder       | MLPEncoder          | 932   \n",
      "2 | accuracy_func | Softmax             | 0     \n",
      "------------------------------------------------------\n",
      "13.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.6 M    Total params\n",
      "54.201    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/rubrix/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/david/miniconda3/envs/rubrix/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31285e0816cd4305beda8dda0463110a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=weasel, train_dataloaders=train_loader, val_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4600a-3212-48d7-9591-0158a259a90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
