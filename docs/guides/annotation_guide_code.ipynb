{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate new data to improve NLP models using Rubrix and biome.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Hey there! In this guide, we will show you how to use Rubrix to annotate new data, and use this new data to improve existing Deep Learning models. Our use case will be Automatic Misogyny Detection (AMI): Deep Learning models able to detect the underlying misogyny on a given text. Ground-breaking work is being made every year on this subject, with shared tasks and new models that push the performance of these models closer and closer to be implemented in apps, social networks and other digital environments. \n",
    "\n",
    "To train these NLP models we are going to use [biome.text](https://github.com/recognai/biome-text), an open-source library to train models with a simple workflow. Rubrix is compatible with almost any library or service, so we will work back and forth with both of them. \n",
    "\n",
    "The data used to feed the models and make the annotations comes from the [IberEval 2018](https://sites.google.com/view/ibereval-2…) shared task. We are also making the specific datasets used in each step of this guide available, so it can be reproduced in the best way possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "If you want to reproduce this code, make sure that all the libraries needed to run this guide are installed and imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U git+https://github.com/recognai/biome-text\n",
    "%pip install rubrix\n",
    "%pip install pandas\n",
    "exit(0)  # Force restart of the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['WANDB_API_KEY'] = '7bd265df21100baa9767bb9f69108bc417db4b4a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biome.text import *\n",
    "import pandas as pd\n",
    "import rubrix as rb\n",
    "\n",
    "import wandb #TODO: erase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the first model\n",
    "\n",
    "Hey there! In this guide, we will show you how to use Rubrix to annotate new data, and use this new data to improve existing Deep Learning models. Our use case will be Automatic Misogyny Detection (AMI): Deep Learning models able to detect the underlying misogyny on a given text. Ground-breaking work is being made every year on this subject, with shared-tasks and new models that push the performance of this model closer and closer to be implemented in apps, social networks and other digital environments. \n",
    "\n",
    "To train these NLP models we are going to use [biome.text](https://github.com/recognai/biome-text), an open-source library to train models with a simple workflow. Rubrix is compatible with almost any library or service, so we will work back and forth with both of them. \n",
    "\n",
    "The data used to feed the models and make the annotations comes from the [IberEval 2018](https://sites.google.com/view/ibereval-2…) shared-task. We are also making the specific datasets used in each step of this guide available, so it can be reproduced in the best way possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO (wont be included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = Dataset.from_pandas(training_df)\n",
    "validation_ds = Dataset.from_pandas(validation_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "training_full_ds = Dataset.from_pandas(training_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dict = {\n",
    "    \"name\": \"rubrix_guide\",\n",
    "    \"features\": {\n",
    "        \"transformers\": {\n",
    "            \"model_name\": \"dccuchile/bert-base-spanish-wwm-cased\",\n",
    "            \"trainable\": True,\n",
    "            \"max_length\": 280,  #twitter characters cap\n",
    "        }\n",
    "    },\n",
    "    \"head\": {\n",
    "        \"type\": \"TextClassification\",\n",
    "        \"multilabel\": True,\n",
    "        \"labels\": [\n",
    "            'sexual_harassment',\n",
    "             'dominance',\n",
    "             'discredit',\n",
    "             'stereotype',\n",
    "             'derailing',\n",
    "             'passive',\n",
    "             'active',\n",
    "             '0'\n",
    "        ],\n",
    "        \"pooler\": {\n",
    "            \"type\": tune.choice([\"gru\", \"lstm\"]),\n",
    "            \"num_layers\": 1,\n",
    "            \"hidden_size\": tune.choice([32,64,128,256]),\n",
    "            \"bidirectional\": tune.choice([True, False]),\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "trainer_dict = {\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"adamw\",\n",
    "        \"lr\": tune.loguniform(1e-5, 1e-4),\n",
    "        \"weight_decay\": tune.loguniform(2e-3, 6e-2 )\n",
    "    },\n",
    "    \"learning_rate_scheduler\": {\n",
    "        \"type\": \"linear_with_warmup\",\n",
    "        \"num_epochs\": 10,\n",
    "        \"num_steps_per_epoch\": int(math.floor(len(training_ds)/batch_size)),\n",
    "        \"warmup_steps\": 100,\n",
    "    },\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": 10,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_alg = HyperOptSearch(metric=\"validation_macro/fscore\", mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_exp = TuneExperiment(\n",
    "    pipeline_config=pipeline_dict, \n",
    "    trainer_config=trainer_dict,\n",
    "    train_dataset=training_ds,\n",
    "    valid_dataset=validation_ds,\n",
    "    name=\"rubrix_guide\",\n",
    "    # parameters for tune.run\n",
    "    num_samples=100,\n",
    "    local_dir=\"tune_runs\",\n",
    "    resources_per_trial={\"cpu\": 2, \"gpu\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_frozen = tune.run(\n",
    "    tune_exp,\n",
    "    scheduler=tune.schedulers.ASHAScheduler(), \n",
    "    config=tune_exp.config,\n",
    "    metric=\"validation_macro/fscore\",\n",
    "    search_alg=search_alg,\n",
    "    mode=\"max\",\n",
    "    progress_reporter=tune.JupyterNotebookReporter(overwrite=True),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f338a8622467eba0ef87b9a79c52cc260cef0b0d60c3c739596fb787bf801dd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
