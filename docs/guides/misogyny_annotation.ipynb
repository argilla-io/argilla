{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Annotate new data to improve Misogyny Detection models using Rubrix and biome.text\n",
    "\n",
    "Hey there! In this guide, we will show you how we used Rubrix to annotate new data and use this new data to improve existing Deep Learning models. Our use case was Automatic Misogyny Detection (AMI): NLP models able to detect the underlying misogyny on a given text. Ground-breaking work is being made every year on this subject, with shared tasks and new models that push the performance of these models closer and closer to be implemented in apps, social networks, and other digital environments. \n",
    "\n",
    "Alongside Rubrix, we used our amazing NLP libary [biome.text](https://github.com/recognai/biome-text) to train models with a simple workflow. Rubrix is compatible with almost any library or service, so we were able to work back and forth with both of them. \n",
    "\n",
    "If it's your first time around, we recomend to start by reading our documentation [front page](https://docs.rubrix.ml/en/stable/). After that, you can continue by reading the Getting Started section. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Our objective\n",
    "\n",
    "One of our team members, Ignacio, was preparing his Bachelor's thesis on the subject of Automatic Misogyny Detection. In this setting, we wanted to use the potential of Rubrix on our favor, going beyond the classic linear workflows that are so common in Deep Learning: gathering some data, preprocessing it, training a model and start making inference. Rubrix breaks that scheme, and allowed us to use a man-in-the-middle approach with retraining and fine-tuning and to add new data in follow-up trainings. \n",
    "\n",
    "We want to talk you more about it in this guide. It is not intended to be a tutorial, even though there will be snippets of code to reproduce our process and get to similar result (we will simplify some aspects of it to keep it light-weighted), but more of a story. We will focus on the process and on what we learnt along the way. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Background\n",
    "\n",
    "The Bachelor's thesis of Ignacio was focused on the Spanish language, and datasets of misogyny in Spanish text is nothing but scarce. This was the first hardship: finding datasets to start training some models. Luckily, there is a very important community of shared tasks focused on the matter, covering a lot of non-English languages. We started working with data from [IberEval 2018](https://sites.google.com/view/ibereval-2…), a shared-task that offered a compilation of tweets, analyzed by experts and classified into 5 different misogyny categories. We started training our first model with around three thousand instances of annotated data. \n",
    "\n",
    "Afterwards, the [EXIST](http://nlp.uned.es/exist2021/) task at [IberLEF 2021](https://sites.google.com/view/iberlef2021) came to our sight. We saw there a perfect opportunity for our work on misogyny detection, for two reasons:\n",
    "\n",
    "*   To test our approach on misogyny detection on a different subdomain, with different data.\n",
    "*   To search for data to expand our three-thousand-or-so instances.\n",
    "\n",
    "We covered our participation in the EXIST task in an [entry of our blogpost](https://medium.com/recognai/against-sexism-like-a-machine-2ae9227881ef). After we submitted our runs, we shifted our efforts towards integrating these new data into our corpus. The categorization was different: IberEval 2018 used a categorization system of 5 categories and 2 targets, but IberLEF 2021 didn't have a target field, and its categories were different. \n",
    "\n",
    "With the classic approach of Deep Learning, our journey would have ended there, with two different, incompatible datasets. But, thanks to Rubrix, it was only the beginning. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Annotation as a single agent\n",
    "\n",
    "Our objective was to adapt data from EXIST shared task to the standard of IberLEF 2021. Therefore, as single annotators, we uploaded the dataset from IberLEF 2021, and begin to explore its predictions and annotations.\n",
    "\n",
    "If you want to upload the training set of the EXIST task, follow the snippet below:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "annotation_df = pd.read_csv('https://raw.githubusercontent.com/ignacioct/Temis/main/datasets/IberLEF%202021/Spanish/EXIST2021_test_labeled_spanish.csv')\n",
    "\n",
    "records = []\n",
    "\n",
    "for index, row in annotation_df.iterrows():\n",
    "\n",
    "    item = rb.TextClassificationRecord(\n",
    "        id=index,\n",
    "        inputs={\n",
    "            \"text\": row[\"text\"]\n",
    "        },\n",
    "        multi_label=True,\n",
    "        metadata={\n",
    "            \"task1_annotation\": row['task1'],\n",
    "            \"task2_annotation\": row['task2'],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    records.append(item)\n",
    "\n",
    "rb.log(records=records, name=\"single_annotation\", tags={\"project\": \"misogyny\", \"annotator\": \"ignacio\"})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once we've logged our annotation dataset into Rubrix, we can start annotating on the UI. Let's quickly remember how it's done\n",
    "\n",
    "1. Open Rubrix in your browser. If you're running it locally, it is usually running on [http://localhost:6900](http://localhost:6900).\n",
    "2. Select the `single_annotation` dataset.\n",
    "3. On the upper-right corner, toggle the `Annotation mode`. \n",
    "4. Start selecting the categories that you think fit the input text. If you don't know Spanish, don't worry! 15 instances are not going to change the final model that much, and you will still learn how to annotate.\n",
    "5. For each instance you can annotate a category by pressing it, discarding the record (if you think it does not fit the problem domain), or leave it without an annotation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Annotating as a team\n",
    "\n",
    "We arraged a team of 5 different annotators, which worked over a week to transform instances from the EXIST standard to the one from IberEval 2018. For doing so, we needed a way to merge several annotations of the same instance into one, preserving the will of the majority, and that's when the Inter-Annotator Agreement (IAA) comes in handy. There many different types of IAAs, some based on rules and others based on statistics.\n",
    "\n",
    "Here's a simplifaction of our IAA as a rule system:\n",
    "* For an instance to be annotated with a category, there must be consensus of, at least, two annotators.\n",
    "* If there's consensus in an sexism category, and other annotators find there's no sexism in the instance, it will be discarded.\n",
    "\n",
    "Our team of annotators was formed by Amélie, Leire, Javier, Víctor and Ignacio. In the next cells, you can find a cell that logs the original annotations made by our annotators (the non-annotated version is the one downloaded in the previous section). After that, we will retrieve these annotated datasets from Rubrix using the `load` command.\n",
    "\n",
    "If you want to explore all the datasets, code and resources used in the whole thesis, you can find them at [Temis Github page](https://github.com/ignacioct/Temis). Come to say hi!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "annotation_1_df = pd.read_json('https://raw.githubusercontent.com/ignacioct/Temis/main/datasets/Annotation/temis_retraining_1.json')\n",
    "annotation_2_df = pd.read_json('https://raw.githubusercontent.com/ignacioct/Temis/main/datasets/Annotation/temis_retraining_2.json')\n",
    "annotation_3_df = pd.read_json('https://raw.githubusercontent.com/ignacioct/Temis/main/datasets/Annotation/temis_retraining_3.json')\n",
    "annotation_4_df = pd.read_json('https://raw.githubusercontent.com/ignacioct/Temis/main/datasets/Annotation/temis_retraining_4.json')\n",
    "annotation_5_df = pd.read_json('https://raw.githubusercontent.com/ignacioct/Temis/main/datasets/Annotation/temis_retraining_5.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's log this information into Rubrix. We are going to an approach similar to our single-agent annotation. We are showing you how to log one of the datasets, you just have to repeat the process and change the names of the logged datasets, so get logged separately, and each agent knows in which dataset she or he should annotate. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import rubrix as rb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "annotation_1_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              inputs  \\\n",
       "0          {'text': 'Y te golpeo más fuerte perra.'}   \n",
       "1  {'text': '@wthxtme @GOLDENMXM Castigado tres m...   \n",
       "2  {'text': '@MaricaIndomito jajajaj el me he top...   \n",
       "3  {'text': 'Resulta que hoy es el día de la juve...   \n",
       "4  {'text': '@EstefMolina_ Los que dicen que cree...   \n",
       "\n",
       "                                          prediction  \\\n",
       "0  [[active, 0.9819192886], [discredit, 0.4090008...   \n",
       "1  [[non-sexist, 1.0], [active, 0.0192600936], [p...   \n",
       "2  [[non-sexist, 1.0], [active, 0.016454557], [di...   \n",
       "3  [[non-sexist, 1.0], [active, 0.019965389700000...   \n",
       "4  [[non-sexist, 1.0], [passive, 0.1393957436], [...   \n",
       "\n",
       "                    annotation  prediction_agent annotation_agent  \\\n",
       "0  [active, sexual_harassment]  temis_multilabel        @recognai   \n",
       "1                         None  temis_multilabel             None   \n",
       "2                         None  temis_multilabel             None   \n",
       "3                         None  temis_multilabel             None   \n",
       "4                         None  temis_multilabel             None   \n",
       "\n",
       "   multi_label  explanation  \\\n",
       "0         True          NaN   \n",
       "1         True          NaN   \n",
       "2         True          NaN   \n",
       "3         True          NaN   \n",
       "4         True          NaN   \n",
       "\n",
       "                                            metadata     status  \\\n",
       "0  {'task1_annotation': 'sexist', 'task2_annotati...  Validated   \n",
       "1  {'task1_annotation': 'non-sexist', 'task2_anno...    Default   \n",
       "2  {'task1_annotation': 'sexist', 'task2_annotati...    Default   \n",
       "3  {'task1_annotation': 'non-sexist', 'task2_anno...    Default   \n",
       "4  {'task1_annotation': 'sexist', 'task2_annotati...    Default   \n",
       "\n",
       "   event_timestamp  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>prediction</th>\n",
       "      <th>annotation</th>\n",
       "      <th>prediction_agent</th>\n",
       "      <th>annotation_agent</th>\n",
       "      <th>multi_label</th>\n",
       "      <th>explanation</th>\n",
       "      <th>metadata</th>\n",
       "      <th>status</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'text': 'Y te golpeo más fuerte perra.'}</td>\n",
       "      <td>[[active, 0.9819192886], [discredit, 0.4090008...</td>\n",
       "      <td>[active, sexual_harassment]</td>\n",
       "      <td>temis_multilabel</td>\n",
       "      <td>@recognai</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'task1_annotation': 'sexist', 'task2_annotati...</td>\n",
       "      <td>Validated</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'text': '@wthxtme @GOLDENMXM Castigado tres m...</td>\n",
       "      <td>[[non-sexist, 1.0], [active, 0.0192600936], [p...</td>\n",
       "      <td>None</td>\n",
       "      <td>temis_multilabel</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'task1_annotation': 'non-sexist', 'task2_anno...</td>\n",
       "      <td>Default</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'text': '@MaricaIndomito jajajaj el me he top...</td>\n",
       "      <td>[[non-sexist, 1.0], [active, 0.016454557], [di...</td>\n",
       "      <td>None</td>\n",
       "      <td>temis_multilabel</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'task1_annotation': 'sexist', 'task2_annotati...</td>\n",
       "      <td>Default</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'text': 'Resulta que hoy es el día de la juve...</td>\n",
       "      <td>[[non-sexist, 1.0], [active, 0.019965389700000...</td>\n",
       "      <td>None</td>\n",
       "      <td>temis_multilabel</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'task1_annotation': 'non-sexist', 'task2_anno...</td>\n",
       "      <td>Default</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'text': '@EstefMolina_ Los que dicen que cree...</td>\n",
       "      <td>[[non-sexist, 1.0], [passive, 0.1393957436], [...</td>\n",
       "      <td>None</td>\n",
       "      <td>temis_multilabel</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'task1_annotation': 'sexist', 'task2_annotati...</td>\n",
       "      <td>Default</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "records = []\n",
    "\n",
    "for index, row in annotation_1_df.iterrows():\n",
    "\n",
    "    item = rb.TextClassificationRecord(\n",
    "        id=index,\n",
    "        inputs={\n",
    "            \"text\": row[\"text\"]\n",
    "        },\n",
    "        annotation=row[\"annotation\"],\n",
    "        annotation_agent=\"annotator 1\",\n",
    "        multi_label=True,\n",
    "        metadata={\n",
    "            \"task1_annotation\": row['task1'],\n",
    "            \"task2_annotation\": row['task2'],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    records.append(item)\n",
    "\n",
    "rb.log(records=records, name=\"annotation_misogyny_1\", tags={\"project\": \"misogyny\", \"annotator\": \"annotator 1\"})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One thing that should be remember is that, for divulgative purpouses, we are simplyfing the complexity of the problem. You can find more information about how the labels in which our agents annotated are divided into two subcategories [here](https://github.com/ignacioct/Temis#predictions).\n",
    "\n",
    "After our logging and exploration, we can go ahead and load these datasets from Rubrix."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "annotation_1 = rb.load(\"annotation_misogyny_1\").set_index(\"id\").sort_index()\n",
    "annotation_2 = rb.load(\"annotation_misogyny_2\").set_index(\"id\").sort_index()\n",
    "annotation_3 = rb.load(\"annotation_misogyny_3\").set_index(\"id\").sort_index()\n",
    "annotation_4 = rb.load(\"annotation_misogyny_4\").set_index(\"id\").sort_index()\n",
    "annotation_5 = rb.load(\"annotation_misogyny_5\").set_index(\"id\").sort_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`rb.load()` returns a Pandas Dataframe. We will use this library to merge our annotations into a single dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We will use this tool to count ocurrences in list\n",
    "from collections import Counter\n",
    "\n",
    "annotation_final = pd.DataFrame(columns=['id','text', 'annotation', 'annotation_agent'])\n",
    "\n",
    "# Iterating through the datasets, all of them has the same length\n",
    "for i in range(len(annotation_anna)):\n",
    "    \n",
    "    # Extracting the annotated categories by each annotator\n",
    "    category_annotated_anna = annotation_anna.iloc[i][\"annotation\"]\n",
    "    category_annotated_bob = annotation_bob.iloc[i][\"annotation\"]\n",
    "    category_annotated_celia = annotation_celia.iloc[i][\"annotation\"]\n",
    "    \n",
    "    # Merging the annotations into a list\n",
    "    annotated_categories = [category_annotated_anna, category_annotated_bob, category_annotated_celia]\n",
    "    # Flattening the list (if there is annotation, it is saved as an individual list)\n",
    "    if not None in annotated_categories:\n",
    "        annotated_categories = [item for sublist in annotated_categories for item in sublist] \n",
    "    \n",
    "    # If all the elements in the list are None, we can return 'non-annotated'\n",
    "    if all(annotation is None for annotation in annotated_categories):\n",
    "        merged_annotation = 'non-annotated'    \n",
    "    \n",
    "    # Counting the annotations\n",
    "    counted_annotations = Counter(annotated_categories)\n",
    "    \n",
    "    # Checking if the element with the most number of annotations follows the rules to be annotated\n",
    "    if counted_annotations[max(counted_annotations, key=counted_annotations.get)] >= 2 and \"0\" not in counted_annotations:\n",
    "        merged_annotation = max(counted_annotations, key=counted_annotations.get)\n",
    "        \n",
    "    else:\n",
    "        merged_annotation = 'no-consensus'\n",
    "        \n",
    "        \n",
    "    # As all elements in each row of the DataFrame except the annotations are the same, we can\n",
    "    # retrieve information from any of the annotators. In our case is Anna.\n",
    "    annotation_final = annotation_final.append({\n",
    "        'id': annotation_anna.iloc[i][\"metadata\"][\"id\"],\n",
    "        'text': annotation_anna.iloc[i][\"inputs\"][\"text\"],\n",
    "        'annotation': merged_annotation,\n",
    "        'annotation_agent': 'Anna, Bob and Celia',\n",
    "    }, ignore_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Appendix\n",
    "\n",
    "Here are some procedures we've made for this guide that were kept on the background. If you want to reproduce all our steps, including the training of models and some extra parts, we will give provide with cells to do so! Feel free to change anything and try new stuff, and tell us if you have some doubts our find something cool at our [Github forum](https://github.com/recognai/rubrix/discussions)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dependencies & Installs\n",
    "\n",
    "During this guide, we've provided some minimal code for our use case. However, to reproduce exactly our process, you will firstly need to install Rubrix, biome.text and pandas. We will also import them."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%pip install -U git+https://github.com/recognai/biome-text\n",
    "%pip install rubrix\n",
    "%pip install pandas\n",
    "exit(0)  # Force restart of the runtime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from biome.text import *\n",
    "import pandas as pd\n",
    "import rubrix as rb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training our first model\n",
    "\n",
    "To reproduce a simplified version of the first trained model, before annotation, you can execute the following cells. We've already searched for good-enough configurations, so you can skip that step.\n",
    "\n",
    "Let's start by loading the datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Loading the datasets\n",
    "training_ds = Dataset.from_csv('https://raw.githubusercontent.com/ignacioct/Temis/main/datasets/IberEval%202018/training_full_df.csv', index=False)\n",
    "test_ds = Dataset.from_csv('https://raw.githubusercontent.com/ignacioct/Temis/main/datasets/IberEval%202018/test_df.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating NLP pipelines with biome.text is quick and convenient! We performed an HPO process on the background, to find suitable hyperparameters for this domain, so let's use them to create our first AMI model. Note that we're making a pipeline with BETO, a Spanish Transformer model, at the head. To learn more about what a Transformer is, please visit the [Transformer guide of biome.text](https://recognai.github.io/biome-text/v3.0.0/documentation/tutorials/4-Using_Transformers_in_biome_text.html)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pipeline_dict = {\n",
    "    \"name\": \"AMI_first_model\",\n",
    "    \"features\": {\n",
    "        \"transformers\": {\n",
    "            \"model_name\": \"dccuchile/bert-base-spanish-wwm-cased\", # BETO model\n",
    "            \"trainable\": True,\n",
    "            \"max_length\": 280,  # As we are working with data from Twitter, this is our max length\n",
    "        }\n",
    "    },\n",
    "    \"head\": {\n",
    "        \"type\": \"TextClassification\",\n",
    "        \n",
    "        # These are the possible misogyny categories.\n",
    "        \"labels\": [\n",
    "            'sexual_harassment',\n",
    "             'dominance',\n",
    "             'discredit',\n",
    "             'stereotype',\n",
    "             'derailing',\n",
    "             'non-sexist'\n",
    "        ],\n",
    "        \"pooler\": {\n",
    "            \"type\": \"lstm\",\n",
    "            \"num_layers\": 1,\n",
    "            \"hidden_size\": 256,\n",
    "            \"bidirectional\": True,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "pl = Pipeline.from_config(pipeline_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer_config = TrainerConfiguration(\n",
    "    optimizer={\n",
    "        \"type\": \"adamw\",\n",
    "        \"lr\": 0.000023636840436059507,\n",
    "        \"weight_decay\": 0.01438297700463013,\n",
    "    },\n",
    "    batch_size=8,\n",
    "    max_epochs=10,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer = Trainer(\n",
    "    pipeline=pl,\n",
    "    train_dataset=training_ds,\n",
    "    valid_dataset=test_ds,\n",
    "    trainer_config=trainer_config\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainer.fit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After `trainer.fit()` stops, the results of the training and the obtained model will be in the output folder."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can make some predictions, and take a look at the performance of the model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pl.predict(\"Las mujeres no deberían tener derecho a voto\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cac2ad44382dcbde9c9d45667b9ac0fec163e57feefe7fa8ea5d11fd16eb612"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('rubrix': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}