{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd00f338a8622467eba0ef87b9a79c52cc260cef0b0d60c3c739596fb787bf801dd",
   "display_name": "Python 3.8.10 64-bit ('rubrix': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Rubrix Cookbook\n",
    "\n",
    "Yeah, you heard it right! Not a cheatsheet, but a cookbook. A notebook of recipes. \n",
    "\n",
    "In this quick guide, we are going to show you how easy can Rubrix be used side by side with some of the most popular AI Python libraries. Rubrix is *agnostic*, it can be used  with any library or framework, no need to implement any interface or modify your existing toolbox and workflows. With these few example you will be able to start loging and exploring your data for any of these libraries with just a glance, and maybe pick up some inspiration if your library of choice is not in this list.\n",
    "\n",
    "If you miss one AI library in this list, tell us about it at [our Github forum](https://github.com/recognai/rubrix/discussions)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## HuggingFace Transformers\n",
    "\n",
    "[HuggingFace](https://huggingface.co) has given to the NLP community many useful tools, and with HuggingFace Transformers produce cutting-edge models is easier than ever. With a few lines of code we can take a Transformer model from their hub, start making some predictions and then log them into Rubrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Classification\n",
    "\n",
    "Let's try a zero-shot classifier using SqueezeBERT for predicting the topic of a sentence."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='zeroshot-topic-classifier', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from transformers import pipeline\n",
    "\n",
    "text_input = \"I love watching rock climbing competitions!\"\n",
    "\n",
    "# We define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"typeform/squeezebert-mnli\",\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "# Making the prediction\n",
    "prediction = classifier(\n",
    "    text_input,\n",
    "    candidate_labels=[\n",
    "        \"politics\",\n",
    "        \"sports\",\n",
    "        \"technology\",\n",
    "    ],\n",
    "    hypothesis_template=\"This text is about {}.\",\n",
    ")\n",
    "\n",
    "# Creating a record object to log into rubrix.\n",
    "record = rb.TextClassificationRecord(\n",
    "    inputs={\"text\": prediction[\"sequence\"]},\n",
    "    prediction=list(zip(prediction[\"labels\"], prediction[\"scores\"])),\n",
    "    prediction_agent=\"https://huggingface.co/typeform/squeezebert-mnli\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"zeroshot-topic-classifier\")"
   ]
  },
  {
   "source": [
    "### Token Classification\n",
    "\n",
    "We will explore a NER zero-shot classifier in the English language."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='zeroshot-ner', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from transformers import pipeline\n",
    "\n",
    "text_input = \"My name is Sarah and I live in London\"\n",
    "\n",
    "# We define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "    \"ner\",\n",
    "    model=\"elastic/distilbert-base-cased-finetuned-conll03-english\",\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "# Making the prediction\n",
    "predictions = classifier(\n",
    "    text_input,\n",
    ")\n",
    "\n",
    "# Creating a record object to log into rubrix.\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=text_input,\n",
    "    tokens=text_input.split(),\n",
    "    prediction=[(pred[\"entity\"], pred[\"start\"], pred[\"end\"]) for pred in predictions],\n",
    "    prediction_agent=\"https://huggingface.co/elastic/distilbert-base-cased-finetuned-conll03-english\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"zeroshot-ner\")\n"
   ]
  },
  {
   "source": [
    "## spaCy\n",
    "\n",
    "One of the queens and kings of NLP libraries. [spaCy](https://spacy.io) offers industrial-strength Natural Language Processing, with support for 64+ languages, 55 trained pipelines for 17 languages, multi-task learning with pretrained transformers like BERT, pretrained word vectors and much more. Combining spaCy with Rubrix allows you to combine these learning capabilities with the power to monitor your predictions, collect and iterate through ground truth and build custom applications and dashboards."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Token Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='lesmiserables-ner', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "import spacy\n",
    "\n",
    "input_text = \"Paris a un enfant et la forêt a un oiseau ; l’oiseau s’appelle le moineau ; l’enfant s’appelle le gamin\"\n",
    "\n",
    "# Loading spaCy model\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Creating spaCy doc\n",
    "doc = nlp(input_text)\n",
    "\n",
    "# Building TokenClassificationRecord\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=input_text,\n",
    "    tokens=[token.text for token in doc],\n",
    "    prediction=[(ent.label_, ent.start_char, ent.end_char) for ent in doc.ents],\n",
    "    prediction_agent=\"spacy.fr_core_news_sm\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"lesmiserables-ner\")"
   ]
  },
  {
   "source": [
    "## Flair\n",
    "\n",
    "Developed by the University of Berlin, it is a simple, yet powerful state-of-the-art NLP framework. Itprovides an NLP library, a text embedding library and a PyTorch framework for NLP. [Flair](https://github.com/flairNLP/flair) offers sequence tagging language models in English, Spanish, Dutch, German and many more, and they are also hosted on [HuggingFace Model Hub](https://huggingface.co/models)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Classification\n",
    "\n",
    "Flair offers some zero-shot models ready to be used, which we are going to use to introduce logging `TextClassificationRecords` with Rubrix. Let's see how to integrate Rubrix in their Deutch offensive language model (we promise to not get very explicit)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-05-29 21:50:30,492 loading file /Users/ignaciotalaveracepeda/.flair/models/germ-eval-2018-task-1-v0.5.pt\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='german-offensive-language', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "input_text = \"Du erzählst immer Quatsch.\"  # something like: \"You are always narrating silliness.\"\n",
    "\n",
    "# Load our pre-trained TARS model for English\n",
    "classifier = TextClassifier.load(\"de-offensive-language\")\n",
    "\n",
    "# Creating Sentence object\n",
    "sentence = Sentence(input_text)\n",
    "\n",
    "# Make the prediction\n",
    "classifier.predict(sentence, multi_class_prob=True)\n",
    "\n",
    "# Creating a record object to log into rubrix.\n",
    "record = rb.TextClassificationRecord(\n",
    "    inputs={\"text\": input_text},\n",
    "    prediction=[(pred.value, pred.score) for pred in sentence.labels],\n",
    "    prediction_agent=\"de-offensive-language\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"german-offensive-language\")"
   ]
  },
  {
   "source": [
    "### Token Classification\n",
    "\n",
    "Flair offers a lot of tools for Token Classification, supporting tasks like named entity recognition (NER), part-of-speech tagging (POS), special support for biomedical data... and with a growing number of supported languages. Lets see some examples for NER and POS tagging."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### NER\n",
    "\n",
    "In this example, we will try the pretrained Dutch NER model from Flair."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-05-29 21:50:34,951 loading file /Users/ignaciotalaveracepeda/.flair/models/ner-dutch/fd03fc5c7a02268a538432a010f4d09ec15e55fe70efd02dfea158916fa4cba8.04438768e42ba7d6599cea01fcabf77563c8c7e2b27a245618f0ed535ad8919c\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='dutch-flair-ner', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "input_text = \"De Nachtwacht is in het Rijksmuseum\"\n",
    "\n",
    "# Loading our NER model\n",
    "tagger = SequenceTagger.load('flair/ner-dutch')\n",
    "\n",
    "# Creating Sentence object\n",
    "sentence = Sentence(input_text)\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# Building TokenClassificationRecord\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=input_text,\n",
    "    tokens=[token.text for token in sentence],\n",
    "    prediction=[(entity.get_labels()[0].value, entity.start_pos, entity.end_pos) for entity in sentence.get_spans('ner')],\n",
    "    prediction_agent=\"flair/ner-dutch\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"dutch-flair-ner\")"
   ]
  },
  {
   "source": [
    "#### POS tagging\n",
    "\n",
    "In the following snippet we will use de multilingual POS tagging model from Flair."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-05-29 21:50:51,193 loading file /Users/ignaciotalaveracepeda/.flair/models/upos-multi/1a44f168663182024fd3ea6d7dcaeee47fe5bcb537cc737ad058b64ad4db9736.5f899f25846741510a6567b89027d988bd6f634b2776a7c3e834fea4629367cb\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='flair-pos-tagging', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "input_text = \"George Washington went to Washington. Dort kaufte er einen Hut.\"\n",
    "\n",
    "# Loading our NER model\n",
    "tagger = SequenceTagger.load(\"flair/upos-multi\")\n",
    "\n",
    "# Creating Sentence object\n",
    "sentence = Sentence(input_text)\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# Building TokenClassificationRecord\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=input_text,\n",
    "    tokens=[token.text for token in sentence],\n",
    "    prediction=[\n",
    "        (entity.get_labels()[0].value, entity.start_pos, entity.end_pos)\n",
    "        for entity in sentence.get_spans()\n",
    "    ],\n",
    "    prediction_agent=\"flair/upos-multi\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"flair-pos-tagging\")"
   ]
  },
  {
   "source": [
    "## Stanza\n",
    "\n",
    "[Stanza]() is a collection of efficient tools for many NLP tasks and processes, all in one library. It was created and it's maintained by the [Standford NLP Group](https://nlp.stanford.edy). We are going to take a look at a few interactions that can be done with Rubrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Classification\n",
    "\n",
    "Let's start by using a Sentiment Analysis model to log some `TextClassificationRecords`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 28.3MB/s]                    \n",
      "2021-05-30 10:43:52 INFO: Downloading default packages for language: en (English)...\n",
      "2021-05-30 10:43:57 INFO: File exists: /Users/ignaciotalaveracepeda/stanza_resources/en/default.zip.\n",
      "2021-05-30 10:44:05 INFO: Finished downloading models and saved to /Users/ignaciotalaveracepeda/stanza_resources.\n",
      "2021-05-30 10:44:05 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2021-05-30 10:44:05 INFO: Use device: cpu\n",
      "2021-05-30 10:44:05 INFO: Loading: tokenize\n",
      "2021-05-30 10:44:05 INFO: Loading: sentiment\n",
      "2021-05-30 10:44:06 INFO: Done loading processors!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='stanza-sentiment', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "import stanza\n",
    "\n",
    "input_text = (\n",
    "    \"There are so many NLP libraries available, I don't know which one to choose!\"\n",
    ")\n",
    "\n",
    "# Downloading our model, in case we don't have it cached\n",
    "stanza.download(\"en\")\n",
    "\n",
    "# Creating the pipeline\n",
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize,sentiment\")\n",
    "\n",
    "# Analizing the input text\n",
    "doc = nlp(input_text)\n",
    "\n",
    "# This model returns 0 for negative, 1 for neutral and 2 for positive outcome.\n",
    "# We are going to log them into Rubrix using a dictionary to translate numbers to labels.\n",
    "num_to_labels = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "\n",
    "# Build a prediction entities list\n",
    "# Stanza, at the moment, only output the most likely label without probability.\n",
    "# So we will suppouse Stanza predicts the most likely label with 1.0 probability, and the rest with 0.\n",
    "entities = []\n",
    "\n",
    "for key in num_to_labels:\n",
    "    if key == sentence.sentiment:\n",
    "        entities.append((num_to_labels[key], 1))\n",
    "    else:\n",
    "        entities.append((num_to_labels[key], 0))\n",
    "\n",
    "# Creating a record object to log into rubrix.\n",
    "record = rb.TextClassificationRecord(\n",
    "    inputs={\"text\": input_text},\n",
    "    prediction=entities,\n",
    "    prediction_agent=\"stanza/en\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"stanza-sentiment\")"
   ]
  },
  {
   "source": [
    "### Token Classification\n",
    "\n",
    "Stanza offers so many different pretrained language models for Token Classification Tasks, and the list does not stop growing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### POS tagging\n",
    "\n",
    "We can use one of the many UD models, used for POS tags, morphological features and syntantic relations. UD stands for [Universal Dependencies](https://universaldependencies.org), the framework where these models has been trained. For this example, let's try to extract POS tags of some Catalan lyrics."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 12.1MB/s]                    \n",
      "2021-05-30 11:02:04 INFO: Downloading default packages for language: ca (Catalan)...\n",
      "2021-05-30 11:02:06 INFO: File exists: /Users/ignaciotalaveracepeda/stanza_resources/ca/default.zip.\n",
      "2021-05-30 11:02:16 INFO: Finished downloading models and saved to /Users/ignaciotalaveracepeda/stanza_resources.\n",
      "2021-05-30 11:02:16 INFO: Loading these models for language: ca (Catalan):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "=======================\n",
      "\n",
      "2021-05-30 11:02:16 INFO: Use device: cpu\n",
      "2021-05-30 11:02:16 INFO: Loading: tokenize\n",
      "2021-05-30 11:02:16 INFO: Loading: mwt\n",
      "2021-05-30 11:02:16 INFO: Loading: pos\n",
      "2021-05-30 11:02:17 INFO: Done loading processors!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='stanza-catalan-pos', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "import stanza\n",
    "\n",
    "# Loading a cool Obrint Pas lyric\n",
    "input_text = \"Viure mantenint viva la flama a través del temps. La flama de tot un poble en moviment\" \n",
    "\n",
    "# Downloading our model, in case we don't have it cached\n",
    "stanza.download(\"ca\")\n",
    "\n",
    "# Creating the pipeline\n",
    "nlp = stanza.Pipeline(lang=\"ca\", processors=\"tokenize,mwt,pos\")\n",
    "\n",
    "# Analizing the input text\n",
    "doc = nlp(input_text)\n",
    "\n",
    "# Building TokenClassificationRecord\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=input_text,\n",
    "    tokens=[word.text for sent in doc.sentences for word in sent.words],\n",
    "    prediction=[\n",
    "        (word.pos, token.start_char, token.end_char)\n",
    "        for sent in doc.sentences\n",
    "        for token in sent.tokens\n",
    "        for word in token.words\n",
    "    ],\n",
    "    prediction_agent=\"flair/catalan\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"stanza-catalan-pos\")"
   ]
  },
  {
   "source": [
    "#### NER\n",
    "\n",
    "Stanza also offers a list of available pretrained models for NER tasks. So, let's try Russian"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 2.98MB/s]                    \n",
      "2021-05-30 11:24:03 INFO: Downloading default packages for language: ru (Russian)...\n",
      "2021-05-30 11:24:06 INFO: File exists: /Users/ignaciotalaveracepeda/stanza_resources/ru/default.zip.\n",
      "2021-05-30 11:24:13 INFO: Finished downloading models and saved to /Users/ignaciotalaveracepeda/stanza_resources.\n",
      "2021-05-30 11:24:13 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| ner       | wikiner   |\n",
      "=========================\n",
      "\n",
      "2021-05-30 11:24:13 INFO: Use device: cpu\n",
      "2021-05-30 11:24:13 INFO: Loading: tokenize\n",
      "2021-05-30 11:24:13 INFO: Loading: ner\n",
      "2021-05-30 11:24:16 INFO: Done loading processors!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='stanza-russian-ner', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "import stanza\n",
    "\n",
    "input_text = \"Герра-и-Пас - одна из моих любимых книг\" #War and Peace is one my favourite books\n",
    "\n",
    "# Downloading our model, in case we don't have it cached\n",
    "stanza.download(\"ru\")\n",
    "\n",
    "# Creating the pipeline\n",
    "nlp = stanza.Pipeline(lang=\"ru\", processors=\"tokenize,ner\")\n",
    "\n",
    "# Analizing the input text\n",
    "doc = nlp(input_text)\n",
    "\n",
    "# Building TokenClassificationRecord\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=input_text,\n",
    "    tokens=[word.text for sent in doc.sentences for word in sent.words],\n",
    "    prediction=[\n",
    "        (token.ner, token.start_char, token.end_char)\n",
    "        for sent in doc.sentences\n",
    "        for token in sent.tokens\n",
    "    ],\n",
    "    prediction_agent=\"flair/russian\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"stanza-russian-ner\")"
   ]
  }
 ]
}