{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd00f338a8622467eba0ef87b9a79c52cc260cef0b0d60c3c739596fb787bf801dd",
   "display_name": "Python 3.8.10 64-bit ('rubrix': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Rubrix Cookbook\n",
    "\n",
    "Yeah, you heard it right! Not a cheatsheet, but a cookbook. A notebook of recipes. \n",
    "\n",
    "In this quick guide, we are going to show you how easy can Rubrix be used side by side with some of the most popular AI Python libraries. Rubrix is *agnostic*, it can be used  with any library or framework, no need to implement any interface or modify your existing toolbox and workflows. With these few example you will be able to start loging and exploring your data for any of these libraries with just a glance, and maybe pick up some inspiration if your library of choice is not in this list.\n",
    "\n",
    "If you miss one AI library in this list, tell us about it at [our Github forum](https://github.com/recognai/rubrix/discussions)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## HuggingFace Transformers\n",
    "\n",
    "HuggingFace has given to the NLP community many useful tools, and with HuggingFace Transformers is easier than ever. With a few lines of code we can take a Transformer model from their hub, start making some predictions and then log them into Rubrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='zeroshot-topic-classifier', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from transformers import pipeline\n",
    "\n",
    "# We define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "        \"zero-shot-classification\",\n",
    "        model=\"typeform/squeezebert-mnli\",\n",
    "        framework=\"pt\",\n",
    "    )\n",
    "    \n",
    "# Choosing our input\n",
    "text_input = \"I love watching rock climbing competitions!\"\n",
    "\n",
    "# Making the prediction\n",
    "prediction = classifier(\n",
    "    text_input,\n",
    "    candidate_labels=[\n",
    "        \"politics\",\n",
    "        \"sports\",\n",
    "        \"technology\",\n",
    "    ],\n",
    "    hypothesis_template=\"This text is about {}.\",\n",
    ")\n",
    "\n",
    "# Creating a record object to log into rubrix.\n",
    "record = rb.TextClassificationRecord(\n",
    "    inputs={\"text\": prediction[\"sequence\"]},\n",
    "    prediction=list(zip(prediction[\"labels\"], prediction[\"scores\"])),\n",
    "    prediction_agent=\"https://huggingface.co/typeform/squeezebert-mnli\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"zeroshot-topic-classifier\")"
   ]
  },
  {
   "source": [
    "### Token Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='zeroshot-ner', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from transformers import pipeline\n",
    "\n",
    "# We define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "        \"ner\",\n",
    "        model=\"elastic/distilbert-base-cased-finetuned-conll03-english\",\n",
    "        framework=\"pt\",\n",
    "    )\n",
    "\n",
    "# Choosing our input\n",
    "text_input = \"My name is Sarah and I live in London\"\n",
    "\n",
    "# Making the prediction\n",
    "predictions = classifier(\n",
    "    text_input,\n",
    ")\n",
    "\n",
    "# Creating a record object to log into rubrix.\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=text_input,\n",
    "    tokens=text_input.split(),\n",
    "    prediction=[(pred[\"entity\"], pred[\"start\"], pred[\"end\"]) for pred in predictions],\n",
    "    prediction_agent=\"https://huggingface.co/elastic/distilbert-base-cased-finetuned-conll03-english\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=[record], name=\"zeroshot-ner\")"
   ]
  }
 ]
}