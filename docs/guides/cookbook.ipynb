{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd00f338a8622467eba0ef87b9a79c52cc260cef0b0d60c3c739596fb787bf801dd",
   "display_name": "Python 3.8.10 64-bit ('rubrix': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Rubrix Cookbook\n",
    "\n",
    "Yeah, you heard it right! Not a cheatsheet, but a cookbook. A notebook of recipes. \n",
    "\n",
    "In this quick guide, we are going to show you how easy can Rubrix be used side by side with some of the most popular AI Python libraries. Rubrix is *agnostic*, it can be used  with any library or framework, no need to implement any interface or modify your existing toolbox and workflows. With these few example you will be able to start loging and exploring your data for any of these libraries with just a glance, and maybe pick up some inspiration if your library of choice is not in this list.\n",
    "\n",
    "If you miss one AI library in this list, tell us about it at [our Github forum](https://github.com/recognai/rubrix/discussions)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## HuggingFace Transformers\n",
    "\n",
    "HuggingFace has given to the NLP community many useful tools, and with HuggingFace Transformers is easier than ever. With a few lines of code we can take a Transformer model from their hub, start making some predictions and then log them into Rubrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='zeroshot-topic-classifier', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from transformers import pipeline\n",
    "\n",
    "# We define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "        \"zero-shot-classification\",\n",
    "        model=\"typeform/squeezebert-mnli\",\n",
    "        framework=\"pt\",\n",
    "    )\n",
    "    \n",
    "# Choosing our input\n",
    "text_input = \"I love watching rock climbing competitions!\"\n",
    "\n",
    "# Making the prediction\n",
    "prediction = classifier(\n",
    "    text_input,\n",
    "    candidate_labels=[\n",
    "        \"politics\",\n",
    "        \"sports\",\n",
    "        \"technology\",\n",
    "    ],\n",
    "    hypothesis_template=\"This text is about {}.\",\n",
    ")\n",
    "\n",
    "# Creating a record object to log into rubrix.\n",
    "record = rb.TextClassificationRecord(\n",
    "    inputs={\"text\": prediction[\"sequence\"]},\n",
    "    prediction=list(zip(prediction[\"labels\"], prediction[\"scores\"])),\n",
    "    prediction_agent=\"https://huggingface.co/typeform/squeezebert-mnli\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"zeroshot-topic-classifier\")"
   ]
  },
  {
   "source": [
    "### Token Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='zeroshot-ner', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from transformers import pipeline\n",
    "\n",
    "# We define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "        \"ner\",\n",
    "        model=\"elastic/distilbert-base-cased-finetuned-conll03-english\",\n",
    "        framework=\"pt\",\n",
    "    )\n",
    "\n",
    "# Choosing our input\n",
    "text_input = \"My name is Sarah and I live in London\"\n",
    "\n",
    "# Making the prediction\n",
    "predictions = classifier(\n",
    "    text_input,\n",
    ")\n",
    "\n",
    "# Creating a record object to log into rubrix.\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=text_input,\n",
    "    tokens=text_input.split(),\n",
    "    prediction=[(pred[\"entity\"], pred[\"start\"], pred[\"end\"]) for pred in predictions],\n",
    "    prediction_agent=\"https://huggingface.co/elastic/distilbert-base-cased-finetuned-conll03-english\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"zeroshot-ner\")"
   ]
  },
  {
   "source": [
    "## Spacy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Token Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting fr_core_news_sm==2.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.3.0/fr_core_news_sm-2.3.0.tar.gz (14.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.7 MB 9.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from fr_core_news_sm==2.3.0) (2.3.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (4.49.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (3.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (0.7.4)\n",
      "Requirement already satisfied: setuptools in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (2.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (2.25.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.20.3)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (7.4.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/ignaciotalaveracepeda/anaconda3/envs/rubrix/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->fr_core_news_sm==2.3.0) (4.0.0)\n",
      "Building wheels for collected packages: fr-core-news-sm\n",
      "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.3.0-py3-none-any.whl size=14718367 sha256=5eaeec363470c1b2310cc4646840538dcb4f1c6a8c3dbb3058b0de272341c044\n",
      "  Stored in directory: /private/var/folders/mb/lvj4fyds5757cy_7swmlpt_00000gn/T/pip-ephem-wheel-cache-ec51_xp6/wheels/48/ca/2e/2a3756cab2ba8745ce853319ba0d44b1efb8892a86320e9633\n",
      "Successfully built fr-core-news-sm\n",
      "Installing collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-2.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='lesmiserables-ner', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "import spacy\n",
    "\n",
    "input_text = \"Paris a un enfant et la forêt a un oiseau ; l’oiseau s’appelle le moineau ; l’enfant s’appelle le gamin\"\n",
    "\n",
    "# Loading spaCy model\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Creating spaCy doc\n",
    "doc = nlp(input_text)\n",
    "\n",
    "# Building TokenClassificationRecord\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=input_text,\n",
    "    tokens=[token.text for token in doc],\n",
    "    prediction=[(ent.label_, ent.start_char, ent.end_char) for ent in doc.ents],\n",
    "    prediction_agent=\"spacy.fr_core_news_sm\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"lesmiserables-ner\")"
   ]
  }
 ]
}