{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd00f338a8622467eba0ef87b9a79c52cc260cef0b0d60c3c739596fb787bf801dd",
   "display_name": "Python 3.8.10 64-bit ('rubrix': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Rubrix Cookbook\n",
    "\n",
    "Yeah, you heard it right! Not a cheatsheet, but a cookbook. A notebook of recipes. \n",
    "\n",
    "In this quick guide, we are going to show you how easy can Rubrix be used side by side with some of the most popular AI Python libraries. Rubrix is *agnostic*, it can be used  with any library or framework, no need to implement any interface or modify your existing toolbox and workflows. With these few example you will be able to start loging and exploring your data for any of these libraries with just a glance, and maybe pick up some inspiration if your library of choice is not in this list.\n",
    "\n",
    "If you miss one AI library in this list, tell us about it at [our Github forum](https://github.com/recognai/rubrix/discussions)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## HuggingFace Transformers\n",
    "\n",
    "HuggingFace has given to the NLP community many useful tools, and with HuggingFace Transformers is easier than ever. With a few lines of code we can take a Transformer model from their hub, start making some predictions and then log them into Rubrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Classification\n",
    "\n",
    "Let's try a zero-shot classifier using SqueezeBERT for predicting the topic of a sentence."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='zeroshot-topic-classifier', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from transformers import pipeline\n",
    "\n",
    "# We define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "        \"zero-shot-classification\",\n",
    "        model=\"typeform/squeezebert-mnli\",\n",
    "        framework=\"pt\",\n",
    "    )\n",
    "    \n",
    "# Choosing our input\n",
    "text_input = \"I love watching rock climbing competitions!\"\n",
    "\n",
    "# Making the prediction\n",
    "prediction = classifier(\n",
    "    text_input,\n",
    "    candidate_labels=[\n",
    "        \"politics\",\n",
    "        \"sports\",\n",
    "        \"technology\",\n",
    "    ],\n",
    "    hypothesis_template=\"This text is about {}.\",\n",
    ")\n",
    "\n",
    "# Creating a record object to log into rubrix.\n",
    "record = rb.TextClassificationRecord(\n",
    "    inputs={\"text\": prediction[\"sequence\"]},\n",
    "    prediction=list(zip(prediction[\"labels\"], prediction[\"scores\"])),\n",
    "    prediction_agent=\"https://huggingface.co/typeform/squeezebert-mnli\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"zeroshot-topic-classifier\")"
   ]
  },
  {
   "source": [
    "### Token Classification\n",
    "\n",
    "We will explore a NER zero-shot classifier in the English language."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='zeroshot-ner', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from transformers import pipeline\n",
    "\n",
    "# We define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "        \"ner\",\n",
    "        model=\"elastic/distilbert-base-cased-finetuned-conll03-english\",\n",
    "        framework=\"pt\",\n",
    "    )\n",
    "\n",
    "# Choosing our input\n",
    "text_input = \"My name is Sarah and I live in London\"\n",
    "\n",
    "# Making the prediction\n",
    "predictions = classifier(\n",
    "    text_input,\n",
    ")\n",
    "\n",
    "# Creating a record object to log into rubrix.\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=text_input,\n",
    "    tokens=text_input.split(),\n",
    "    prediction=[(pred[\"entity\"], pred[\"start\"], pred[\"end\"]) for pred in predictions],\n",
    "    prediction_agent=\"https://huggingface.co/elastic/distilbert-base-cased-finetuned-conll03-english\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"zeroshot-ner\")"
   ]
  },
  {
   "source": [
    "## Spacy\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Token Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='lesmiserables-ner', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "import spacy\n",
    "\n",
    "input_text = \"Paris a un enfant et la forêt a un oiseau ; l’oiseau s’appelle le moineau ; l’enfant s’appelle le gamin\"\n",
    "\n",
    "# Loading spaCy model\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Creating spaCy doc\n",
    "doc = nlp(input_text)\n",
    "\n",
    "# Building TokenClassificationRecord\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=input_text,\n",
    "    tokens=[token.text for token in doc],\n",
    "    prediction=[(ent.label_, ent.start_char, ent.end_char) for ent in doc.ents],\n",
    "    prediction_agent=\"spacy.fr_core_news_sm\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"lesmiserables-ner\")"
   ]
  },
  {
   "source": [
    "## Flair\n",
    "\n",
    "Developed by the University of Berlin, it is a simple, yet powerful state-of-the-art NLP framework. It provides an NLP library, a text embedding library and a PyTorch framework for NLP. Flair offers sequence tagging language models in English, Spanish, Dutch, German and many more, and they are also hosted on [HuggingFace Model Hub](https://huggingface.co/models)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Text Classification\n",
    "\n",
    "Flair offers some zero-shot models ready to be used, which we are going to use to introduce logging `TextClassificationRecords` with Rubrix. Let's see how to integrate Rubrix in their Deutch offensive language model (we promise to not get very explicit)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-05-29 21:50:30,492 loading file /Users/ignaciotalaveracepeda/.flair/models/germ-eval-2018-task-1-v0.5.pt\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='german-offensive-language', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "# Load our pre-trained TARS model for English\n",
    "classifier = TextClassifier.load('de-offensive-language')\n",
    "\n",
    "input_text = 'Du erzählst immer Quatsch.' #something like: \"You are always narrating silliness.\"\n",
    "\n",
    "# Creating Sentence object\n",
    "sentence = Sentence(input_text) \n",
    "\n",
    "# Make the prediction\n",
    "classifier.predict(sentence, multi_class_prob=True)\n",
    "\n",
    "# Creating a record object to log into rubrix.\n",
    "record = rb.TextClassificationRecord(\n",
    "    inputs={\"text\": input_text},\n",
    "    prediction=[(pred.value, pred.score) for pred in sentence.labels],\n",
    "    prediction_agent=\"flair/de-offensive-language\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"german-offensive-language\")"
   ]
  },
  {
   "source": [
    "### Token Classification\n",
    "\n",
    "Flair offers a lot of tools for Token Classification, supporting tasks like named entity recognition (NER), part-of-speech tagging (POS), special support for biomedical data... and with a growing number of supported languages. Lets see some examples for NER and POS tagging."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### NER\n",
    "\n",
    "In this example, we will try the pretrained Dutch NER model from Flair."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-05-29 21:50:34,951 loading file /Users/ignaciotalaveracepeda/.flair/models/ner-dutch/fd03fc5c7a02268a538432a010f4d09ec15e55fe70efd02dfea158916fa4cba8.04438768e42ba7d6599cea01fcabf77563c8c7e2b27a245618f0ed535ad8919c\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='dutch-flair-ner', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "input_text = \"De Nachtwacht is in het Rijksmuseum\"\n",
    "\n",
    "# Loading our NER model\n",
    "tagger = SequenceTagger.load('flair/ner-dutch')\n",
    "\n",
    "# Creating Sentence object\n",
    "sentence = Sentence(input_text)\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# Building TokenClassificationRecord\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=input_text,\n",
    "    tokens=[token.text for token in sentence],\n",
    "    prediction=[(entity.get_labels()[0].value, entity.start_pos, entity.end_pos) for entity in sentence.get_spans('ner')],\n",
    "    prediction_agent=\"flair/ner-dutch\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"dutch-flair-ner\")"
   ]
  },
  {
   "source": [
    "#### POS tagging\n",
    "\n",
    "In the following snippet we will use de multilingual POS tagging model from Flair."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-05-29 21:50:51,193 loading file /Users/ignaciotalaveracepeda/.flair/models/upos-multi/1a44f168663182024fd3ea6d7dcaeee47fe5bcb537cc737ad058b64ad4db9736.5f899f25846741510a6567b89027d988bd6f634b2776a7c3e834fea4629367cb\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BulkResponse(dataset='flair-pos-tagging', processed=1, failed=0)"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "input_text = \"George Washington went to Washington. Dort kaufte er einen Hut.\"\n",
    "\n",
    "# Loading our NER model\n",
    "tagger = SequenceTagger.load('flair/upos-multi')\n",
    "\n",
    "# Creating Sentence object\n",
    "sentence = Sentence(input_text)\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# Building TokenClassificationRecord\n",
    "record = rb.TokenClassificationRecord(\n",
    "    text=input_text,\n",
    "    tokens=[token.text for token in sentence],\n",
    "    prediction=[(entity.get_labels()[0].value, entity.start_pos, entity.end_pos) for entity in sentence.get_spans()],\n",
    "    prediction_agent=\"flair/upos-multi\",\n",
    ")\n",
    "\n",
    "# Logging into Rubrix\n",
    "rb.log(records=record, name=\"flair-pos-tagging\")"
   ]
  }
 ]
}