{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "020957ce-46fa-4799-8321-716e62900269",
   "metadata": {},
   "source": [
    "# ðŸ‘® Weak Supervision\n",
    "\n",
    "## FeedbackDataset\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Info\n",
    "    \n",
    "The `FeedbackDataset` does not offer support for weak supervision as of now. If you would like to use it, you will need to use one of the other datasets. To get more info about the dataset differences, you can have a look [here](../choose_dataset.md). \n",
    "    \n",
    "</div>\n",
    "\n",
    "## Other datasets\n",
    "\n",
    "This guide gives you a brief introduction to weak supervision with Argilla.\n",
    "\n",
    "Argilla currently supports weak supervision for **multi-class** and **multi-label** text classification use cases. Support for token classification (e.g., Named Entity Recognition) will be added soon.\n",
    "\n",
    "![Labeling workflow](/_static/images/guides/weak_supervision/weak_supervision.png \"Labeling workflow\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9eb86995-f158-4392-86b7-eb5305a9ec3b",
   "metadata": {},
   "source": [
    "### Argilla weak supervision in a nutshell\n",
    "\n",
    "The recommended workflow for weak supervision is:\n",
    "\n",
    "- Log an unlabeled dataset into Argilla.\n",
    "- Use the `Annotate` mode for hand- and/or bulk-labeling a validation set. This validation is key to measuring the quality and performance of your rules. Additionally, you need to build a test set that is not used for defining rules. This test set will be used to measure the performance of your end model, as with any other supervised model.\n",
    "- Use the `Define rules` mode for evaluating and defining rules. Rules are defined with search queries (using ES query string DSL). Additionally, you can use the Python client methods to add, delete, or modify rules programmatically, making them available for refinement in the UI.\n",
    "- Use the Python client for reading rules, defining additional rules if needed, and training a label (for building a training set) or a downstream model (for building an end classifier).\n",
    "\n",
    "```python\n",
    "from argilla.labeling.text_classification import Rule, WeakLabels\n",
    "\n",
    "rules = [\n",
    "    Rule(query=\"plz OR please\", label=\"SPAM\"),\n",
    "]\n",
    "\n",
    "weak_labels = WeakLabels(\n",
    "    rules=rules,\n",
    "    dataset=\"weak_supervision_yt\"\n",
    ")\n",
    "\n",
    "# returns a summary of the applied rules\n",
    "weak_labels.summary()\n",
    "```\n",
    "\n",
    "The next sections cover the main components of this workflow. \n",
    "\n",
    "#### Weak labeling using the UI\n",
    "\n",
    "Since version 0.8.0 you can find and define weak labeling rules directly in the UI. \n",
    "The [weak labeling mode](../../reference/webapp/pages.md#modes) to define rules is found in the right sidebar of the [Dataset page](../../reference/webapp/pages.md#dataset).\n",
    "\n",
    "#### Weak supervision from Python\n",
    "\n",
    "Doing weak supervision with Argilla is straightforward. Keeping the same spirit as other parts of the library, you can use any weak supervision library or method, such as Snorkel or Flyingsquid. \n",
    "\n",
    "Argilla weak supervision support is built around two basic abstractions:\n",
    "\n",
    "\n",
    "#### `Rule`\n",
    "A rule encodes a heuristic for labeling a record.\n",
    "\n",
    "Heuristics can be defined using [Elasticsearch's queries](../../reference/webapp/features.md#search-records):\n",
    "\n",
    "```python\n",
    "plz = Rule(query=\"plz OR please\", label=\"SPAM\")\n",
    "```\n",
    "\n",
    "or with Python functions (similar to Snorkel's labeling functions, which you can use as well):\n",
    "\n",
    "```python\n",
    "from typing import Optional\n",
    "\n",
    "def contains_http(record: rg.TextClassificationRecord) -> Optional[str]:\n",
    "    if \"http\" in record.inputs[\"text\"]:\n",
    "        return \"SPAM\"\n",
    "```\n",
    "\n",
    "Besides textual features, Python labeling functions can exploit metadata features:\n",
    "\n",
    "```python\n",
    "def author_channel(record: rg.TextClassificationRecord) -> Optional[str]:\n",
    "    # the word channel appears in the comment author name\n",
    "    if \"channel\" in record.metadata[\"author\"]:\n",
    "        return \"SPAM\"\n",
    "```\n",
    "\n",
    "A rule should either return a string value representing a weak label or `None` in case of abstention.\n",
    "\n",
    "These rules can be:\n",
    "\n",
    "1. Defined using the no-code feature of the UI (see the [weak labeling mode](../../reference/webapp/pages.md#modes) reference).\n",
    "2. `Rule` objects can be created using Python as shown above. These objects can be either applied locally by developers (which might be interesting for testing without overloading the server) or added to the dataset in the Argilla server, making these rules available from the UI. \n",
    "3. Python functions cannot be defined with the no-code feature and can only be applied locally but not added to the dataset in the Argilla server. Data teams can use these Python labeling functions to add extra heuristics before building a weakly labeled dataset. This function should be used for heuristics which are not possible to define using ES queries.\n",
    "\n",
    "\n",
    "\n",
    "#### `Weak Labels`\n",
    "\n",
    "Weak Labels objects bundle and apply a set of rules to the records of a Argilla dataset. Applying a rule to a record means assigning a weak label or abstaining.\n",
    "\n",
    "This abstraction provides you with the building blocks for training and testing weak supervision \"denoising\", \"label\" or even \"end\" models:\n",
    "\n",
    "```python\n",
    "rules = [contains_http, author_channel]\n",
    "weak_labels = WeakLabels(\n",
    "    rules=rules, \n",
    "    dataset=\"weak_supervision_yt\"\n",
    ")\n",
    "\n",
    "# returns a summary of the applied rules\n",
    "weak_labels.summary()\n",
    "```\n",
    "\n",
    "More information about these abstractions can be found in the [Python Labeling module docs](../../reference/python/python_labeling.md).\n",
    "\n",
    "### Built-in label models\n",
    "\n",
    "To make things even easier for you, we provide wrapper classes around the most common label models, that directly consume a `WeakLabels` object.\n",
    "This makes working with those models a breeze.\n",
    "Take a look at the list of built-in models in the [labeling module docs](../../reference/python/python_labeling.md).\n",
    "\n",
    "\n",
    "### Detailed Workflow\n",
    "\n",
    "A typical workflow to use weak supervision is:\n",
    "\n",
    "1. Create an Argilla dataset with your raw dataset. If you actually have some labeled data you can log it into the same dataset.\n",
    "2. Define a set of weak labeling rules with the Rules definition mode in the UI or using the Python client `add_rules` method.\n",
    "3. Create a `WeakLabels` object and apply the rules using the Python client. You can load the rules from your dataset and add additional rules and labeling functions using Python. Typically, you'll iterate between this step and step 2.\n",
    "4. Once you are satisfied with your weak labels, use the matrix of the `WeakLabels` instance with your library/method of choice to build a training set or even train a downstream text classification model.\n",
    "\n",
    "\n",
    "This guide shows you an end-to-end example using Snorkel, Flyingsquid and Weasel. Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf52dd8f-fb8e-4909-9f6d-0a8856afa999",
   "metadata": {},
   "source": [
    "### Example dataset\n",
    "\n",
    "We'll be using a well-known dataset for weak supervision examples, the [YouTube Spam Collection](https://archive.ics.uci.edu/dataset/380/youtube+spam+collection) dataset, which is a binary classification task for detecting spam comments in Youtube videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b1e00af-c6f9-42aa-81aa-2976c9591b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alessandro leite</td>\n",
       "      <td>2014-11-05T22:21:36</td>\n",
       "      <td>pls http://www10.vakinha.com.br/VaquinhaE.aspx...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Salim Tayara</td>\n",
       "      <td>2014-11-02T14:33:30</td>\n",
       "      <td>if your like drones, plz subscribe to Kamal Ta...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Phuc Ly</td>\n",
       "      <td>2014-01-20T15:27:47</td>\n",
       "      <td>go here to check the views :3ï»¿</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DropShotSk8r</td>\n",
       "      <td>2014-01-19T04:27:18</td>\n",
       "      <td>Came here to check the views, goodbye.ï»¿</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>css403</td>\n",
       "      <td>2014-11-07T14:25:48</td>\n",
       "      <td>i am 2,126,492,636 viewer :Dï»¿</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            author                 date  \\\n",
       "0           0  Alessandro leite  2014-11-05T22:21:36   \n",
       "1           1      Salim Tayara  2014-11-02T14:33:30   \n",
       "2           2           Phuc Ly  2014-01-20T15:27:47   \n",
       "3           3      DropShotSk8r  2014-01-19T04:27:18   \n",
       "4           4            css403  2014-11-07T14:25:48   \n",
       "\n",
       "                                                text  label  video  \n",
       "0  pls http://www10.vakinha.com.br/VaquinhaE.aspx...   -1.0      1  \n",
       "1  if your like drones, plz subscribe to Kamal Ta...   -1.0      1  \n",
       "2                     go here to check the views :3ï»¿   -1.0      1  \n",
       "3            Came here to check the views, goodbye.ï»¿   -1.0      1  \n",
       "4                      i am 2,126,492,636 viewer :Dï»¿   -1.0      1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "train_df = pd.read_csv(\"../../tutorials/notebooks/data/yt_comments_train.csv\")\n",
    "test_df = pd.read_csv(\"../../tutorials/notebooks/data/yt_comments_test.csv\")\n",
    "\n",
    "# preview data\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8fcd253-f8b5-40ba-a9a2-9d068e19c1cc",
   "metadata": {},
   "source": [
    "### 1. Create an Argilla dataset with unlabeled data and test data\n",
    "\n",
    "Let's load the train (non-labeled) and the test (containing labels) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78571aa4-314d-4b4e-b933-c3292213b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "\n",
    "# build records from the train dataset\n",
    "records = [\n",
    "    rg.TextClassificationRecord(\n",
    "        text=row.text, metadata={\"video\": row.video, \"author\": row.author}\n",
    "    )\n",
    "    for i, row in train_df.iterrows()\n",
    "]\n",
    "\n",
    "# build records from the test dataset with annotation\n",
    "labels = [\"HAM\", \"SPAM\"]\n",
    "records += [\n",
    "    rg.TextClassificationRecord(\n",
    "        text=row.text,\n",
    "        annotation=labels[row.label],\n",
    "        metadata={\"video\": row.video, \"author\": row.author},\n",
    "    )\n",
    "    for i, row in test_df.iterrows()\n",
    "]\n",
    "\n",
    "# log records to Argilla\n",
    "rg.log(records, name=\"weak_supervision_yt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baafda4f-45c0-49d6-9c37-7473c6888ebe",
   "metadata": {},
   "source": [
    "After this step, you have a fully browsable dataset available that you can access via the [Argilla web app](/reference/webapp/index.md)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dde95ce0-6e1e-4c9e-aff2-ac12643b9a48",
   "metadata": {},
   "source": [
    "### 2. Define and manage rules\n",
    "\n",
    "Let's now define some of the rules proposed in the tutorial [Snorkel Intro Tutorial: Data Labeling](https://www.snorkel.org/use-cases/01-spam-tutorial). \n",
    "\n",
    "Rules in Argilla can be defined and used in several ways, In particular: (1) using the UI, (2) using the Python client to add rules to the server, and (3) using the Python client to add additional rules locally, either using Python functions or Rule objects.\n",
    "\n",
    "#### Define rules using the UI\n",
    "\n",
    "Rules can be defined directly with our web app in the [weak labeling mode](../../reference/webapp/pages.md#modes) and [Elasticsearch's query strings](../../reference/webapp/features.md#search-records).\n",
    "\n",
    "Afterward, you can conveniently load them into your notebook with the [load_rules function](../../reference/python/python_labeling.rst).\n",
    "\n",
    "#### Define rules using the Python client\n",
    "\n",
    "Rules can also be defined programmatically as shown below. Depending on your use case and team structure you can mix and match both interfaces (UI or Python). Depending on your workflow, you can decide whether to use the `add_rules` method to add them to the dataset, or just apply them locally (without adding them to the Argilla dataset).\n",
    "\n",
    "Let's see here some programmatic rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045700ef-62b7-44e2-95f9-0f966236303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.labeling.text_classification import Rule, WeakLabels\n",
    "\n",
    "#  rules defined as Elasticsearch queries\n",
    "check_out = Rule(query=\"check out\", label=\"SPAM\")\n",
    "plz = Rule(query=\"plz OR please\", label=\"SPAM\")\n",
    "subscribe = Rule(query=\"subscribe\", label=\"SPAM\")\n",
    "my = Rule(query=\"my\", label=\"SPAM\")\n",
    "song = Rule(query=\"song\", label=\"HAM\")\n",
    "love = Rule(query=\"love\", label=\"HAM\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f4d4d7f-9a95-4905-a38b-3907d5293c4f",
   "metadata": {},
   "source": [
    "You can also define plain Python labeling functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3554c-9646-4f2b-ab33-13518566bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# rules defined as Python labeling functions\n",
    "def contains_http(record: rg.TextClassificationRecord):\n",
    "    if \"http\" in record.inputs[\"text\"]:\n",
    "        return \"SPAM\"\n",
    "\n",
    "\n",
    "def short_comment(record: rg.TextClassificationRecord):\n",
    "    return \"HAM\" if len(record.inputs[\"text\"].split()) < 5 else None\n",
    "\n",
    "\n",
    "def regex_check_out(record: rg.TextClassificationRecord):\n",
    "    return (\n",
    "        \"SPAM\" if re.search(r\"check.*out\", record.inputs[\"text\"], flags=re.I) else None\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bf6eba2",
   "metadata": {},
   "source": [
    "You can load your predefined rules and convert them to Rule instances, and add them to dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa36602",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_rules_df = pd.read_csv(\n",
    "    \"../../_static/datasets/weak_supervision_tutorial/labeling_rules.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3de8bf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>your</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rich</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>film</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>meeting</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>help</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    query label\n",
       "0           0     your  SPAM\n",
       "1           1     rich  SPAM\n",
       "2           2     film   HAM\n",
       "3           3  meeting   HAM\n",
       "4           4     help   HAM"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview labeling rules\n",
    "labeling_rules_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0712bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "predefined_labeling_rules = []\n",
    "for index, row in labeling_rules_df.iterrows():\n",
    "    predefined_labeling_rules.append(Rule(row[\"query\"], row[\"label\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "405c93ec-b136-43cf-af50-96c956b65f12",
   "metadata": {},
   "source": [
    "### 3. Building and analyzing weak labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf60f4-c5f5-492d-ac0d-52a25cfb5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.labeling.text_classification import load_rules, add_rules, delete_rules\n",
    "\n",
    "# bundle our rules in a list\n",
    "rules = [check_out, plz, subscribe, my, song, love]\n",
    "\n",
    "labeling_functions = [contains_http, short_comment, regex_check_out]\n",
    "\n",
    "# add rules to dataset\n",
    "add_rules(dataset=\"weak_supervision_yt\", rules=rules)\n",
    "\n",
    "\n",
    "# add the predefined rules loaded from external file\n",
    "add_rules(dataset=\"weak_supervision_yt\", rules=predefined_labeling_rules)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40c8a439-5389-4329-86f8-e16d28eafb16",
   "metadata": {},
   "source": [
    "After the above step, the rules will be accesible in the `weak_supervision_yt` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cfec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the rules available in the dataset including interactively defined in the UI\n",
    "dataset_labeling_rules = load_rules(dataset=\"weak_supervision_yt\")\n",
    "\n",
    "# extend the labeling rules with labeling functions\n",
    "dataset_labeling_rules.extend(labeling_functions)\n",
    "\n",
    "# apply the final rules to the dataset\n",
    "weak_labels = WeakLabels(dataset=\"weak_supervision_yt\", rules=dataset_labeling_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0584b8b-4b0d-4857-9e8b-9823d9172634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>coverage</th>\n",
       "      <th>annotated_coverage</th>\n",
       "      <th>overlaps</th>\n",
       "      <th>conflicts</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check out</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.224401</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.224401</td>\n",
       "      <td>0.031590</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plz OR please</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.104575</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.036492</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subscribe</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.082244</td>\n",
       "      <td>0.031590</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.192810</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.168845</td>\n",
       "      <td>0.062636</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <td>{HAM}</td>\n",
       "      <td>0.118192</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.070806</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.790698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>{HAM}</td>\n",
       "      <td>0.090959</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.071351</td>\n",
       "      <td>0.034858</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.052832</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rich</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meeting</th>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>{HAM}</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.023965</td>\n",
       "      <td>0.023965</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_http</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.106209</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_comment</th>\n",
       "      <td>{HAM}</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.101307</td>\n",
       "      <td>0.064270</td>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_check_out</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.226580</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.226035</td>\n",
       "      <td>0.032135</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>{SPAM, HAM}</td>\n",
       "      <td>0.762527</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.458061</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>354</td>\n",
       "      <td>42</td>\n",
       "      <td>0.893939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       label  coverage  annotated_coverage  overlaps  \\\n",
       "check out             {SPAM}  0.224401               0.176  0.224401   \n",
       "plz OR please         {SPAM}  0.104575               0.088  0.098039   \n",
       "subscribe             {SPAM}  0.101852               0.120  0.082244   \n",
       "my                    {SPAM}  0.192810               0.192  0.168845   \n",
       "song                   {HAM}  0.118192               0.172  0.070806   \n",
       "love                   {HAM}  0.090959               0.140  0.071351   \n",
       "your                  {SPAM}  0.052832               0.088  0.041939   \n",
       "rich                  {SPAM}  0.000545               0.000  0.000000   \n",
       "film                      {}  0.000000               0.000  0.000000   \n",
       "meeting                   {}  0.000000               0.000  0.000000   \n",
       "help                   {HAM}  0.027778               0.036  0.023965   \n",
       "contains_http         {SPAM}  0.106209               0.024  0.078431   \n",
       "short_comment          {HAM}  0.245098               0.368  0.101307   \n",
       "regex_check_out       {SPAM}  0.226580               0.180  0.226035   \n",
       "total            {SPAM, HAM}  0.762527               0.880  0.458061   \n",
       "\n",
       "                 conflicts  correct  incorrect  precision  \n",
       "check out         0.031590       44          0   1.000000  \n",
       "plz OR please     0.036492       22          0   1.000000  \n",
       "subscribe         0.031590       30          0   1.000000  \n",
       "my                0.062636       42          6   0.875000  \n",
       "song              0.037037       34          9   0.790698  \n",
       "love              0.034858       28          7   0.800000  \n",
       "your              0.019608       19          3   0.863636  \n",
       "rich              0.000000        0          0        NaN  \n",
       "film              0.000000        0          0        NaN  \n",
       "meeting           0.000000        0          0        NaN  \n",
       "help              0.023965        0          9   0.000000  \n",
       "contains_http     0.055556        6          0   1.000000  \n",
       "short_comment     0.064270       84          8   0.913043  \n",
       "regex_check_out   0.032135       45          0   1.000000  \n",
       "total             0.147059      354         42   0.893939  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show some stats about the rules, see the `summary()` docstring for details\n",
    "weak_labels.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcf263ad",
   "metadata": {},
   "source": [
    "You can remove the rules that are wrong from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_informative_rules = [\n",
    "    Rule(\"rich\", \"SPAM\"),\n",
    "    Rule(\"film\", \"HAM\"),\n",
    "    Rule(\"meeting\", \"HAM\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.labeling.text_classification import delete_rules\n",
    "\n",
    "delete_rules(dataset=\"weak_supervision_yt\", rules=not_informative_rules)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd384863",
   "metadata": {},
   "source": [
    "You can update the rule:\n",
    "    \n",
    "    help\t{HAM}\t0.027778\t0.036\t0.023965\t0.023965\t0\t9\t0.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e664fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "help_rule = Rule(\"help\", label=\"SPAM\")\n",
    "help_rule.update_at_dataset(dataset=\"weak_supervision_yt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8d9d3f9",
   "metadata": {},
   "source": [
    "Let us load the rules again and apply weak labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c52c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rules = labeling_functions + load_rules(dataset=\"weak_supervision_yt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9bc0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_labels = WeakLabels(dataset=\"weak_supervision_yt\", rules=final_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbb7978a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>coverage</th>\n",
       "      <th>annotated_coverage</th>\n",
       "      <th>overlaps</th>\n",
       "      <th>conflicts</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>contains_http</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.106209</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_comment</th>\n",
       "      <td>{HAM}</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.101307</td>\n",
       "      <td>0.064270</td>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_check_out</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.226580</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.226035</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check out</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.224401</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.224401</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plz OR please</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.104575</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.023420</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subscribe</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.082244</td>\n",
       "      <td>0.025054</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.192810</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.168845</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <td>{HAM}</td>\n",
       "      <td>0.118192</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.070806</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>0.790698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>{HAM}</td>\n",
       "      <td>0.090959</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.071351</td>\n",
       "      <td>0.034858</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.052832</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>{SPAM}</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.023965</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>{SPAM, HAM}</td>\n",
       "      <td>0.761983</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.458061</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>363</td>\n",
       "      <td>33</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       label  coverage  annotated_coverage  overlaps  \\\n",
       "contains_http         {SPAM}  0.106209               0.024  0.078431   \n",
       "short_comment          {HAM}  0.245098               0.368  0.101307   \n",
       "regex_check_out       {SPAM}  0.226580               0.180  0.226035   \n",
       "check out             {SPAM}  0.224401               0.176  0.224401   \n",
       "plz OR please         {SPAM}  0.104575               0.088  0.098039   \n",
       "subscribe             {SPAM}  0.101852               0.120  0.082244   \n",
       "my                    {SPAM}  0.192810               0.192  0.168845   \n",
       "song                   {HAM}  0.118192               0.172  0.070806   \n",
       "love                   {HAM}  0.090959               0.140  0.071351   \n",
       "your                  {SPAM}  0.052832               0.088  0.041939   \n",
       "help                  {SPAM}  0.027778               0.036  0.023965   \n",
       "total            {SPAM, HAM}  0.761983               0.880  0.458061   \n",
       "\n",
       "                 conflicts  correct  incorrect  precision  \n",
       "contains_http     0.049020        6          0   1.000000  \n",
       "short_comment     0.064270       84          8   0.913043  \n",
       "regex_check_out   0.027778       45          0   1.000000  \n",
       "check out         0.027778       44          0   1.000000  \n",
       "plz OR please     0.023420       22          0   1.000000  \n",
       "subscribe         0.025054       30          0   1.000000  \n",
       "my                0.050654       42          6   0.875000  \n",
       "song              0.037037       34          9   0.790698  \n",
       "love              0.034858       28          7   0.800000  \n",
       "your              0.015795       19          3   0.863636  \n",
       "help              0.003813        9          0   1.000000  \n",
       "total             0.126906      363         33   0.916667  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weak_labels.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4364c17-4a5d-464b-8f2b-36f50c81b174",
   "metadata": {},
   "source": [
    "### 4. Using the weak labels\n",
    "\n",
    "At this step, you have at least two options:\n",
    "\n",
    "1. Use the weak labels for training a \"denoising\" or label model to build a less noisy training set. Highly popular options for this are [Snorkel](https://snorkel.org/) or [Flyingsquid](https://github.com/HazyResearch/flyingsquid). After this step, you can train a downstream model with the \"clean\" labels.\n",
    "\n",
    "2. Use the weak labels directly with recent \"end-to-end\" (e.g., [Weasel](https://github.com/autonlab/weasel)) or joint models (e.g., [COSINE](https://github.com/yueyu1030/COSINE)).\n",
    "\n",
    "\n",
    "Let's see some examples:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebab5f3a-f158-4090-9933-3615435256a5",
   "metadata": {},
   "source": [
    "#### A simple majority vote\n",
    "\n",
    "As a first example, we will show you how to use the `WeakLabels` object together with a simple majority vote model, which is arguably the most straightforward label model.\n",
    "On a per-record basis, it simply counts the votes for each label returned by the rules and takes the majority vote.\n",
    "Argilla provides a neat implementation of this logic in its `MajorityVoter` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb42d90-b2ec-4b26-ae0c-165b26a87458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.labeling.text_classification import MajorityVoter\n",
    "\n",
    "# instantiate the majority vote label model by simply providing the weak labels object\n",
    "majority_model = MajorityVoter(weak_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee31a144-a426-4d27-a7aa-13cc1c8dc3bf",
   "metadata": {},
   "source": [
    "In contrast to the other label models we will discuss further down, the majority voter does not need to be fitted.\n",
    "You can directly check its performance by simply calling its `score()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5acfce87-56e7-4f2f-8572-de797a22938d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        SPAM       0.99      0.93      0.96       102\n",
      "         HAM       0.94      0.99      0.96       108\n",
      "\n",
      "    accuracy                           0.96       210\n",
      "   macro avg       0.96      0.96      0.96       210\n",
      "weighted avg       0.96      0.96      0.96       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check its performance\n",
    "print(majority_model.score(output_str=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bb83339-8909-4c44-b032-a2e6208f49f9",
   "metadata": {},
   "source": [
    "An accuracy of 0.96 seems surprisingly high, but you need to keep in mind that we simply excluded the records from the evaluation, for which the model abstained (that is a tie in the votes or no votes at all).\n",
    "So let's account for this and correct the accuracy by assuming the model performs like a random classifier for these abstained records:\n",
    "\n",
    "> $accuracy_c = frac_{non} \\times accuracy + frac_{abs} \\times accuracy_{random}$\n",
    "\n",
    "where $frac_{non}$ is the fraction of non-abstained records and $frac_{abs}$ the fraction of abstained records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78061952-6569-4241-9bc4-87caf6ad3e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fractions using the support metric (see above)\n",
    "frac_non = 200 / len(weak_labels.annotation())\n",
    "frac_abs = 1 - (200 / len(weak_labels.annotation()))\n",
    "\n",
    "# accuracy without abstentions: 0.96; accuracy of random classifier: 0.5\n",
    "print(\"accuracy_c:\", frac_non * 0.96 + frac_abs * 0.5)\n",
    "# accuracy_c: 0.868"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0dcbe2e-8078-4d81-8cb2-a2bb621b4d34",
   "metadata": {},
   "source": [
    "As we will see further down, **an accuracy of 0.868** is still a very decent baseline.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "To get a noisy estimate of the corrected accuracy, you can also set the _\"tie_break_policy\"_ argument: `majority_model.score(..., tie_break_policy=\"random\")`.\n",
    "    \n",
    "</div>\n",
    "\n",
    "When predicting weak labels to train a downstream model, however, you probably want to discard the abstentions.\n",
    "Calling the `predict()` method on the majority voter, excludes the abstentions by default and only returns records without annotations.\n",
    "These are normally used to build a training set for a downstream model.\n",
    "\n",
    "You can quickly explore the predicted records with Argilla, before building a training set for training a downstream text classifier. \n",
    "This step is useful for validation, manual revision, or defining score thresholds for accepting labels from your label model (for example, only considering labels with a score greater than 0.8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745e9f4-d445-422e-a45d-371a086a3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your training records with the predictions of the label model\n",
    "records_for_training = majority_model.predict()\n",
    "\n",
    "# optional: log the records to a new dataset in Argilla\n",
    "rg.log(records_for_training, name=\"majority_voter_results\")\n",
    "\n",
    "# extract training data\n",
    "training_data = pd.DataFrame(\n",
    "    [{\"text\": rec.text, \"label\": rec.prediction[0][0]} for rec in records_for_training]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "250d800e-85ba-4cc5-9fcf-a7105f94fbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.rtbf.be/tv/emission/detail_the-voic...</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.ermail.pl/dolacz/V3VeYGIN CLICK  ht...</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect! &amp;lt;3ï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Check out Melbourne shuffle, everybody!ï»¿</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Check out my videos guy! :) Hope you guys had ...</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>Great songï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>subscribeï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>LoLï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>Love this songï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>LOVE THE WAY YOU LIE ..&amp;quot;ï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1053 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     http://www.rtbf.be/tv/emission/detail_the-voic...  SPAM\n",
       "1     http://www.ermail.pl/dolacz/V3VeYGIN CLICK  ht...  SPAM\n",
       "2                                       Perfect! &lt;3ï»¿   HAM\n",
       "3              Check out Melbourne shuffle, everybody!ï»¿  SPAM\n",
       "4     Check out my videos guy! :) Hope you guys had ...  SPAM\n",
       "...                                                 ...   ...\n",
       "1048                                        Great songï»¿   HAM\n",
       "1049                                         subscribeï»¿   HAM\n",
       "1050                                               LoLï»¿   HAM\n",
       "1051                                    Love this songï»¿   HAM\n",
       "1052                     LOVE THE WAY YOU LIE ..&quot;ï»¿   HAM\n",
       "\n",
       "[1053 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview training data\n",
    "training_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2186a612-57a4-4118-97fb-927ed87df96d",
   "metadata": {},
   "source": [
    "#### Label model with Snorkel\n",
    "\n",
    "Snorkel's label model is by far the most popular option for using weak supervision, and Argilla provides built-in support for it. \n",
    "Using Snorkel with Argilla's `WeakLabels` is as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af30dfa-b401-4e96-984d-c59753411557",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install snorkel -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb50bb-edfb-40a2-9e4c-094e22284df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.labeling.text_classification import Snorkel\n",
    "\n",
    "# we pass our WeakLabels instance to our Snorkel label model\n",
    "snorkel_model = Snorkel(weak_labels)\n",
    "\n",
    "# we fit the model\n",
    "snorkel_model.fit(lr=0.001, n_epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9947561-f177-46cd-a965-bf78ed11cd0a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "The `Snorkel` label model is not suited for multi-label classification tasks and does not support them.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5f6346d-1a34-4efa-87de-f3e69b7550ca",
   "metadata": {},
   "source": [
    "When fitting the snorkel model, we recommend performing a quick grid search for the learning rate `lr` and the number of epochs `n_epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c82339f-561d-4c59-89ee-c49ddbe8da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        SPAM       0.93      0.93      0.93       106\n",
      "         HAM       0.94      0.94      0.94       114\n",
      "\n",
      "    accuracy                           0.94       220\n",
      "   macro avg       0.94      0.94      0.94       220\n",
      "weighted avg       0.94      0.94      0.94       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we check its performance\n",
    "print(snorkel_model.score(output_str=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27d3e81f-e1ac-4203-8641-e721981aa0a6",
   "metadata": {},
   "source": [
    "At first sight, the model seems to perform worse than the majority vote baseline.\n",
    "However, let's again correct the accuracy for the abstentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9700f2-5e88-4926-8f2f-d3acada5c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fractions using the support metric (see above)\n",
    "frac_non = 209 / len(weak_labels.annotation())\n",
    "frac_abs = 1 - (209 / len(weak_labels.annotation()))\n",
    "\n",
    "# accuracy without abstentions: 0.95; accuracy of random classifier: 0.5\n",
    "print(\"accuracy_c:\", frac_non * 0.95 + frac_abs * 0.5)\n",
    "# accuracy_c: 0.8761999999999999"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "075463f3-8695-4d28-af24-8860b2efd691",
   "metadata": {},
   "source": [
    "Now we can see that with **an accuracy of 0.876**, its performance over the whole test set is actually slightly better.\n",
    "\n",
    "After fitting your label model, you can quickly explore its predictions, before building a training set for training a downstream text classifier. \n",
    "This step is useful for validation, manual revision, or defining score thresholds for accepting labels from your label model (for example, only considering labels with a score greater than 0.8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3fd76-8b58-4ae3-bc58-9d82c039bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your training records with the predictions of the label model\n",
    "records_for_training = snorkel_model.predict()\n",
    "\n",
    "# optional: log the records to a new dataset in Argilla\n",
    "rg.log(records_for_training, name=\"snorkel_results\")\n",
    "\n",
    "# extract training data\n",
    "training_data = pd.DataFrame(\n",
    "    [{\"text\": rec.text, \"label\": rec.prediction[0][0]} for rec in records_for_training]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e18b365-5412-47c7-b0e6-e140bd0c2dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.rtbf.be/tv/emission/detail_the-voic...</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.ermail.pl/dolacz/V3VeYGIN CLICK  ht...</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect! &amp;lt;3ï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Check out Melbourne shuffle, everybody!ï»¿</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook account HACK!! http://hackfbaccountl...</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>Great songï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>subscribeï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>LoLï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>Love this songï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>LOVE THE WAY YOU LIE ..&amp;quot;ï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1179 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     http://www.rtbf.be/tv/emission/detail_the-voic...  SPAM\n",
       "1     http://www.ermail.pl/dolacz/V3VeYGIN CLICK  ht...  SPAM\n",
       "2                                       Perfect! &lt;3ï»¿   HAM\n",
       "3              Check out Melbourne shuffle, everybody!ï»¿  SPAM\n",
       "4      Facebook account HACK!! http://hackfbaccountl...   HAM\n",
       "...                                                 ...   ...\n",
       "1174                                        Great songï»¿   HAM\n",
       "1175                                         subscribeï»¿   HAM\n",
       "1176                                               LoLï»¿   HAM\n",
       "1177                                    Love this songï»¿   HAM\n",
       "1178                     LOVE THE WAY YOU LIE ..&quot;ï»¿   HAM\n",
       "\n",
       "[1179 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview training data\n",
    "training_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3f0123c-a7a5-4a35-82fc-a5a616cd5000",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "For an example of how to use the `WeakLabels` object with Snorkel's raw `LabelModel` class, you can check out the [WeakLabels reference](../../reference/python/python_labeling.rst).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c1f69fc-7f2f-4b57-8262-a0a6c2f92329",
   "metadata": {},
   "source": [
    "#### Label model with FlyingSquid\n",
    "\n",
    "FlyingSquid is a powerful method developed by [Hazy Research](https://hazyresearch.stanford.edu/), a research group from Stanford behind ground-breaking work on programmatic data labeling, including Snorkel.\n",
    "FlyingSquid uses a closed-form solution for fitting the label model with great speed gains and similar performance.\n",
    "Just like for Snorkel, Argilla provides built-in support for FlyingSquid, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55482c-02f6-4e7a-8637-0aa50e4e9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flyingsquid pgmpy -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ede78a-0fe6-4f2b-87b1-3d0f06f0c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.labeling.text_classification import FlyingSquid\n",
    "\n",
    "# we pass our WeakLabels instance to our FlyingSquid label model\n",
    "flyingsquid_model = FlyingSquid(weak_labels)\n",
    "\n",
    "# we fit the model\n",
    "flyingsquid_model.fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21b834d9-ca48-480f-89ee-493dd974ba95",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "The `FlyingSquid` label model is not suited for multi-label classification tasks and does not support them.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d81dbf5-edf9-4c8c-a876-5fcb16d73090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        SPAM       0.92      0.93      0.93       106\n",
      "         HAM       0.94      0.92      0.93       114\n",
      "\n",
      "    accuracy                           0.93       220\n",
      "   macro avg       0.93      0.93      0.93       220\n",
      "weighted avg       0.93      0.93      0.93       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we check its performance\n",
    "print(flyingsquid_model.score(output_str=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b287726d-c4c6-424b-9ed8-e8453702744c",
   "metadata": {},
   "source": [
    "Again, let's correct the accuracy for the abstentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641b855-ef30-4d84-a917-532a7ba12be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fractions using the support metric (see above)\n",
    "frac_non = 209 / len(weak_labels.annotation())\n",
    "frac_abs = 1 - (209 / len(weak_labels.annotation()))\n",
    "\n",
    "# accuracy without abstentions: 0.93; accuracy of random classifier: 0.5\n",
    "print(\"accuracy_c:\", frac_non * 0.93 + frac_abs * 0.5)\n",
    "# accuracy_c: 0.85948"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "678757c6-9ceb-46f2-949f-5fd10cb8685b",
   "metadata": {},
   "source": [
    "Here, it really seems that with **an accuracy of 0.859**, the performance over the whole test set is actually slightly worse than the baseline of the majority vote.\n",
    "\n",
    "After fitting your label model, you can quickly explore its predictions, before building a training set for training a downstream text classifier. \n",
    "This step is useful for validation, manual revision, or defining score thresholds for accepting labels from your label model (for example, only considering labels with a score greater than 0.8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30478c-fdda-445f-ad49-cac01b8bde71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your training records with the predictions of the label model\n",
    "records_for_training = flyingsquid_model.predict()\n",
    "\n",
    "# log the records to a new dataset in Argilla\n",
    "rg.log(records_for_training, name=\"flyingsquid_results\")\n",
    "\n",
    "# extract training data\n",
    "training_data = pd.DataFrame(\n",
    "    [{\"text\": rec.text, \"label\": rec.prediction[0][0]} for rec in records_for_training]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d641340-f82b-4af8-b86b-7c06eaf59f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.rtbf.be/tv/emission/detail_the-voic...</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.ermail.pl/dolacz/V3VeYGIN CLICK  ht...</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect! &amp;lt;3ï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Check out Melbourne shuffle, everybody!ï»¿</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook account HACK!! http://hackfbaccountl...</td>\n",
       "      <td>SPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>Great songï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>subscribeï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>LoLï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>Love this songï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>LOVE THE WAY YOU LIE ..&amp;quot;ï»¿</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1179 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     http://www.rtbf.be/tv/emission/detail_the-voic...  SPAM\n",
       "1     http://www.ermail.pl/dolacz/V3VeYGIN CLICK  ht...  SPAM\n",
       "2                                       Perfect! &lt;3ï»¿   HAM\n",
       "3              Check out Melbourne shuffle, everybody!ï»¿  SPAM\n",
       "4      Facebook account HACK!! http://hackfbaccountl...  SPAM\n",
       "...                                                 ...   ...\n",
       "1174                                        Great songï»¿   HAM\n",
       "1175                                         subscribeï»¿   HAM\n",
       "1176                                               LoLï»¿   HAM\n",
       "1177                                    Love this songï»¿   HAM\n",
       "1178                     LOVE THE WAY YOU LIE ..&quot;ï»¿   HAM\n",
       "\n",
       "[1179 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview training data\n",
    "training_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06cec1b4-97c8-45a0-9fc4-06e663b9ee4d",
   "metadata": {},
   "source": [
    "#### Joint Model with Weasel\n",
    "\n",
    "[Weasel](https://github.com/autonlab/weasel) lets you train downstream models end-to-end using directly weak labels.\n",
    "In contrast to Snorkel or FlyingSquid, which are two-stage approaches, Weasel is a one-stage method that jointly trains the label and the end model at the same time.\n",
    "For more details check out the [End-to-End Weak Supervision paper](https://arxiv.org/abs/2107.02233) presented at NeurIPS 2021.\n",
    "\n",
    "In this guide, we will show you how you can **train a Hugging Face transformers** model directly **with weak labels using Weasel**.\n",
    "Since Weasel uses [PyTorch Lightning](https://pytorch-lightning.readthedocs.io/en/latest/) for the training, some basic knowledge of PyTorch is helpful, but not strictly necessary.\n",
    "\n",
    "Let's start with installing the Weasel Python package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1ac1d61-5a40-44dc-a340-46bbdb8852eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install git+https://github.com/autonlab/weasel#egg=weasel[all]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ffab015-2204-4986-b415-98ba95228736",
   "metadata": {},
   "source": [
    "The first step is to obtain our weak labels.\n",
    "For this, we use the same rules and dataset as in the examples above (Snorkel and FlyingSquid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc17f25f-a4c2-47a3-b8b2-ba9bf1966b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain our weak labels\n",
    "weak_labels = WeakLabels(rules=rules, dataset=\"weak_supervision_yt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f6273d8-5765-4979-b3eb-3b648b789796",
   "metadata": {},
   "source": [
    "In the second step, we instantiate our end model, which, in our case, will be a pre-trained transformer from the Hugging Face Hub.\n",
    "Here we choose the small ELECTRA model by Google that shows excellent performance given its moderate number of parameters.\n",
    "Due to its size, you can fine-tune it on your CPU within a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598eac51-5ae9-4d16-aeca-df8c10a00f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weasel.models.downstream_models.transformers import Transformers\n",
    "\n",
    "# instantiate our transformers end model\n",
    "end_model = Transformers(\"google/electra-small-discriminator\", num_labels=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dcec749-929f-439b-969a-620380319363",
   "metadata": {},
   "source": [
    "With our end-model at hand, we can now instantiate the Weasel model.\n",
    "Apart from the end-model, it also includes a neural encoder that tries to estimate latent labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a8cc63-aed4-490d-9930-72e474c8836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weasel.models import Weasel\n",
    "\n",
    "# instantiate our weasel end-to-end model\n",
    "weasel = Weasel(\n",
    "    end_model=end_model,\n",
    "    num_LFs=len(weak_labels.rules),\n",
    "    n_classes=2,\n",
    "    encoder={\"hidden_dims\": [32, 10]},\n",
    "    optim_encoder={\"name\": \"adam\", \"lr\": 1e-4},\n",
    "    optim_end_model={\"name\": \"adam\", \"lr\": 5e-5},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0d48a81-2a0c-4958-9b49-093c48beb0d5",
   "metadata": {},
   "source": [
    "Afterwards, we wrap our data in the `TransformersDataModule`, so that Weasel and PyTorch Lightning can work with it.\n",
    "In this step, we also tokenize the data. \n",
    "Here, we need to be careful to use the corresponding tokenizer to our end-model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa1b28-cf3a-4c4e-9ccf-1ac67777ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from weasel.datamodules.transformers_datamodule import (\n",
    "    TransformersDataModule,\n",
    "    TransformersCollator,\n",
    ")\n",
    "\n",
    "# tokenizer for our transformers end model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
    "\n",
    "# tokenize train and test data\n",
    "X_train = [\n",
    "    tokenizer(rec.text, truncation=True)\n",
    "    for rec in weak_labels.records(has_annotation=False)\n",
    "]\n",
    "X_test = [\n",
    "    tokenizer(rec.text, truncation=True)\n",
    "    for rec in weak_labels.records(has_annotation=True)\n",
    "]\n",
    "\n",
    "# instantiate data module\n",
    "datamodule = TransformersDataModule(\n",
    "    label_matrix=weak_labels.matrix(has_annotation=False),\n",
    "    X_train=X_train,\n",
    "    collator=TransformersCollator(tokenizer),\n",
    "    X_test=X_test,\n",
    "    Y_test=weak_labels.annotation(),\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30b35f33-a9e1-4289-84d5-bcc1d4c1c200",
   "metadata": {},
   "source": [
    "Now, we have everything ready to start the training of our Weasel model.\n",
    "For the training process, Weasel relies on the excellent [PyTorch Lightning Trainer](https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html).\n",
    "It provides tons of options and features to optimize the training process but the defaults below should give you reasonable results.\n",
    "Keep in mind that you are fine-tuning a full-blown transformer model, albeit a small one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90b1ed-f2c6-4993-bf62-c15964cec3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "# instantiate the pytorch-lightning trainer\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,  # >= 1 to use GPU(s)\n",
    "    max_epochs=2,\n",
    "    logger=None,\n",
    "    callbacks=[pl.callbacks.ModelCheckpoint(monitor=\"Val/accuracy\", mode=\"max\")],\n",
    ")\n",
    "\n",
    "# fit the model end-to-end\n",
    "trainer.fit(\n",
    "    model=weasel,\n",
    "    datamodule=datamodule,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "080f22be-7555-431b-b416-d1b57ef46128",
   "metadata": {},
   "source": [
    "After the training, we can call the `Trainer.test` method to check the final performance. \n",
    "The model should achieve a test accuracy of around 0.94."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb06a5e6-680f-47e1-bb74-1e97917c59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()\n",
    "# {'accuracy': 0.94, ...}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d54ef7cc-9c4f-444a-a6a0-5e4bac36c04f",
   "metadata": {},
   "source": [
    "To use the model for inference, you can either use its *predict* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9daafb6-937a-46d4-932d-4fd7296b9880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text for the inference\n",
    "text = \"In my head this is like 2 years ago.. Time FLIES\"\n",
    "\n",
    "# Get predictions for the example text\n",
    "predicted_probs, predicted_label = weasel.predict(tokenizer(text, return_tensors=\"pt\"))\n",
    "\n",
    "# Map predicted int to label\n",
    "weak_labels.int2label[int(predicted_label)]  # HAM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aabc852-4e91-4d4b-86b3-da1e9eea4f04",
   "metadata": {},
   "source": [
    "Or you can instantiate one of the popular transformers pipelines, providing directly the end-model and the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f8aed5-6618-4170-b144-87bd8863e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# modify the id2label mapping of the model\n",
    "weasel.end_model.model.config.id2label = weak_labels.int2label\n",
    "\n",
    "# create transformers pipeline\n",
    "classifier = pipeline(\n",
    "    \"text-classification\", model=weasel.end_model.model, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# use pipeline for predictions\n",
    "classifier(text)  # [{'label': 'HAM', 'score': 0.6110987663269043}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2584bca9d226488c39a669ff1ce19d7ca5f410e2d3aa9b82f20653edd0d96bfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
