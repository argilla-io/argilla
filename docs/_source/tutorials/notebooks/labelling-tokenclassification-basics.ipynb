{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üóÇÔ∏è Assign records to your annotation team\n",
    "\n",
    "In this tutorial, you will learn how to assign records to specific users so that you can avoid or control the overlap in annotations. It will walk you through the following steps:\n",
    "\n",
    "- üì• Loading a dataset \n",
    "- üîÄ Make a random assignment \n",
    "- üíæ Log your dataset and assignments in Argilla \n",
    "- ‚úçÔ∏è Annotate records assigned to you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. note::\n",
    "This tutorial applies only to Text2Text, Token Classification and Text Classification datasets. To assign annotations in Feedback datasets follow [this guide](../../practical_guides/assign_records.md)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Annotations are often done by teams that share the workload. When this is the case, we want to avoid annotation overlap for efficiency or to control when and how this overlap happens. To do this in Argilla `(v1.6.0)` we have two options: \n",
    "\n",
    "1. we can keep a single dataset and assign a set of records to each user.\n",
    "\n",
    "2. we can split our dataset into different datasets that have the records assigned to each user and log them in their personal workspaces.\n",
    "\n",
    "You may want to use option 1 if you want to keep the whole dataset available to see and explore for every team member but still, you want them to focus on a set of records when they annotate. This can be interesting if your annotators also make weak labeling rules based on the annotations of the whole team.\n",
    "\n",
    "Option 2 is better if you want each team member to work independently and not see the records that other teammates are working on. This can be interesting if you want to measure annotator agreement afterwards.\n",
    "\n",
    "In this tutorial, we will make a random assignment where each record is annotated by one person only and walk you through sharing your assignments with your team using each option. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces**: If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](../../getting_started/quickstart.ipynb). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "    \n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this tutorial, you'll need to install the Argilla client and a few third-party libraries using `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install argilla datasets==2.10.1 httpx==0.23.3 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the Argilla module for reading and writing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running Argilla using the Docker quickstart image or Hugging Face Spaces, you need to init the Argilla client with the `URL` and `API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\", \n",
    "    api_key=\"admin.apikey\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running a private Hugging Face Space, you will also need to set the [HF_TOKEN](https://huggingface.co/settings/tokens) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the HF_TOKEN environment variable\n",
    "# import os\n",
    "# os.environ['HF_TOKEN'] = \"your-hf-token\"\n",
    "\n",
    "# # Replace api_url with the url to your HF Spaces URL\n",
    "# # Replace api_key if you configured a custom API key\n",
    "# rg.init(\n",
    "#     api_url=\"https://[your-owner-name]-[your_space_name].hf.space\", \n",
    "#     api_key=\"admin.apikey\",\n",
    "#     extra_headers={\"Authorization\": f\"Bearer {os.environ['HF_TOKEN']}\"},\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Telemetry\n",
    "\n",
    "We gain valuable insights from how you interact with our tutorials. To improve ourselves in offering you the most suitable content, using the following lines of code will help us understand that this tutorial is serving you effectively. Though this is entirely anonymous, you can choose to skip this step if you prefer. For more info, please check out the [Telemetry](../../reference/telemetry.md) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from argilla.utils.telemetry import tutorial_running\n",
    "    tutorial_running()\n",
    "except ImportError:\n",
    "    print(\"Telemetry is introduced in Argilla 1.20.0 and not found in the current installation. Skipping telemetry.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Loading a dataset\n",
    "\n",
    "We can work with a dataset that already exists in Argilla or load a completely new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an existing Argilla dataset\n",
    "\n",
    "We can load a whole dataset that was already logged in our Argilla instance or a selection of records in a dataset defined by a query. In this case, we have included a query so that we only load the records that haven't been annotated yet.\n",
    "Learn more about queries [here](../../practical_guides/filter_dataset.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load records with the \"Default\" status from a dataset\n",
    "ds = rg.load(\"gutenberg_spacy-ner\", query=\"status:Default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new dataset\n",
    "If you're working with a new dataset, then you'll need to create a new Argilla dataset object. Here, we have loaded the same dataset from the Huggingface hub. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = rg.DatasetForTokenClassification.from_datasets(\n",
    "    dataset=load_dataset('argilla/gutenberg_spacy-ner', split='train')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about loading and creating Argilla datasets [here](../../practical_guides/create_update_dataset/create_dataset.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÄ Make a random assignment\n",
    "\n",
    "As a first step, we want to get the list of the users who will be annotating our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get workspace where the dataset is (or will be) located\n",
    "ws = rg.Workspace.from_name(\"my_workspace\")\n",
    "# get the list of users with access to the workspace\n",
    "# make sure that all users who will work on the dataset have access to the workspace\n",
    "# optional: filter users to get only those with annotator role\n",
    "users = [u for u in rg.User.list() if u.role == \"annotator\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "\n",
    "If you are using a version earlier than 1.11.0 you will need to call the API directly to get the list of users as is done in the following cell. Note that, in that case, users will be returned as dictionaries and so `users.username` will be `users['username']` instead.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "rg_client= rg.active_client().client\n",
    "auth_headers = {\"X-Argilla-API-Key\": rg_client.token}\n",
    "http=httpx.Client(base_url=rg_client.base_url, headers=auth_headers)\n",
    "\n",
    "# make a request using our Argilla Client\n",
    "users = http.get(\"/api/users\").json()\n",
    "\n",
    "# optional: filter users to get only those with annotator role\n",
    "users = [u for u in users if u['role']=='annotator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will shuffle our dataset so that the assignment is random, but this step is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this cell if you don't want to shuffle the dataset\n",
    "import random\n",
    "\n",
    "random.shuffle(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start making the assignments. To do this, we will divide our dataset into chunks of the same length as the available annotators and save the assignments in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# build a dictionary where the key is the username and the value is the list of records assigned to them\n",
    "assignments = defaultdict(list)\n",
    "\n",
    "# divide your dataset into chunks of the same length as the users list and make the assignments\n",
    "n = len(users)\n",
    "chunked_records = [ds[i:i + n] for i in range(0, len(ds), n)]\n",
    "for chunk in chunked_records:\n",
    "    for idx, record in enumerate(chunk):\n",
    "        assignments[users[idx].username].append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Log your dataset and assignments in Argilla "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1\n",
    "If you want to follow option 1, where we have 1 dataset accessible to all teammates, you need to save the assignments as record metadata before logging them.\n",
    "\n",
    "Make sure that you log this dataset in a workspace that all the users who will work on it have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the assignments dictionary to save the metadata and build a list with all records\n",
    "assigned_records = []\n",
    "for user, records in assignments.items():\n",
    "    for record in records:\n",
    "        record.metadata['user'] = user\n",
    "        assigned_records.append(record)\n",
    "\n",
    "# log the records in Argilla\n",
    "rg.log(\n",
    "    records=assigned_records,\n",
    "    workspace='recognai',\n",
    "    name='gutenberg_spacy-ner',\n",
    "    tags={'with assignments': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2\n",
    "If you're following option 2, where annotators only have access to the records assigned to them, you need to log each user's assignments as a separate dataset in their individual workspace.\n",
    "\n",
    "For this to work, users who are going to annotate should have the `annotator` role so that they cannot access each other's workspaces. Whoever is supervising the project should have an `admin` role so they can work with datasets tied to this project.\n",
    "\n",
    "Learn more about managing user roles and access [here](../../getting_started/installation/configurations/user_management.md).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the dictionary and log the dataset for each user\n",
    "for user, records in assignments.items():\n",
    "    rg.log(\n",
    "        records=records,\n",
    "        workspace=user,\n",
    "        name='gutenberg_spacy-ner'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: If you plan to have more than one user annotating the same record, we recommend adding an ID to each record before splitting them into several datasets. That way you will be able to retrieve the different annotations for each record when postprocessing the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úçÔ∏è Annotate records assigned to you\n",
    "\n",
    "Now it's time to open the Argilla UI and start annotating!\n",
    "\n",
    "If you followed option 1, you want to ask your annotators to open the dataset in the UI, select their username under `Metadata`>`user` and click on the `Filter` button. This will filter the records assigned to them automatically.\n",
    "\n",
    "<img src=\"../../_static/tutorials/labelling-tokenclassification-basics/labelling-tokenclassification-basics-screenshot.png\" alt=\"Using the metadata filter to select annotations assigned to a specific person\" style=\"width: 1100px;\">\n",
    "\n",
    "If you followed option 2, just ask your annotators to open the dataset in their workspace and start annotating it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned how to split a dataset into random chunks so you can assign records to each member of your annotation team in two ways. In the first way, we kept a single dataset so that our team could choose whether to see the whole dataset or focus on the records assigned to them. In the second way, each annotator has a dataset with the records assigned to them and they cannot access the records of other teammates.\n",
    "\n",
    "This allows you to manage your annotation team and help them work more efficiently. üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d98cb9bf90a932b5bf8e86e91214497eb0e38eb318595fbd6fbd5460fe92036"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
