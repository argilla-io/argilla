{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d018ede1-93e5-44f7-a8b8-ea8436d063c1",
   "metadata": {},
   "source": [
    "# ðŸ¤— Build a custom sentiment classifier with SetFit and Argilla\n",
    "\n",
    "In this tutorial, we'll **build a sentiment classifier for user requests in the banking domain** using SetFit and Argilla.\n",
    "\n",
    "**SetFit** is an exciting open-source package for few-shot classification developed by teams at Hugging Face and Intel Labs. You can read all about it on the [project repository](https://github.com/huggingface/setfit). \n",
    "\n",
    "**Argilla** empowers you to quickly build and iterate on training data for NLP.\n",
    "\n",
    "Let's see how to combine them to build a sentiment classifier from scratch!\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial will show you how to fine-tune a sentiment classifier for your own domain, starting with no labeled data.\n",
    "\n",
    "Most online tutorials about fine-tuning models assume you already have a training dataset. You'll find many tutorials for fine-tuning a pre-trained model with widely-used datasets, such as IMDB for sentiment analysis. \n",
    "\n",
    "However, often **what you want is to fine-tune a model for your use case**. It's well-known that NLP model performance usually degrades with \"out-of-domain\" data. For example, a sentiment classifier pre-trained on movie reviews (e.g., IMDB) will not perform very well with customer requests.\n",
    "\n",
    "<img src=\"../../_static/tutorials/training-textclassification-setfit-sentiment/setfit_sentiment.png\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69321d8f-d3c4-4627-96ef-de416db75181",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In this tutorial, we'll use `setfit` and `datasets` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0991d97-a5e1-415b-9ae6-4df48e98a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install setfit datasets -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e511b-772b-4ee1-b1cd-5ee939c569fc",
   "metadata": {},
   "source": [
    "Let's import the modules we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f45016e-508b-498e-b8fb-83ec6fda2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import argilla as rg\n",
    "\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "from setfit import SetFitModel, SetFitTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2697c2cd-d6d1-45fb-97b6-2bf2b97d60c0",
   "metadata": {},
   "source": [
    "## Source dataset: `Banking 77`\n",
    "\n",
    "This dataset contains online banking user queries annotated with their corresponding intents. \n",
    "\n",
    "In our case, **we'll label the sentiment of these queries**. This might be useful for digital assistants and customer service analytics.\n",
    "\n",
    "\n",
    "Let's load the dataset directly from the Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73889eff-4214-4d49-bec9-816d5bf83175",
   "metadata": {},
   "outputs": [],
   "source": [
    "banking_ds = load_dataset(\"banking77\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3742e35a-6afc-4aeb-8701-b0245cd77350",
   "metadata": {},
   "source": [
    "### A note on sentiment analysis and data annotation\n",
    "\n",
    "Sentiment analysis is one of the most subjective tasks in NLP. What we understand by sentiment will vary from one application to another and depend on the business objectives of the project. Also, sentiment can be modeled in different ways, leading to different **labeling schemes**. \n",
    "\n",
    "For example, sentiment can be modeled as real value (going from -1 to 1, from 0 to 1.0, etc.) or with 2 or more labels (including different degrees such as positive, negative, neutral, etc.)\n",
    "\n",
    "For this tutorial, we'll use the **following labeling scheme**: `POSITIVE`, `NEGATIVE` and `NEUTRAL`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd871f0a-6056-4663-81f1-fc74a9cc03bb",
   "metadata": {},
   "source": [
    "## 1. Load the dataset and label a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c75da-288f-4b6f-8d9d-7f8f34c85c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "argilla_ds = rg.read_datasets(banking_ds, task=\"TextClassification\")\n",
    "\n",
    "rg.log(argilla_ds, \"banking_sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4950ad03-68ca-4b4b-9a8c-681aa39d3761",
   "metadata": {},
   "source": [
    "## 2. Hand labelling\n",
    "\n",
    "Now using Argilla UI you can label just a few examples (e.g., 50 examples).\n",
    "\n",
    "Once you have done that, just read and prepare the data for training your SetFit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b92b3a4a-709c-472c-a6a1-dcb74f07446b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 108\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 36\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_ds = rg.load(\"banking_sentiment\").prepare_for_training()\n",
    "labelled_ds = labelled_ds.train_test_split()\n"
    "labelled_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec30b04-76ff-482c-a263-7e1463fc93f5",
   "metadata": {},
   "source": [
    "## 3. Train our SetFit sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "012d8dec-2734-405e-ab67-9bc4adb841b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights.\n",
      "108 train samples in total, 540 train steps with batch size 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68306dacccdb45f598436446901d5bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a978e093a2644798f0c658fe39c5a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8611111111111112}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=labelled_ds[\"train\"],\n",
    "    eval_dataset=labelled_ds[\"test\"],\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=8,\n",
    "    num_iterations=20,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b659e-ebd4-4488-8f7f-7848e02fe09a",
   "metadata": {},
   "source": [
    "Here we are using the simplest approach for training our SetFit model. Since it [integrates with Optuna](https://github.com/huggingface/setfit/blob/main/notebooks/text-classification_hyperparameter-search.ipynb), you could use hyperparameter tuning to find the best hyperparamaters for training your model. However, it is better to start with a simple baseline, validate the model for your use case and iterate on the data before focusing on model experimentation and tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d3e6b-0684-47db-ab69-ff705945363f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how to build a training set from scratch and train a sentiment classifier for your own problem.\n",
    "\n",
    "Although this is a simple example, you can apply this same process to your own use case. \n",
    "\n",
    "Here, we've covered one way of building training sets: **hand labeling**.\n",
    "\n",
    "If want to discover other methods like weak supervision or active learning check the following tutorials:\n",
    "\n",
    "- [Building a news classifier with weak supervision](labelling-textclassification-sentencetransformers-weaksupervision.ipynb)\n",
    "- [Active learning with small-text](training-textclassification-smalltext-activelearning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a625c698-1b6b-4e71-8077-1649de637fca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Next steps\n",
    "\n",
    "\n",
    "ðŸ™‹â€â™€ï¸ Join the [Argilla Slack community](https://join.slack.com/t/rubrixworkspace/shared_invite/zt-whigkyjn-a3IUJLD7gDbTZ0rKlvcJ5g)\n",
    "\n",
    "ðŸ“š [Argilla documentation](https://docs.argilla.io) for more guides and tutorials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "39f4e3bd8ecb53b4a2ef9bccb982583dac0632e40e094b10b94294b76eaa26cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
