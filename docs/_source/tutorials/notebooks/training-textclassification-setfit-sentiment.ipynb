{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d018ede1-93e5-44f7-a8b8-ea8436d063c1",
   "metadata": {},
   "source": [
    "# ðŸ¤— Train a sentiment classifier with SetFit\n",
    "\n",
    "In this tutorial, we'll **build a sentiment classifier for user requests in the banking domain** using SetFit and Argilla.\n",
    "\n",
    "**SetFit** is an exciting open-source package for few-shot classification developed by teams at Hugging Face and Intel Labs. You can read all about it on the [project repository](https://github.com/huggingface/setfit). \n",
    "\n",
    "**Argilla** empowers you to quickly build and iterate on training data for NLP.\n",
    "\n",
    "Let's see how to combine them to build a sentiment classifier from scratch!\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial will show you how to fine-tune a sentiment classifier for your own domain, starting with no labeled data.\n",
    "\n",
    "Most online tutorials about fine-tuning models assume you already have a training dataset. You'll find many tutorials for fine-tuning a pre-trained model with widely used datasets, such as IMDB for sentiment analysis. \n",
    "\n",
    "However, often **what you want is to fine-tune a model for your use case**. It's well-known that NLP model performance usually degrades with \"out-of-domain\" data. For example, a sentiment classifier pre-trained on movie reviews (e.g., IMDB) will not perform very well with customer requests.\n",
    "\n",
    "<img src=\"../../_static/tutorials/training-textclassification-setfit-sentiment/setfit_sentiment.png\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69321d8f-d3c4-4627-96ef-de416db75181",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces**: If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](../../getting_started/quickstart.ipynb). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "    \n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter Notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0991d97-a5e1-415b-9ae6-4df48e98a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install argilla setfit datasets -qqq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fabdd145",
   "metadata": {},
   "source": [
    "Let's import the Argilla module for reading and writing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac811da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "556046ed",
   "metadata": {
    "id": "7TRNourOwigS"
   },
   "source": [
    "If you are running Argilla using the Docker quickstart image or Hugging Face Spaces, you need to init the Argilla client with the `URL` and `API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "# Replace workspace with the name of your workspace\n",
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\", \n",
    "    api_key=\"owner.apikey\",\n",
    "    workspace=\"admin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running a private Hugging Face Space, you will also need to set the [HF_TOKEN](https://huggingface.co/settings/tokens) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the HF_TOKEN environment variable\n",
    "# import os\n",
    "# os.environ['HF_TOKEN'] = \"your-hf-token\"\n",
    "\n",
    "# # Replace api_url with the url to your HF Spaces URL\n",
    "# # Replace api_key if you configured a custom API key\n",
    "# # Replace workspace with the name of your workspace\n",
    "# rg.init(\n",
    "#     api_url=\"https://[your-owner-name]-[your_space_name].hf.space\", \n",
    "#     api_key=\"owner.apikey\",\n",
    "#     workspace=\"admin\",\n",
    "#     extra_headers={\"Authorization\": f\"Bearer {os.environ['HF_TOKEN']}\"},\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5be64d5e",
   "metadata": {
    "id": "ccL8UFwj_CaD"
   },
   "source": [
    "Finally, let's include the imports we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f45016e-508b-498e-b8fb-83ec6fda2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from setfit import SetFitModel, SetFitTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Telemetry\n",
    "\n",
    "We gain valuable insights from how you interact with our tutorials. To improve ourselves in offering you the most suitable content, using the following lines of code will help us understand that this tutorial is serving you effectively. Though this is entirely anonymous, you can choose to skip this step if you prefer. For more info, please check out the [Telemetry](../../reference/telemetry.md) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from argilla.utils.telemetry import tutorial_running\n",
    "    tutorial_running()\n",
    "except ImportError:\n",
    "    print(\"Telemetry is introduced in Argilla 1.20.0 and not found in the current installation. Skipping telemetry.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2697c2cd-d6d1-45fb-97b6-2bf2b97d60c0",
   "metadata": {},
   "source": [
    "## Source dataset: `banking77`\n",
    "\n",
    "The [banking77](https://huggingface.co/datasets/banking77), available on the Hugging Face Hub, contains online banking user queries annotated with their corresponding intents. \n",
    "\n",
    "In our case, **we'll label the sentiment of these queries**. This might be useful for digital assistants and customer service analytics.\n",
    "\n",
    "\n",
    "Let's load the dataset directly from the Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73889eff-4214-4d49-bec9-816d5bf83175",
   "metadata": {},
   "outputs": [],
   "source": [
    "banking_ds = load_dataset(\"banking77\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4226a6b-1f57-473d-9481-2acd586432c1",
   "metadata": {},
   "source": [
    "Let's get a preview of the dataset's content using Pandas `head` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5648f1-9bc2-4b47-a6d4-e23b0bc60bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am still waiting on my card?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What can I do if my card still hasn't arrived ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been waiting over a week. Is the card s...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I track my card while it is in the process...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I know if I will get my card, or if it ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>When did you send me my new card?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Do you have info about the card on delivery?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What do I do if I still have not received my n...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Does the package with my card have tracking?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I ordered my card but it still isn't here</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Why has my new card still not come?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I still haven't received my card after two wee...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Can you track my card for me?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Is there a way to track the delivery of my card?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>It's been a week since I ordered my card and i...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "0                      I am still waiting on my card?     11\n",
       "1   What can I do if my card still hasn't arrived ...     11\n",
       "2   I have been waiting over a week. Is the card s...     11\n",
       "3   Can I track my card while it is in the process...     11\n",
       "4   How do I know if I will get my card, or if it ...     11\n",
       "5                   When did you send me my new card?     11\n",
       "6        Do you have info about the card on delivery?     11\n",
       "7   What do I do if I still have not received my n...     11\n",
       "8        Does the package with my card have tracking?     11\n",
       "9           I ordered my card but it still isn't here     11\n",
       "10                Why has my new card still not come?     11\n",
       "11  I still haven't received my card after two wee...     11\n",
       "12                      Can you track my card for me?     11\n",
       "13   Is there a way to track the delivery of my card?     11\n",
       "14  It's been a week since I ordered my card and i...     11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking_ds.to_pandas().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3742e35a-6afc-4aeb-8701-b0245cd77350",
   "metadata": {},
   "source": [
    "### A note on sentiment analysis and data annotation\n",
    "\n",
    "Sentiment analysis is one of the most subjective tasks in NLP. What we understand by sentiment will vary from one application to another and depend on the business objectives of the project. Also, sentiment can be modeled in different ways, leading to different **labeling schemes**. \n",
    "\n",
    "For example, sentiment can be modeled as real value (going from -1 to 1, from 0 to 1.0, etc.) or with 2 or more labels (including different degrees such as positive, negative, neutral, etc.)\n",
    "\n",
    "For this tutorial, we'll use the **following labeling scheme**: `POSITIVE`, `NEGATIVE` and `NEUTRAL`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd871f0a-6056-4663-81f1-fc74a9cc03bb",
   "metadata": {},
   "source": [
    "## 1. Load the dataset and label a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c75da-288f-4b6f-8d9d-7f8f34c85c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "argilla_ds = rg.read_datasets(banking_ds, task=\"TextClassification\")\n",
    "\n",
    "rg.log(argilla_ds, \"banking_sentiment\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4950ad03-68ca-4b4b-9a8c-681aa39d3761",
   "metadata": {},
   "source": [
    "## 2. Hand labeling\n",
    "\n",
    "In this step, you can use Argilla UI to label a few examples (e.g., 50 examples).\n",
    "\n",
    "Once you have labelled a few example, you can read and prepare the data for training your SetFit model.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "If you don't have time for labeling now we have labelled a small dataset with Argilla and pushed it to the Hugging Face Hub.\n",
    "    \n",
    "To use it replace the below cell with this code: \n",
    "\n",
    "    `labelled_ds = load_dataset(\"argilla/sentiment-banking-setfit\")`\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b92b3a4a-709c-472c-a6a1-dcb74f07446b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 108\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 36\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_ds = rg.load(\"banking_sentiment\").prepare_for_training()\n",
    "labelled_ds = labelled_ds.train_test_split()\n",
    "labelled_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec30b04-76ff-482c-a263-7e1463fc93f5",
   "metadata": {},
   "source": [
    "## 3. Train our SetFit sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "012d8dec-2734-405e-ab67-9bc4adb841b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights.\n",
      "108 train samples in total, 540 train steps with batch size 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68306dacccdb45f598436446901d5bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a978e093a2644798f0c658fe39c5a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8611111111111112}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=labelled_ds[\"train\"],\n",
    "    eval_dataset=labelled_ds[\"test\"],\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=8,\n",
    "    num_iterations=20,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b659e-ebd4-4488-8f7f-7848e02fe09a",
   "metadata": {},
   "source": [
    "Here we are using the simplest approach for training our SetFit model. Since it [integrates with Optuna](https://github.com/huggingface/setfit/blob/main/notebooks/text-classification_hyperparameter-search.ipynb), you could use hyperparameter tuning to find the best hyperparameter for training your model. However, it is better to start with a simple baseline, validate the model for your use case and iterate on the data before focusing on model experimentation and tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d3e6b-0684-47db-ab69-ff705945363f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how to build a training set from scratch and train a sentiment classifier for your own problem.\n",
    "\n",
    "Although this is a simple example, you can apply this same process to your own use case. \n",
    "\n",
    "Here, we've covered one way of building training sets: **hand labeling**.\n",
    "\n",
    "If you are interested in SetFit, you can check our other SetFit + Argilla tutorials:\n",
    "\n",
    "- [Zero-shot and few-shot classification with SetFit](/tutorials/notebooks/labelling-textclassification-setfit-zeroshot.html)\n",
    "- [Few-shot classification with SetFit](training-textclassification-setfit-fewshot.ipynb)\n",
    "\n",
    "Or check out the [SetFit repository on GitHub](https://github.com/huggingface/setfit).\n",
    "\n",
    "If want to discover other methods like weak supervision or active learning check the following tutorials:\n",
    "\n",
    "- [Building a news classifier with weak supervision](labelling-textclassification-sentencetransformers-weaksupervision.ipynb)\n",
    "- [Active learning with small-text](training-textclassification-smalltext-activelearning.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a89950ea50845724e7eccac1d52607e0edbb142472dde8c3f43ca41b572e2025"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
