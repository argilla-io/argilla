{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast active learning with `classy-classification`\n",
    "\n",
    "\n",
    "In this tutorial, we will show you how we can use an intuitive few-shot learning package in a straightforward active learning loop. It will walk you through the following steps:\n",
    "\n",
    "- üíø load data into Argilla \n",
    "- ‚è± train a few-shot classifier using `classy-classification` \n",
    "- üïµüèΩ‚Äç‚ôÇÔ∏è define active learning heuristics\n",
    "- üîÅ set-up an active-learning loop\n",
    "\n",
    "\n",
    "<img src=\"../../_static/tutorials/training-textclassification-classyclassification-activelearning/training-textclassification-classyclassification-activelearning.png\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "One of the potential difficulties that arise with active learning, is the speed by which the model is able to update. Transformer models are amazing but do require a GPU to fine-tune and people do not always have access to those. Similarly, fine-tuning transformer models requires a fair amount of initial data. Luckily, `classy-classification` can be used to solve both of these problems!\n",
    "\n",
    "These other active learning methods can be found [here](../techniques/active_learning.md).\n",
    "So, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Apart from Argilla, we'll need a few third party libraries that can be installed via pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"classy-classification[onnx]==0.6.0\" -qqq\n",
    "%pip install \"argilla[listeners]>=1.1.0\" -qqq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíø load data into Argilla  \n",
    "\n",
    "For this analysis, we will be using [our news dataset](https://huggingface.co/datasets/argilla/news) from the HuggingFace hub. This is a news classification task, which requires the texts to be classified into 4 categories: ```[\"World\", \"Sports\", \"Sci/Tech\", \"Business\"]```. Due to the [nice integration with the HuggingFace hub](../../guides/features/datasets.html), we can do this easily, within several lines of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 records logged to https://pre.argilla.io/datasets/recognai/news-unlabelled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='news-unlabelled', processed=500, failed=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argilla as rg\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load from datasets\n",
    "my_dataset = load_dataset(\"argilla/news\")\n",
    "dataset_rg = rg.read_datasets(my_dataset[\"train\"], task=\"TextClassification\")\n",
    "\n",
    "# log subset into argilla\n",
    "rg.log(dataset_rg[:500], \"news-unlabelled\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have loaded the data, we can start creating some training examples for our few-shot classifier. To get a nice headstart, we will label roughly `4 labels` per class within the Argilla UI.\n",
    "\n",
    "<img src=\"../../_static/tutorials/training-textclassification-classyclassification-activelearning/news_labelled_data.png\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è± train a few-shot classifier \n",
    "\n",
    "Using the labelled data, we can now obtain training samples for our few-shot classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business': 0.2686566277246892,\n",
       " 'Sci/Tech': 0.2415910117784897,\n",
       " 'Sports': 0.22240821993980525,\n",
       " 'World': 0.267344140557016}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from classy_classification import ClassyClassifier\n",
    "import argilla as rg\n",
    "\n",
    "# load the dataset\n",
    "train_rg = rg.load(\"news-unlabelled\", query=\"status: Validated\")\n",
    "\n",
    "# Get some annotated examples per class\n",
    "n_samples_per_class = 5\n",
    "data = {\"World\": [], \"Sports\": [], \"Sci/Tech\": [], \"Business\": []}\n",
    "while not all([len(value)== n_samples_per_class for key,value in data.items()]):\n",
    "    for idx, rec in enumerate(train_rg):\n",
    "        if len(data[rec.annotation]) < n_samples_per_class:\n",
    "            data[rec.annotation].append(rec.text)\n",
    "            \n",
    "# train a few-shot classifier\n",
    "classifier = ClassyClassifier(data=data, model=\"all-MiniLM-L6-v2\")\n",
    "classifier(\"This texts is about games, goals, matches and sports.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are not good yet, but they will get better once we start our active-learning loop."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üïµüèΩ‚Äç‚ôÇÔ∏è active learning heuristics\n",
    "\n",
    "During an active learning loop, we want to simplify the annotation progress during each training iteration. We will do this by:\n",
    "\n",
    "- use `5` samples per loop.\n",
    "- defining a certainty threshold of `0.9`, for which we will assume that the prediction can be validated automatically.\n",
    "- infer the record prediction scores using the model from the previous loop.\n",
    "- check and annotate the samples that do not reach the automatic validation.\n",
    "- adding the annotated samples to our training data.\n",
    "- make predictions for a second loop of `5` samples.\n",
    "  \n",
    "Throughout these loops, our predictions will produce more certain scores, which will make the annotation process easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67dbd7371364134884526f96e7c4f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 records logged to https://pre.argilla.io/datasets/recognai/news-active-learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='news-active-learning', processed=5, failed=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argilla as rg\n",
    "\n",
    "# Define heristic variables variables\n",
    "NUM_SAMPLES_PER_LOOP = 5\n",
    "CERTAINTY_THRESHOLD = 0.9\n",
    "loop_data = data\n",
    "\n",
    "# load input data\n",
    "ds = rg.load(\"news-unlabelled\", query=\"status: Default\", limit=1000)\n",
    "\n",
    "# create active learning dataset\n",
    "DATASET_NAME = \"news-active-learning\"\n",
    "try:\n",
    "    rg.delete(DATASET_NAME)\n",
    "except Exception:\n",
    "    pass\n",
    "settings = rg.TextClassificationSettings(label_schema=list(data.keys()))\n",
    "rg.configure_dataset(name=DATASET_NAME, settings=settings)\n",
    "\n",
    "# evalaute and update records\n",
    "def evaluate_records(records, idx = 0):\n",
    "    texts = [rec.text for rec in records]\n",
    "    predictions = [list(pred.items()) for pred in classifier.pipe(texts)]\n",
    "    for pred, rec in zip(predictions, records):\n",
    "        max_score = max(pred, key=lambda item: item[1])\n",
    "        if max_score[1] > CERTAINTY_THRESHOLD:\n",
    "            rec.annotation = max_score[0]\n",
    "            rec.status = \"Validated\"\n",
    "        rec.prediction = pred\n",
    "        rec.metadata = {\"idx\": idx}\n",
    "    return records\n",
    "\n",
    "# log initial predictions\n",
    "ds_slice = evaluate_records(ds[:NUM_SAMPLES_PER_LOOP])\n",
    "rg.log(ds[:NUM_SAMPLES_PER_LOOP], DATASET_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ set-up an active-learning loop\n",
    "\n",
    "We will set-up the active-learning loop using [Argilla Listeners](../../guides/features/features.md). Argilla Listeners enable you to build fine-grained complex workflows as background processes, like a low-key alternative to job scheduling directly integrated with Argilla. So, they are a perfect fit for waiting on new annotations and adding logging newly inferred predictions in the background. \n",
    "\n",
    "Note that restarting the loop, also requires a reset of the `data` used for the initial classifier training.\n",
    "\n",
    "0. prepare\n",
    "   1. start the loop\n",
    "   2. set status filter to `Default`\n",
    "   3. validate the 10 initially logged record\n",
    "   4. don`t forget to refresh the record page\n",
    "1. update the classifier with the annotated data\n",
    "2. make predictions on new data\n",
    "3. log predictions\n",
    "4. annotate the second loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla import listener\n",
    "\n",
    "# Set up the active learning loop with the listener decorator\n",
    "@listener(\n",
    "    dataset=DATASET_NAME,\n",
    "    query=\"(status:Validated OR status:Discarded) AND metadata.idx:{idx}\",\n",
    "    condition=lambda search: search.total == NUM_SAMPLES_PER_LOOP,\n",
    "    execution_interval_in_seconds=1,\n",
    "    idx=0,\n",
    ")\n",
    "def active_learning_loop(records, ctx):\n",
    "    idx = ctx.query_params[\"idx\"]\n",
    "    new_idx = idx+NUM_SAMPLES_PER_LOOP\n",
    "    print(\"1. train a few-shot classifier with validated data\")\n",
    "    for rec in records:\n",
    "        if rec.status == \"Validated\":\n",
    "            loop_data[rec.annotation].append(rec.text)\n",
    "    classifier.set_training_data(loop_data)\n",
    "\n",
    "    print(\"2. get new record predictions\")\n",
    "    ds_slice = ds[new_idx: new_idx+NUM_SAMPLES_PER_LOOP]\n",
    "    records_to_update = evaluate_records(ds_slice, new_idx)\n",
    "    texts = [rec.text for rec in ds_slice]\n",
    "    predictions = [list(pred.items()) for pred in classifier.pipe(texts)]\n",
    "    \n",
    "    print(\"3. update query params\")\n",
    "    ctx.query_params[\"idx\"] = new_idx\n",
    "\n",
    "    print(\"4. Log the batch to Argilla\")\n",
    "    rg.log(records_to_update, DATASET_NAME)\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "    print(f\"Waiting for next {new_idx} annotations ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. train a few-shot classifier with validated data\n",
      "2. get new record predictions\n",
      "3. update query params\n",
      "4. Log the batch to Argilla\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abe2d7ad8d64eeeb04eaa5641bdc350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 records logged to https://pre.argilla.io/datasets/recognai/news-active-learning\n",
      "Done!\n",
      "Waiting for next 5 annotations ...\n"
     ]
    }
   ],
   "source": [
    "active_learning_loop.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"https://share.descript.com/embed/nvlUjF8tNcZ\" width=\"100%\" height=\"600\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned how to use an active learner with Argill and what heuristics we can apply for defining an active learner.\n",
    "This can help us reduce the development time required for creating a new text classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "‚≠ê Argilla [Github repo](https://github.com/argilla-io/argilla) to stay updated.\n",
    "\n",
    "üìö [Argilla documentation](https://docs.argilla.io) for more guides and tutorials.\n",
    "\n",
    "üôã‚Äç‚ôÄÔ∏è Join the Argilla community! A good place to start is the [discussion forum](https://github.com/argilla-io/argilla/discussions)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Nov 24 2022, 21:36:36) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "39f4e3bd8ecb53b4a2ef9bccb982583dac0632e40e094b10b94294b76eaa26cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
