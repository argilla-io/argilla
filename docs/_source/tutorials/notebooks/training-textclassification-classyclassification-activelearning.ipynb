{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification active learning with `classy-classification`\n",
    "\n",
    "\n",
    "In this tutorial, we will show you how we can use an intuitive few-shot learning package in a straightforward active learning loop. It will walk you through the following steps:\n",
    "\n",
    "- üíø load data into Argilla \n",
    "- ‚è± train a few-shot classifier using `classy-classification` \n",
    "- üïµüèΩ‚Äç‚ôÇÔ∏è define active learning heuristics\n",
    "- üîÅ set up an active learning loop\n",
    "- üé• A live demo video\n",
    "\n",
    "\n",
    "<img src=\"../../_static/tutorials/training-textclassification-classyclassification-activelearning/training-textclassification-classyclassification-activelearning.png\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "One of the potential difficulties that arise with active learning, is the speed by which the model is able to update. Transformer models are amazing but do require a GPU to fine-tune and people do not always have access to those. Similarly, fine-tuning transformer models requires a fair amount of initial data. Luckily, `classy-classification` can be used to solve both of these problems!\n",
    "\n",
    "These other active learning methods can be found [here](../techniques/active_learning.md).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces**: If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](../../getting_started/quickstart.ipynb). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "    \n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter Notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"classy-classification[onnx]==0.6.0\" -qqq\n",
    "%pip install \"argilla[listeners]>=1.1.0\" -qqq\n",
    "%pip install datasets -qqq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the Argilla module for reading and writing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running Argilla using the Docker quickstart image or Hugging Face Spaces, you need to init the Argilla client with the `URL` and `API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "# Replace workspace with the name of your workspace\n",
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\", \n",
    "    api_key=\"owner.apikey\",\n",
    "    workspace=\"admin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running a private Hugging Face Space, you will also need to set the [HF_TOKEN](https://huggingface.co/settings/tokens) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the HF_TOKEN environment variable\n",
    "# import os\n",
    "# os.environ['HF_TOKEN'] = \"your-hf-token\"\n",
    "\n",
    "# # Replace api_url with the url to your HF Spaces URL\n",
    "# # Replace api_key if you configured a custom API key\n",
    "# # Replace workspace with the name of your workspace\n",
    "# rg.init(\n",
    "#     api_url=\"https://[your-owner-name]-[your_space_name].hf.space\", \n",
    "#     api_key=\"owner.apikey\",\n",
    "#     workspace=\"admin\",\n",
    "#     extra_headers={\"Authorization\": f\"Bearer {os.environ['HF_TOKEN']}\"},\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's include the imports we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classy_classification import ClassyClassifier\n",
    "from datasets import load_dataset\n",
    "from argilla import listener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Telemetry\n",
    "\n",
    "We gain valuable insights from how you interact with our tutorials. To improve ourselves in offering you the most suitable content, using the following lines of code will help us understand that this tutorial is serving you effectively. Though this is entirely anonymous, you can choose to skip this step if you prefer. For more info, please check out the [Telemetry](../../reference/telemetry.md) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from argilla.utils.telemetry import tutorial_running\n",
    "    tutorial_running()\n",
    "except ImportError:\n",
    "    print(\"Telemetry is introduced in Argilla 1.20.0 and not found in the current installation. Skipping telemetry.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíø Load data into Argilla  \n",
    "\n",
    "For this analysis, we will be using [our news dataset](https://huggingface.co/datasets/argilla/news) from the HuggingFace hub. This is a news classification task, which requires the texts to be classified into 4 categories: ```[\"World\", \"Sports\", \"Sci/Tech\", \"Business\"]```. Due to the [nice integration with the HuggingFace hub](../../guides/features/datasets.html), we can easily do this within several lines of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from datasets\n",
    "my_dataset = load_dataset(\"argilla/news\")\n",
    "dataset_rg = rg.read_datasets(my_dataset[\"train\"], task=\"TextClassification\")\n",
    "\n",
    "# Log subset into argilla\n",
    "rg.log(dataset_rg[:500], \"news-unlabelled\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the data, we can start creating some training examples for our few-shot classifier. To get a nice headstart, we will label roughly `4 labels` per class within the Argilla UI.\n",
    "\n",
    "<img src=\"../../_static/tutorials/training-textclassification-classyclassification-activelearning/news_labelled_data.png\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è± Train a few-shot classifier \n",
    "\n",
    "Using the labelled data, we can now obtain training samples for our few-shot classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business': 0.2686566277246892,\n",
       " 'Sci/Tech': 0.2415910117784897,\n",
       " 'Sports': 0.22240821993980525,\n",
       " 'World': 0.267344140557016}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_rg = rg.load(\"news-unlabelled\", query=\"status: Validated\")\n",
    "\n",
    "# Get some annotated examples per class\n",
    "n_samples_per_class = 5\n",
    "data = {\"World\": [], \"Sports\": [], \"Sci/Tech\": [], \"Business\": []}\n",
    "while not all([len(value)== n_samples_per_class for key,value in data.items()]):\n",
    "    for idx, rec in enumerate(train_rg):\n",
    "        if len(data[rec.annotation]) < n_samples_per_class:\n",
    "            data[rec.annotation].append(rec.text)\n",
    "            \n",
    "# Train a few-shot classifier\n",
    "classifier = ClassyClassifier(data=data, model=\"all-MiniLM-L6-v2\")\n",
    "classifier(\"This texts is about games, goals, matches and sports.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are not good yet, but they will get better once we start our active learning loop."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üïµüèΩ‚Äç‚ôÇÔ∏è Active learning heuristics\n",
    "\n",
    "During an active learning loop, we want to simplify the annotation progress during each training iteration. We will do this by:\n",
    "\n",
    "- use `5` samples per loop.\n",
    "- defining a certainty threshold of `0.9`, for which we will assume that the prediction can be validated automatically.\n",
    "- infer the record prediction scores using the model from the previous loop.\n",
    "- check and annotate the samples that do not reach the automatic validation.\n",
    "- adding the annotated samples to our training data.\n",
    "- make predictions for a second loop of `5` samples.\n",
    "  \n",
    "Throughout these loops, our predictions will produce more certain scores, which will make the annotation process easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define heuristic variables variables\n",
    "NUM_SAMPLES_PER_LOOP = 5\n",
    "CERTAINTY_THRESHOLD = 0.9\n",
    "loop_data = data\n",
    "\n",
    "# Load input data\n",
    "ds = rg.load(\"news-unlabelled\", query=\"status: Default\", limit=1000)\n",
    "\n",
    "# Create the active learning dataset\n",
    "DATASET_NAME = \"news-active-learning\"\n",
    "try:\n",
    "    rg.delete(DATASET_NAME)\n",
    "except Exception:\n",
    "    pass\n",
    "settings = rg.TextClassificationSettings(label_schema=list(data.keys()))\n",
    "rg.configure_dataset_settings(name=DATASET_NAME, settings=settings)\n",
    "\n",
    "# Evaluate and update records\n",
    "def evaluate_records(records, idx = 0):\n",
    "    texts = [rec.text for rec in records]\n",
    "    predictions = [list(pred.items()) for pred in classifier.pipe(texts)]\n",
    "    for pred, rec in zip(predictions, records):\n",
    "        max_score = max(pred, key=lambda item: item[1])\n",
    "        if max_score[1] > CERTAINTY_THRESHOLD:\n",
    "            rec.annotation = max_score[0]\n",
    "            rec.status = \"Validated\"\n",
    "        rec.prediction = pred\n",
    "        rec.metadata = {\"idx\": idx}\n",
    "    return records\n",
    "\n",
    "# Log initial predictions\n",
    "ds_slice = evaluate_records(ds[:NUM_SAMPLES_PER_LOOP])\n",
    "rg.log(ds[:NUM_SAMPLES_PER_LOOP], DATASET_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ Set up an active learning loop\n",
    "\n",
    "We will set-up the active learning loop using [Argilla Listeners](/reference/python/python_listeners.html). Argilla Listeners enable you to build fine-grained complex workflows as background processes, like a low-key alternative to job scheduling directly integrated with Argilla. So, they are a perfect fit for waiting on new annotations and adding logging newly inferred predictions in the background. \n",
    "\n",
    "Note that restarting the loop, also requires a reset of the `data` used for the initial classifier training.\n",
    "\n",
    "1. prepare\n",
    "   1. start the loop\n",
    "   2. set status filter to `Default`\n",
    "   3. validate the 10 initially logged record\n",
    "   4. don`t forget to refresh the record page\n",
    "2. update the classifier with the annotated data\n",
    "3. make predictions on new data\n",
    "4. log predictions\n",
    "5. annotate the second loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the active learning loop with the listener decorator\n",
    "@listener(\n",
    "    dataset=DATASET_NAME,\n",
    "    query=\"(status:Validated OR status:Discarded) AND metadata.idx:{idx}\",\n",
    "    condition=lambda search: search.total == NUM_SAMPLES_PER_LOOP,\n",
    "    execution_interval_in_seconds=1,\n",
    "    idx=0,\n",
    ")\n",
    "def active_learning_loop(records, ctx):\n",
    "    idx = ctx.query_params[\"idx\"]\n",
    "    new_idx = idx+NUM_SAMPLES_PER_LOOP\n",
    "    print(\"1. train a few-shot classifier with validated data\")\n",
    "    for rec in records:\n",
    "        if rec.status == \"Validated\":\n",
    "            loop_data[rec.annotation].append(rec.text)\n",
    "    classifier.set_training_data(loop_data)\n",
    "\n",
    "    print(\"2. get new record predictions\")\n",
    "    ds_slice = ds[new_idx: new_idx+NUM_SAMPLES_PER_LOOP]\n",
    "    records_to_update = evaluate_records(ds_slice, new_idx)\n",
    "    texts = [rec.text for rec in ds_slice]\n",
    "    predictions = [list(pred.items()) for pred in classifier.pipe(texts)]\n",
    "    \n",
    "    print(\"3. update query params\")\n",
    "    ctx.query_params[\"idx\"] = new_idx\n",
    "\n",
    "    print(\"4. Log the batch to Argilla\")\n",
    "    rg.log(records_to_update, DATASET_NAME)\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "    print(f\"Waiting for next {new_idx} annotations ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learning_loop.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé• A live demo video\n",
    "\n",
    "To show you the actual usage from within our UI, we¬¥ve created a live demo which you can watch underneath."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"https://share.descript.com/embed/nvlUjF8tNcZ\" width=\"100%\" height=\"600\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned how to use an active learner with Argilla and what heuristics we can apply to define an active learner.\n",
    "This can help us reduce the development time required for creating a new text classification model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 05:57:50) \n[Clang 11.1.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2584bca9d226488c39a669ff1ce19d7ca5f410e2d3aa9b82f20653edd0d96bfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
