{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44dca393-21cf-420c-a96c-3d08e2c17bea",
   "metadata": {},
   "source": [
    "# üî´ Zero-shot NER with Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f188f15e-7922-4aee-b4a3-ff003d49dc86",
   "metadata": {},
   "source": [
    "In this tutorial you will learn how to analyze and validate NER predictions from the new zero-shot model provided by the Flair NLP library with Argilla.\n",
    "\n",
    "- üõ† Useful for quickly bootstrapping a training set (using Argilla [*Annotation Mode*](../reference/webapp/annotate_records.md)) as well as integrating with weak-supervision workflows.\n",
    "- üëÅ We will use a challenging, exciting dataset: wnut_17 (more info below).\n",
    "- üîÆ You will be able to see and work with the obtained predictions.\n",
    "\n",
    "<video width=\"100%\" controls><source src=\"../../_static/tutorials/labelling-tokenclassification-flair-fewshot/zeroshot_tutorial.mp4\" type=\"video/mp4\"></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f6344",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial will show you how to work with Named Entity Recognition (NER), Flair and Argilla. But, what is NER?\n",
    "\n",
    "According to [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/06/part-10-step-by-step-guide-to-master-nlp-named-entity-recognition/), \n",
    "\"NER is a **natural language processing technique** that can automatically scan entire articles and pull out some fundamental entities in a text and classify them into predefined categories\". These entities can be names, quantities, dates and times, amounts of money/currencies, and much more. \n",
    "\n",
    "On the other hand, [Flair](https://github.com/flairNLP/flair) is a library which facilitates the application of NLP models to NER and other NLP techniques in many different languages. It is not only a powerful library, but also intuitive. \n",
    "\n",
    "Thanks to these resources and the [*Annotation Mode*](../reference/webapp/annotate_records.md) of *Argilla*, we can quickly build up a data set to train a domain-specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b710019-983d-43a4-84f6-7f8210b8cb48",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "Argilla, is a free and open-source tool to explore, annotate, and monitor data for NLP projects.\n",
    "\n",
    "If you are new to Argilla, check out the [Github repository](https://github.com/argilla/argilla) ‚≠ê.\n",
    "\n",
    "If you have not installed and launched Argilla yet, check the [Setup and Installation guide](../getting_started/setup&installation.rst).\n",
    "\n",
    "For this tutorial we also need the third party libraries datasets and flair, which can be installed via pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02acf9ed-ec17-49eb-aa1b-6ddf584ab348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"datasets~=2.6.0\" \"flair~=0.11.0\" -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc0dc5c-b925-4b77-85ac-1fab6f8c0994",
   "metadata": {},
   "source": [
    "## 1. Load the `wnut_17` dataset\n",
    "\n",
    "In this example, we'll use a challenging NER dataset, the **\"WNUT 17: Emerging and Rare entity recognition\"** , which focuses on unusual, previously-unseen entities in the context of emerging discussions. This dataset is useful for getting a sense of the quality of our zero-shot predictions.\n",
    "\n",
    "Let's load the test set from the [Hugging Face Hub](https://huggingface.co/datasets/wnut_17):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdbb485-4b77-4261-87a2-9ede27e22167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# download data set\n",
    "dataset = load_dataset(\"wnut_17\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620cdc33-69a6-4e35-b40e-b7d8f6dddbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define labels\n",
    "labels = ['corporation', 'creative-work', 'group', 'location', 'person', 'product']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142034f-5328-425f-bc06-81fcb589d132",
   "metadata": {},
   "source": [
    "## 2. Configure Flair TARSTagger\n",
    "\n",
    "Now let's configure our NER model, following [Flair's  documentation](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_10_TRAINING_ZERO_SHOT_MODEL.md#use-case-2-zero-shot-named-entity-recognition-ner-with-tars):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f6107-9512-4c49-9d8b-488d886bfa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TARSTagger\n",
    "\n",
    "# load zero-shot NER tagger\n",
    "tars = TARSTagger.load('tars-ner')\n",
    "\n",
    "# define labels for named entities using wnut labels\n",
    "tars.add_and_switch_to_new_task('task 1', labels, label_type='ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a82c2-bf74-4eed-8b85-32d6e08e3dda",
   "metadata": {},
   "source": [
    "Let's test it with one example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26122f5-a3a6-46ee-b85f-bdb4ec0c8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "# wrap our tokens in a flair Sentence\n",
    "sentence = Sentence(\" \".join(dataset[0]['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d6d4d-b8f9-4f24-8e12-0b54de81aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predictions to our sentence\n",
    "tars.predict(sentence)\n",
    "\n",
    "# extract predicted entities into a list of tuples (entity, start_char, end_char)\n",
    "[\n",
    "    (entity.get_labels()[0].value, entity.start_position, entity.end_position)\n",
    "    for entity in sentence.get_spans(\"ner\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63316fe3-00a4-413d-80d0-93d51acb7a2b",
   "metadata": {},
   "source": [
    "## 3. Predict over `wnut_17` and log into `argilla`\n",
    "\n",
    "Now, let's log the predictions in Argilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec1235d-afd0-4b91-8de3-3dc3fc6b5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "\n",
    "# build records for the first 100 examples\n",
    "records = []\n",
    "for record in dataset.select(range(100)):\n",
    "    input_text = \" \".join(record[\"tokens\"])\n",
    "    \n",
    "    sentence = Sentence(input_text)\n",
    "    tars.predict(sentence)\n",
    "    prediction = [\n",
    "        (entity.get_labels()[0].value, entity.start_position, entity.end_position)\n",
    "        for entity in sentence.get_spans(\"ner\")\n",
    "    ]\n",
    "    \n",
    "    # building TokenClassificationRecord\n",
    "    records.append(\n",
    "        rg.TokenClassificationRecord(\n",
    "            text=input_text,\n",
    "            tokens=[token.text for token in sentence],\n",
    "            prediction=prediction,\n",
    "            prediction_agent=\"tars-ner\",\n",
    "        )\n",
    "    )\n",
    "    \n",
    "# log the records to Argilla\n",
    "rg.log(records, name='tars_ner_wnut_17', metadata={\"split\": \"test\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140e801",
   "metadata": {},
   "source": [
    "Now you can see the results obtained! With the annotation mode, you can change, add, validate or discard your results. Statistics are also available, to better monitor your records!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa28c2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Getting predictions with a zero-shot approach can be very helpful to guide humans in their annotation process.\n",
    "Especially for NER tasks, Argilla makes it very easy to explore and correct those predictions thanks to its **Annotation Mode** üòé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93856ebf",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "‚≠ê Star Argilla [Github repo](https://github.com/argilla/argilla) to stay updated.\n",
    "\n",
    "üìö [Argilla documentation](https://docs.argilla.io) for more guides and tutorials.\n",
    "\n",
    "üôã‚Äç‚ôÄÔ∏è Join the Argilla community! A good place to start is the [discussion forum](https://github.com/argilla/argilla/discussions)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "03f665a1a0825a92bc240e01069a3e92c7de5b4cc92abab3eda948bbc50d6f03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
