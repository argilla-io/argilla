{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44dca393-21cf-420c-a96c-3d08e2c17bea",
   "metadata": {},
   "source": [
    "# üî´ Evaluate a zero-shot NER with Flair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f188f15e-7922-4aee-b4a3-ff003d49dc86",
   "metadata": {},
   "source": [
    "In this tutorial, you will learn how to analyze and validate NER predictions from the new zero-shot model provided by the Flair NLP library with Argilla.\n",
    "\n",
    "- üõ† Useful for quickly bootstrapping a training set (using Argilla [*Annotation Mode*](../../reference/webapp/features.html#annotate)) as well as integrating with weak-supervision workflows.\n",
    "- üëÅ We will use a challenging, exciting dataset: wnut_17 (more info below).\n",
    "- üîÆ You will be able to see and work with the obtained predictions.\n",
    "\n",
    "![labelling-tokenclassification-flair-fewshot](../../_static/tutorials/labelling-tokenclassification-flair-fewshot/labelling-tokenclassification-flair-fewshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f6344",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial will show you how to work with Named Entity Recognition (NER), Flair and Argilla. But, what is NER?\n",
    "\n",
    "According to [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/06/part-10-step-by-step-guide-to-master-nlp-named-entity-recognition/), \n",
    "\"NER is a **natural language processing technique** that can automatically scan entire articles and pull out some fundamental entities in a text and classify them into predefined categories\". These entities can be names, quantities, dates and times, amounts of money/currencies, and much more. \n",
    "\n",
    "On the other hand, [Flair](https://github.com/flairNLP/flair) is a library which facilitates the application of NLP models to NER and other NLP techniques in many different languages. It is not only a powerful library, but also intuitive. \n",
    "\n",
    "Thanks to these resources and the [*Annotation Mode*](../../reference/webapp/features.html#annotate) of *Argilla*, we can quickly build up a data set to train a domain-specific model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa2748a9",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces**: If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](../../getting_started/quickstart.ipynb). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "    \n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter Notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b710019-983d-43a4-84f6-7f8210b8cb48",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this tutorial, you'll need to install the Argilla client and a few third party libraries using `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02acf9ed-ec17-49eb-aa1b-6ddf584ab348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"argilla\" \"datasets~=2.6.0\" \"flair~=0.11.0\" -qqq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fabdd145",
   "metadata": {},
   "source": [
    "Let's import the Argilla module for reading and writing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac811da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "556046ed",
   "metadata": {
    "id": "7TRNourOwigS"
   },
   "source": [
    "If you are running Argilla using the Docker quickstart image or Hugging Face Spaces, you need to init the Argilla client with the `URL` and `API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "# Replace workspace with the name of your workspace\n",
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\", \n",
    "    api_key=\"owner.apikey\",\n",
    "    workspace=\"admin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running a private Hugging Face Space, you will also need to set the [HF_TOKEN](https://huggingface.co/settings/tokens) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the HF_TOKEN environment variable\n",
    "# import os\n",
    "# os.environ['HF_TOKEN'] = \"your-hf-token\"\n",
    "\n",
    "# # Replace api_url with the url to your HF Spaces URL\n",
    "# # Replace api_key if you configured a custom API key\n",
    "# # Replace workspace with the name of your workspace\n",
    "# rg.init(\n",
    "#     api_url=\"https://[your-owner-name]-[your_space_name].hf.space\", \n",
    "#     api_key=\"admin.apikey\",\n",
    "#     workspace=\"admin\",\n",
    "#     extra_headers={\"Authorization\": f\"Bearer {os.environ['HF_TOKEN']}\"},\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5be64d5e",
   "metadata": {
    "id": "ccL8UFwj_CaD"
   },
   "source": [
    "Finally, let's include the imports we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5614f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from flair.models import TARSTagger\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Telemetry\n",
    "\n",
    "We gain valuable insights from how you interact with our tutorials. To improve ourselves in offering you the most suitable content, using the following lines of code will help us understand that this tutorial is serving you effectively. Though this is entirely anonymous, you can choose to skip this step if you prefer. For more info, please check out the [Telemetry](../../reference/telemetry.md) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from argilla.utils.telemetry import tutorial_running\n",
    "    tutorial_running()\n",
    "except ImportError:\n",
    "    print(\"Telemetry is introduced in Argilla 1.20.0 and not found in the current installation. Skipping telemetry.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc0dc5c-b925-4b77-85ac-1fab6f8c0994",
   "metadata": {},
   "source": [
    "## 1. Load the `wnut_17` dataset\n",
    "\n",
    "In this example, we'll use a challenging NER dataset, the **\"WNUT 17: Emerging and Rare entity recognition\"** , which focuses on unusual, previously unseen entities in the context of emerging discussions. This dataset is useful for getting a sense of the quality of our zero-shot predictions.\n",
    "\n",
    "Let's load the test set from the [Hugging Face Hub](https://huggingface.co/datasets/wnut_17):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdbb485-4b77-4261-87a2-9ede27e22167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data set\n",
    "dataset = load_dataset(\"wnut_17\", split=\"test\")\n",
    "\n",
    "# Define labels\n",
    "labels = [\"corporation\", \"creative-work\", \"group\", \"location\", \"person\", \"product\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142034f-5328-425f-bc06-81fcb589d132",
   "metadata": {},
   "source": [
    "## 2. Configure Flair TARSTagger\n",
    "\n",
    "Now let's configure our NER model, following [Flair's  documentation](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_10_TRAINING_ZERO_SHOT_MODEL.md#use-case-2-zero-shot-named-entity-recognition-ner-with-tars):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f6107-9512-4c49-9d8b-488d886bfa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load zero-shot NER tagger\n",
    "tars = TARSTagger.load(\"tars-ner\")\n",
    "\n",
    "# Define labels for named entities using wnut labels\n",
    "tars.add_and_switch_to_new_task(\"task 1\", labels, label_type=\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a82c2-bf74-4eed-8b85-32d6e08e3dda",
   "metadata": {},
   "source": [
    "Let's test it with one example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26122f5-a3a6-46ee-b85f-bdb4ec0c8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wrap our tokens in a flair Sentence\n",
    "sentence = Sentence(\" \".join(dataset[0][\"tokens\"]))\n",
    "\n",
    "# Add predictions to our sentence\n",
    "tars.predict(sentence)\n",
    "\n",
    "# Extract predicted entities into a list of tuples (entity, start_char, end_char)\n",
    "[\n",
    "    (entity.get_labels()[0].value, entity.start_position, entity.end_position)\n",
    "    for entity in sentence.get_spans(\"ner\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63316fe3-00a4-413d-80d0-93d51acb7a2b",
   "metadata": {},
   "source": [
    "## 3. Predict over `wnut_17` and log into `argilla`\n",
    "\n",
    "Now, let's log the predictions in Argilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec1235d-afd0-4b91-8de3-3dc3fc6b5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build records for the first 100 examples\n",
    "records = []\n",
    "\n",
    "for record in dataset.select(range(100)):\n",
    "    input_text = \" \".join(record[\"tokens\"])\n",
    "\n",
    "    sentence = Sentence(input_text)\n",
    "    tars.predict(sentence)\n",
    "    prediction = [\n",
    "        (entity.get_labels()[0].value, entity.start_position, entity.end_position)\n",
    "        for entity in sentence.get_spans(\"ner\")\n",
    "    ]\n",
    "\n",
    "    # Building TokenClassificationRecord\n",
    "    records.append(\n",
    "        rg.TokenClassificationRecord(\n",
    "            text=input_text,\n",
    "            tokens=[token.text for token in sentence],\n",
    "            prediction=prediction,\n",
    "            prediction_agent=\"tars-ner\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Log the records to Argilla\n",
    "rg.log(records, name=\"tars_ner_wnut_17\", metadata={\"split\": \"test\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140e801",
   "metadata": {},
   "source": [
    "Now you can see the results obtained! With the annotation mode, you can change, add, validate or discard your results. Statistics are also available, to better monitor your records!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99aa28c2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Getting predictions with a zero-shot approach can be very helpful in guiding humans in their annotation process.\n",
    "Especially for NER tasks, Argilla makes it very easy to explore and correct those predictions thanks to its **Hand-labeling Mode** üòé."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1 (default, Dec 17 2020, 03:56:09) \n[Clang 11.0.0 (clang-1100.0.33.17)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "8874e298d2bce9702a08b32d5709c9f02d53b2045f1d246836c6e4c8123e6782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
