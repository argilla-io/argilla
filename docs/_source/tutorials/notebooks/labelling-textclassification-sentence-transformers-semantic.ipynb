{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö§ Speed-up data labelling with Sentence Transformer embeddings\n",
    "\n",
    "In this tutorial, you'll learn to use Sentence Transformer embeddings and similarity search to make data labelling significantly faster. It will walk you through the following steps:\n",
    "\n",
    "\n",
    "- üíæ use sentence transformers to generate embeddings of a banking customer requests\n",
    "- üôÉ upload the dataset into Argilla for data labelling\n",
    "- üè∑ use the similarity search feature to efficiently find an label bulks of semantically-related examples\n",
    "\n",
    "<img src=\"../../_static/tutorials/labelling-textclassification-sentence-transformers-semantic/4.png\" alt=\"Similarity search\" style=\"width: 1100px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, we'll use the power of embeddings to make data labelling (and curation) more efficient. The idea of exploiting embeddings for labelling is not new, and there are several cool, standalone libraries to label data using embeddings.\n",
    "\n",
    "Since `1.2.0`, Argilla gives you a way to leverage embedding-based similarity together with all other workflows already provided: search-based bulk labelling, programmatic labelling using search queries, model pre-annotation, and human-in-the-loop workflows. This also means you can combine keyword search and filters with this new similarity search feature. All these without any vendor or model lock-in, you can use ANY embedding or encoding method, including but not limited to `Sentence Transformers`, `OpenAI`, or `Co:here`. \n",
    "\n",
    "If you want a deep-dive you can check the [Semantic similarity deep-dive](../../guides/features/semantic-search.ipynb), but this tutorial will show you the basics to get started. \n",
    "\n",
    "Let's do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First you need to install and run Argilla, and make sure you're running the right version of [Elasticsearch or Opensearch](../../guides/features/semantic-search.ipynb). The, you'll need a few third-party libraries that can be installed via `pip`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%pip install datasets==2.8.0 sentence-transformers==2.2.2  -qqq  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Downloading and embedding your dataset\n",
    "\n",
    "The code below will load the banking customer requests dataset from the Hub, encode the `text` field, and create the `vectors` field which will contain only one key (`mini-lm-sentence-transformers`). For the purposes of labelling the dataset from scratch, it will also remove the `label` field, which contains original intent labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Define fast version of sentence transformers\n",
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "\n",
    "# Load dataset with banking\n",
    "dataset = load_dataset(\"banking77\", split=\"test\")\n",
    "\n",
    "# Encode text field using batched computation\n",
    "dataset = dataset.map(lambda batch: {\"vectors\": encoder.encode(batch[\"text\"])}, batch_size=32, batched=True)\n",
    "\n",
    "\n",
    "# Moves the label to a metadata field, because you'll be labelling the dataset yourself\n",
    "dataset = dataset.remove_columns(\"label\")\n",
    "\n",
    "# Turn vectors into a dictionary\n",
    "dataset = dataset.map(\n",
    "    lambda r: {\"vectors\": {\"mini-lm-sentence-transformers\": r[\"vectors\"]}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset now contains a `vectors` field with the embedding vector generated by the sentence transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I locate my card?</td>\n",
       "      <td>{'mini-lm-sentence-transformers': [-0.01016708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I still have not received my new card, I order...</td>\n",
       "      <td>{'mini-lm-sentence-transformers': [-0.04284123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ordered a card but it has not arrived. Help ...</td>\n",
       "      <td>{'mini-lm-sentence-transformers': [-0.03365558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is there a way to know when my card will arrive?</td>\n",
       "      <td>{'mini-lm-sentence-transformers': [0.012195908...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My card has not arrived yet.</td>\n",
       "      <td>{'mini-lm-sentence-transformers': [-0.04361863...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                           How do I locate my card?   \n",
       "1  I still have not received my new card, I order...   \n",
       "2  I ordered a card but it has not arrived. Help ...   \n",
       "3   Is there a way to know when my card will arrive?   \n",
       "4                       My card has not arrived yet.   \n",
       "\n",
       "                                             vectors  \n",
       "0  {'mini-lm-sentence-transformers': [-0.01016708...  \n",
       "1  {'mini-lm-sentence-transformers': [-0.04284123...  \n",
       "2  {'mini-lm-sentence-transformers': [-0.03365558...  \n",
       "3  {'mini-lm-sentence-transformers': [0.012195908...  \n",
       "4  {'mini-lm-sentence-transformers': [-0.04361863...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üôÉ Upload dataset into Argilla\n",
    "\n",
    "The original `banking77` dataset is a intent classification dataset with dozens of labels (`lost_card`, `card_arrival`, etc.). To keep this tutorial simple, we define a simplified labelling scheme with higher level classes: `[\"change_details\", \"card\", \"atm\", \"top_up\", \"balance\", \"transfer\", \"exchange_rate\", \"pin\"]`.\n",
    "\n",
    "Let's define the dataset settings, configure the dataset, and upload our dataset with vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "\n",
    "rg_ds = rg.DatasetForTextClassification.from_datasets(dataset)\n",
    "\n",
    "# Setting for the label scheme\n",
    "settings = rg.TextClassificationSettings(label_schema=[\"change_details\", \"card\", \"atm\", \"top_up\", \"balance\", \"transfer\", \"exchange_rate\", \"pin\"])\n",
    "\n",
    "rg.configure_dataset(name=\"banking77-topics\", settings=settings)\n",
    "\n",
    "rg.log(\n",
    "    name=\"banking77-topics\",\n",
    "    records=rg_ds,\n",
    "    chunk_size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑ Bulk labelling with the `find similar` action\n",
    "\n",
    "Now that our `banking77-topics` is available from the Argilla UI. We can start annotating our data leveraging semantic similarity search. The workflow is following:\n",
    "\n",
    "1. Label a record (e.g., \"Change my information\" with the label `change_details`) and then click on Find similar on the top-right of your record.\n",
    "2. As a result, you'll get to a list of the most similar record sorted by similarity (on descending order).\n",
    "3. You can now review the records and assign either the `change_details` label or any other. For our use case, we see that most of the suggested records fall into the same category.\n",
    "\n",
    "\n",
    "Let's see it step-by-step:\n",
    "\n",
    "### Label a record\n",
    "Using the hand-labelling mode, you can label a record like the one below:\n",
    "\n",
    "![labelling-textclassification-sentence-transformers-semantic](../../_static/tutorials/labelling-textclassification-sentence-transformers-semantic/6.png)\n",
    "\n",
    "Now if you want to find semantically similar or even duplicates of this record you can use the Find similar button. \n",
    "\n",
    "### Find similar\n",
    "\n",
    "As a result you'll get a list the 50 most similar records. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "    \n",
    "Remember that you can combine this similarity search with the other search features: keywords, the query string DSL, and filters. If you have filters enabled for example, the find similar action will return the most similar records from the subset of records with the filter enabled.\n",
    "    \n",
    "</div>\n",
    "\n",
    "![labelling-textclassification-sentence-transformers-semantic](../../_static/tutorials/labelling-textclassification-sentence-transformers-semantic/4.png)\n",
    "\n",
    "As you can see the model is effectively capturing similar meaning without the need of explicit shared words: e.g., `details` vs `information`.\n",
    "\n",
    "### Review records\n",
    "At this point, you can label the records one by one or scroll-down to review them before using the bulk-labelling button on the top of the records list.\n",
    "\n",
    "\n",
    "![labelling-textclassification-sentence-transformers-semantic](../../_static/tutorials/labelling-textclassification-sentence-transformers-semantic/3.png)\n",
    "\n",
    "### Bulk label\n",
    "\n",
    "For this tutorial, our labels are sufficiently well-separated for the embeddings to group records that fall under the same topic. So in this case, it is safe to use the bulk labelling feature directly, effectively labelling 50 semantically-similar examples after a quick revision.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Warning\n",
    "\n",
    "For other use cases, you might need to be more careful and combine this feature with search queries and filters. For quick experimentation, you can also assume you'll make some labelling errors and then use tools like `cleanlab` for detecting label errors.\n",
    "</div>\n",
    "\n",
    "![labelling-textclassification-sentence-transformers-semantic](../../_static/tutorials/labelling-textclassification-sentence-transformers-semantic/2.png)\n",
    "\n",
    "![labelling-textclassification-sentence-transformers-semantic](../../_static/tutorials/labelling-textclassification-sentence-transformers-semantic/1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned to use similarity search for data labelling with Argilla by using Sentence Transformers to embed your raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "If you want to continue learning Argilla:\n",
    "\n",
    "üôã‚Äç‚ôÄÔ∏è Join the [Argilla Slack community](https://join.slack.com/t/rubrixworkspace/shared_invite/zt-whigkyjn-a3IUJLD7gDbTZ0rKlvcJ5g)!\n",
    "\n",
    "‚≠ê Argilla [Github repo](https://github.com/argilla-io/argilla) to stay updated.\n",
    "\n",
    "üìö [Argilla documentation](https://docs.argilla.io) for more guides and tutorials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c6ac5964d63158aef0c318a650c56c288100fe36867cf6a65be3eefaa97102a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
