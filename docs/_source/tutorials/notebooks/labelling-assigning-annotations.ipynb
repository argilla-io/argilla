{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚úçÔ∏è Assign records to your annotation team\n",
    "\n",
    "\n",
    "In this tutorial, you will learn how to assign records to specific users so that you can avoid or control the overlap in annotations. It will walk you through the following steps:\n",
    "\n",
    "- üì• Loading a dataset \n",
    "- üîÄ Make a random assignment \n",
    "- üíæ Log your dataset and assignments in Argilla \n",
    "- ‚úçÔ∏è Annotate records assigned to you"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Annotations are often done by teams that share the workload. When this is the case, we want to avoid annotation overlap for efficiency or to control when and how this overlap happens. To do this we have two options: \n",
    "1. we can keep a single dataset and assign a set of records to each user.\n",
    "2. we can split our dataset into different datasets, one for the records assigned to each user, and log it in their own workspace. \n",
    "\n",
    "You may want to use option 1 if you want to keep the whole dataset available to see and explore for every team member but still you want them to focus on a set of records when they annotate. This can be interesting if your annotators will also make weak labelling rules based on the annotations of the whole team.\n",
    "\n",
    "Option 2 is better if you want each team member to work independently and not see the records that other teammates are working on. This can be interesting if you want to measure annotator agreement afterwards.\n",
    "\n",
    "In this tutorial, we will make a random assignment where each record is annotated by person only and walk you through sharing your assignments with your team using each option. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces**: If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](../../getting_started/quickstart.ipynb). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "    \n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this tutorial, you'll need to install the Argilla client and a few third party libraries using `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install argilla==1.6.0 datasets==2.10.1 httpx==0.23.3 -qqq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the Argilla module for reading and writing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running Argilla using the Docker quickstart image or Hugging Face Spaces, you need to init the Argilla client with the `URL` and `API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "\n",
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\", \n",
    "    api_key=\"admin.apikey\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Loading a dataset\n",
    "\n",
    "We can work with a dataset that already exists in Argilla or load a completely new dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an existing Argilla dataset\n",
    "\n",
    "We can load a whole dataset that was already logged in our Argilla instance or a selection of records in a dataset defined by a query. In this case, we have included a query so that we only load the records that haven't been annotated yet.\n",
    "Learn more about queries [here](../../guides/query_datasets.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load records with the \"Default\" status from a dataset\n",
    "ds = rg.load(\"gutenberg_spacy-ner\", query=\"status:Default\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new dataset\n",
    "If you're working with a new dataset, then you'll need to create a new Argilla dataset object. Here, we have loaded the same dataset from the Huggingface hub. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = rg.DatasetForTokenClassification.from_datasets(\n",
    "    dataset=load_dataset('argilla/gutenberg_spacy-ner', split='train')\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about loading and creating Argilla datasets [here](../../guides/log_load_and_prepare_data.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÄ Make a random assignment\n",
    "\n",
    "As a first step, we want to get the list of the users that will be annotating our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "rg_client= rg.active_client().client\n",
    "auth_headers = {\"X-Argilla-API-Key\": rg_client.token}\n",
    "http=httpx.Client(base_url=rg_client.base_url, headers=auth_headers)\n",
    "\n",
    "# make a request using our Argilla Client\n",
    "users = http.get(\"/api/users\").json()\n",
    "\n",
    "# optional: filter users to get only those with annotator role\n",
    "users = [u for u in users if u['role']=='annotator']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will shuffle our dataset so that the assignment is random, but this step is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this cell if you don't want to shuffle the dataset\n",
    "import random\n",
    "\n",
    "random.shuffle(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start making the assignments. To do this, we will divide our dataset in chunks of the same length as the available annotators and save the assignment of each record in the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide your dataset in chunks of the same length as the users list and make the assignments\n",
    "n = len(users)\n",
    "chunked_records = [ds[i:i + n] for i in range(0, len(ds), n)]\n",
    "for chunk in chunked_records:\n",
    "    for idx, rec in enumerate(chunk):\n",
    "        rec.metadata[\"user\"] = users[idx]['username']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Log your dataset and assignments in Argilla "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1\n",
    "If you want to follow option 1, where we have 1 dataset accessible to all teammates, we just need to log this dataset as it is.\n",
    "\n",
    "Make sure that you log this dataset in a workspace that all the users that will work on this dataset have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log the dataset in Argilla\n",
    "rg.log(\n",
    "    records=ds,\n",
    "    workspace='recognai',\n",
    "    name='gutenberg_spacy-ner',\n",
    "    tags={'with assignments': True}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2\n",
    "If you're following option 2, where annotators only have access to the records assigned to them, we will divide our dataset into several ones and log them in the individual workspaces of our annotators. \n",
    "\n",
    "For this to work, users that are going to annotate should have the `annotator` role so that they cannot access each other's workspaces. Whoever is supervising the project should have an `admin` role so they can see all workspaces and datasets tied to this project.\n",
    "\n",
    "Learn more about managing user roles and access [here](../../getting_started/installation/configurations/user_management.md).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# loop through the dataset and build a dictionary where the key is the username and the value is the list of records assigned to them\n",
    "assignments = defaultdict(list)\n",
    "\n",
    "for record in ds:\n",
    "    user = record.metadata['user']\n",
    "    assignments[user].append(record)\n",
    "\n",
    "# loop through the dictionary and log the dataset for each user\n",
    "for user, records in assignments.items():\n",
    "    rg.log(\n",
    "        records=records,\n",
    "        workspace=user,\n",
    "        name='gutenberg_spacy-ner'\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plan to have more than one user annotating the same record, we recommend adding an ID to each record before splitting them into several datasets. That way you will be able to retrieve the different annotations for each record when postprocessing the datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úçÔ∏è Annotate records assigned to you\n",
    "\n",
    "Now it's time to open the Argilla UI and start annotating!\n",
    "\n",
    "If you followed option 1, you want to ask your annotators to open the dataset in the UI and select their username under `Metadata`>`user`. This will filter the records assigned to them automatically.\n",
    "\n",
    "<img src=\"../../_static/tutorials/labelling-assigning-annotations/labelling-assinging-annotations-screenshot.png\" alt=\"Using the metadata filter to select annotations assigned to a specific person\" style=\"width: 1100px;\">\n",
    "\n",
    "If you followed option 2, just ask your annotators to open the dataset in their workspace and start annotating it.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned how to split a dataset into random chunks so you can assign records to each member of your annotation team in two ways. In the first way, we kept a single dataset so that our team can choose whether to see the whole dataset or focus on the records assigned to them. In the second way, each annotator has a dataset with the records assigned to them and they cannot access the records of other teammates.\n",
    "\n",
    "This allows you to manage your annotation team and help them work more efficiently. üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
