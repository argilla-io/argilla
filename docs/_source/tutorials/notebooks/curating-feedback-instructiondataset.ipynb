{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curate an instruction dataset for supervised fine-tuning\n",
    "\n",
    "\n",
    "In this tutorial, we will show you how you can curate a public instruction dataset, like [Databricks' Dolly](https://huggingface.co/datasets/databricks/databricks-dolly-15k), to use it for fine-tuning an LLM to solve instruction tasks. It will walk you through the following steps:\n",
    "\n",
    "- Define the project \n",
    "- Split the workload and import to Argilla\n",
    "- Collect feedback and publish the results\n",
    "- Fine-tune a model\n",
    "\n",
    "INSERT_IMAGE\n",
    "<!-- <img src=\"../../_static/tutorials/deploying-texttokenclassification-fastapi/deploying-texttokenclassification-fastapi.png\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\"> -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The internet is flooding with open-source datasets for fine-tuning LLMs, some created by humans, others generated with generative models. However, these datasets often have many problematic and low-quality examples. By curating them, we can make the fine-tuning step more efficient.\n",
    "\n",
    "In this tutorial, we take the Dolly dataset as an example to show how you can build an instruction dataset for your fine-tuning projects by cleaning a generated dataset using Argilla's Feedback Task.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "1. [Deploy Argilla on Hugging Face Spaces](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla): This is the fastest option and the recommended choice for connecting to external notebooks (e.g., Google Colab) if you have an account on Hugging Face.\n",
    "\n",
    "2. [Launch Argilla using Argilla's quickstart Docker image](../../getting_started/quickstart.ipynb): This is the recommended option if you want Argilla running on your local machine. Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "    \n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter notebook tool of your choice.\n",
    "</div>\n",
    "\n",
    "## Setup\n",
    "\n",
    "For this tutorial, you'll need to install the Argilla client and a few third party libraries using `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'argilla' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n argilla ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%pip install argilla datasets pandas httpx -qqq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the Argilla module for reading and writing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running Argilla using the Docker quickstart image or Hugging Face Spaces, you need to init the Argilla client with the `URL` and `API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\", \n",
    "    api_key=\"admin.apikey\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's include the imports we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalia/opt/anaconda3/envs/argilla/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the project \n",
    "As a first step, let's load the dataset and quickly explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/natalia/.cache/huggingface/datasets/databricks___json/databricks--databricks-dolly-15k-6e0f9ea7eaa0ee08/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'context', 'response', 'category'],\n",
       "    num_rows: 15011\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset('databricks/databricks-dolly-15k', split='train')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Virgin Australia start operating?</td>\n",
       "      <td>Virgin Australia, the trading name of Virgin A...</td>\n",
       "      <td>Virgin Australia commenced services on 31 Augu...</td>\n",
       "      <td>closed_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which is a species of fish? Tope or Rope</td>\n",
       "      <td></td>\n",
       "      <td>Tope</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why can camels survive for long without water?</td>\n",
       "      <td></td>\n",
       "      <td>Camels use the fat in their humps to keep them...</td>\n",
       "      <td>open_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice's parents have three daughters: Amy, Jes...</td>\n",
       "      <td></td>\n",
       "      <td>The name of the third daughter is Alice</td>\n",
       "      <td>open_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When was Tomoaki Komorida born?</td>\n",
       "      <td>Komorida was born in Kumamoto Prefecture on Ju...</td>\n",
       "      <td>Tomoaki Komorida was born on July 10,1981.</td>\n",
       "      <td>closed_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15006</th>\n",
       "      <td>How do i accept the change</td>\n",
       "      <td></td>\n",
       "      <td>Embrace the change and see the difference</td>\n",
       "      <td>brainstorming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15007</th>\n",
       "      <td>What is a laser and who created it?</td>\n",
       "      <td>A laser is a device that emits light through a...</td>\n",
       "      <td>A laser is a device that emits light from an e...</td>\n",
       "      <td>summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15008</th>\n",
       "      <td>What is the difference between a road bike and...</td>\n",
       "      <td></td>\n",
       "      <td>Road bikes are built to be ridden on asphalt a...</td>\n",
       "      <td>open_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15009</th>\n",
       "      <td>How does GIS help in the real estate investmen...</td>\n",
       "      <td></td>\n",
       "      <td>Real estate investors depend on precise, accur...</td>\n",
       "      <td>general_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15010</th>\n",
       "      <td>What is the Masters?</td>\n",
       "      <td></td>\n",
       "      <td>The Masters Tournament is a golf tournament he...</td>\n",
       "      <td>general_qa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15011 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             instruction  \\\n",
       "0             When did Virgin Australia start operating?   \n",
       "1               Which is a species of fish? Tope or Rope   \n",
       "2         Why can camels survive for long without water?   \n",
       "3      Alice's parents have three daughters: Amy, Jes...   \n",
       "4                        When was Tomoaki Komorida born?   \n",
       "...                                                  ...   \n",
       "15006                         How do i accept the change   \n",
       "15007                What is a laser and who created it?   \n",
       "15008  What is the difference between a road bike and...   \n",
       "15009  How does GIS help in the real estate investmen...   \n",
       "15010                               What is the Masters?   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Virgin Australia, the trading name of Virgin A...   \n",
       "1                                                          \n",
       "2                                                          \n",
       "3                                                          \n",
       "4      Komorida was born in Kumamoto Prefecture on Ju...   \n",
       "...                                                  ...   \n",
       "15006                                                      \n",
       "15007  A laser is a device that emits light through a...   \n",
       "15008                                                      \n",
       "15009                                                      \n",
       "15010                                                      \n",
       "\n",
       "                                                response        category  \n",
       "0      Virgin Australia commenced services on 31 Augu...       closed_qa  \n",
       "1                                                   Tope  classification  \n",
       "2      Camels use the fat in their humps to keep them...         open_qa  \n",
       "3                The name of the third daughter is Alice         open_qa  \n",
       "4             Tomoaki Komorida was born on July 10,1981.       closed_qa  \n",
       "...                                                  ...             ...  \n",
       "15006          Embrace the change and see the difference   brainstorming  \n",
       "15007  A laser is a device that emits light from an e...   summarization  \n",
       "15008  Road bikes are built to be ridden on asphalt a...         open_qa  \n",
       "15009  Real estate investors depend on precise, accur...      general_qa  \n",
       "15010  The Masters Tournament is a golf tournament he...      general_qa  \n",
       "\n",
       "[15011 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project, we would like to make sure that the `instruction` and the `response` are formulated clearly and concisely and also using correct language and information. We will add those two fields to our records. To help our annotation team, we will also include the `context` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the data as Argilla records\n",
    "records = [rg.FeedbackRecord(fields={\"instruction\": record[\"instruction\"], \"response\": record[\"response\"], \"context\": record[\"context\"]}) for record in data]\n",
    "\n",
    "# list of fields that we will use later for our dataset settings\n",
    "fields = [\n",
    "    rg.TextField(name=\"instruction\"),\n",
    "    rg.TextField(name=\"response\"),\n",
    "    rg.TextField(name=\"context\")\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can think of the questions that we would like to ask about these records and we will provide some guidelines for the annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of questions to display in the feedback form\n",
    "questions =[\n",
    "    rg.RatingQuestion(\n",
    "        name=\"changes-needed\", \n",
    "        title=\"Does the instruction or response in this record need corrections?\", \n",
    "        description=\"0 = no: choose if everything looks good and you won't provide any corrections\\n1 = yes: choose if you are providing corrections to the instruction or response\",\n",
    "        required=True,\n",
    "        values=[0,1]\n",
    "    ),\n",
    "    rg.TextQuestion(\n",
    "        name=\"new-instruction\",\n",
    "        title=\"Provide a new version of the instruction:\",\n",
    "        required=False\n",
    "    ),\n",
    "    rg.TextQuestion(\n",
    "        name=\"new-response\",\n",
    "        title=\"Provide a new verstion of the response:\",\n",
    "        required=False\n",
    "    )\n",
    "]\n",
    "\n",
    "guidelines = \"In this dataset, you will find a collection of records that show at least an instruction and a response to that instruction. The aim of the project is to correct the instructions and responses to make sure they are of the highest quality. Both texts should be clear and include real information. In addition, the response should be as complete but concise as possible. To help you with the responses, some records have another text field called Context below the response. This field shows the text where the response was taken from.\\n\\nTo curate the dataset, you will need to answer the following questions:\\n\\n1 - Does the instruction or response in this record need corrections?\\nThis question has a binary selection. Choose 0 if everything looks good and you won't provide any corrections. You can submit the response straightaway. Choose 1 if you are going to provide a corrected version of either the instruction or the response.\\n\\n2 - Provide a new version of the instruction:\\nIf the instruction needs corrections, write a new version in this text area. If the instruction is ok, leave it empty.\\n\\n3 - Provide a new version of the response:\\nIf the response needs corrections, write a new version in this text area. If the response is ok, leave it empty.\\n\\nIf you are not sure about a record and you prefer not to provide a response, click Discard.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Split the workload and import to Argilla\n",
    "For this specific project, we don't want any overlap between our annotation team, as we only want one unique version of each record. We'll assume that the annotations of our team have the desired quality to work as demonstration data for our instruction-following model. \n",
    "\n",
    "```{tip}\n",
    "For extra quality assurance, you can make a new dataset where annotators rate the quality of the human annotated dataset.\n",
    "```\n",
    "\n",
    "To avoid having multiple responses for a record, we will split the workload between all of our annotators and import the records assigned to them in a dataset in their personal workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# make a request using your Argilla Client to get the list of users\n",
    "rg_client= rg.active_client().client\n",
    "auth_headers = {\"X-Argilla-API-Key\": rg_client.token}\n",
    "http=httpx.Client(base_url=rg_client.base_url, headers=auth_headers)\n",
    "users = http.get(\"/api/users\").json()\n",
    "\n",
    "# filter users to get only those with annotator role\n",
    "users = [user for user in users if user['role']=='annotator']\n",
    "\n",
    "# shuffle the records to get a random assignment\n",
    "random.shuffle(records)\n",
    "\n",
    "# build a dictionary where the key is the username and the value is the list of records assigned to them\n",
    "assignments = defaultdict(list)\n",
    "\n",
    "# divide your records in chunks of the same length as the users list and make the assignments\n",
    "# you will need to follow the instructions to create and push a dataset for each of the key-value pairs in this dictionary\n",
    "n = len(users)\n",
    "chunked_records = [records[i:i + n] for i in range(0, len(records), n)]\n",
    "for chunk in chunked_records:\n",
    "    for idx, record in enumerate(chunk):\n",
    "        assignments[users[idx]['username']].append(record)\n",
    "\n",
    "# create a dataset for each annotator and push it to their personal workspace\n",
    "for username,records in assignments:\n",
    "    dataset = rg.FeedbackDataset(\n",
    "        guidelines=guidelines,\n",
    "        fields=fields,\n",
    "        questions=questions\n",
    "    )\n",
    "    dataset.add_records(records)\n",
    "    dataset.push_to_argilla(name='dolly_cleaning', workspace=username)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect feedback and publish the results\n",
    "At this point, the dataset are ready to start the annotation. Once this is done, we will collect all the feedback from our annotators and join it in a single dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = []\n",
    "for username in assignments.keys():\n",
    "    feedback.extend(rg.FeedbackDataset.from_argilla('dolly_cleaning', workspace=username))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the dataset a bit so we can draw some conclusions about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# count how many records were modified. How many had modifications in the instruction, how many in the response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could publish the dataset as it is now, but for this example we'll do a little post-processing so that we simplify the fields and substitute the old instruction and response with the new version provided by our annotators. That way we have a dataset that's fully ready for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = []\n",
    "for record in feedback:\n",
    "    # we will skip records where our annotators didn't submit their feedback\n",
    "    if record['responses'][0]['status'] != 'submitted':\n",
    "        continue\n",
    "\n",
    "    response = record['responses'][0]['values']\n",
    "    # if the annotator answered 0 in the first question, we will keep the original text\n",
    "    if ['changes-needed']['value'] == 0:\n",
    "        new_dataset.append(record['fields'])\n",
    "    # if not, we will substitute the instruction and response with the text submitted by the annotator\n",
    "    else:\n",
    "        if 'new-instruction' in response:\n",
    "            record['fields']['instruction'] = response['new-instruction']['value']\n",
    "        if 'new-response' in response:\n",
    "            record['fields']['response'] = response['new-response']['value']\n",
    "        new_dataset.append(record['fields'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_dataset)\n",
    "new_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're happy with the result, we can publish it in the Hugging Face Hub, so the whole open-source community can benefit from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#push to hub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is ready to be used as a demonstration dataset to fine-tune instruction-following models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned how to create an instruction dataset by curating a public dataset with a permissive license, in this case the Dolly dataset made by Databricks employees. This can help us to fine-tune an instruction-following model using high-quality data that will allow a more efficient training with better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d98cb9bf90a932b5bf8e86e91214497eb0e38eb318595fbd6fbd5460fe92036"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
