{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curate an instruction dataset for LLM supervised fine-tuning\n",
    "\n",
    "\n",
    "In this tutorial, we will INSERT_INTRODUCTION. It will walk you through the following steps:\n",
    "\n",
    "- INSERT_STEPS. INSERT EMOJI\n",
    "\n",
    "INSERT_IMAGE\n",
    "<!-- <img src=\"../../_static/tutorials/deploying-texttokenclassification-fastapi/deploying-texttokenclassification-fastapi.png\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\"> -->\n",
    "\n",
    "Intro: importance of cleaning public datasets, especially if these have been generated by other models. In this tutorial, you will learn how to build an instruction dataset for your fine-tuning projects by cleaning the Dolly dataset.\n",
    "\n",
    "Step 1: get Dolly dataset from HF hub. ‘En’ split.\n",
    "\n",
    "Step 2: Configure questions and write some annotation guidelines\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "rating “Does this record need a correction?” 0=no, 1=yes\n",
    "\n",
    "Text field “correct Instruction” \n",
    "\n",
    "text field “correct Input” \n",
    "\n",
    "text field “correct response” \n",
    "\n",
    "Step 3: turn the dataset into Argilla records with the desired format. In this case:\n",
    "\n",
    "Record fields**:**\n",
    "\n",
    "One instruction\n",
    "\n",
    "One input (context)\n",
    "\n",
    "One response\n",
    "\n",
    "Step 4: No overlap → divide the dataset and place in personal workspaces\n",
    "\n",
    "in this case we don’t need overlap. We only want 1 result per record and we’ll assume that the human annotations have the desired quality. This is for demonstration data.\n",
    "\n",
    "Tip: for extra quality assurance, you can make a new dataset where annotators assess the quality of the human annotated dataset.\n",
    "\n",
    "Step 5: Annotate \n",
    "\n",
    "- copy fields that need corrections. Empty field = no corrections needed.\n",
    "\n",
    "Step 6:  Collect annotations \n",
    "\n",
    "Step 7 (optional): Publish the dataset\n",
    "\n",
    "Step 8: fine-tune your model (??)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "INSERT_INTRODUCTION\n",
    "\n",
    "INSERT_POTENTIAL_REFERENCES_TO_OTHER_PART_OF_DOCS\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "1. [Deploy Argilla on Hugging Face Spaces](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla): This is the fastest option and the recommended choice for connecting to external notebooks (e.g., Google Colab) if you have an account on Hugging Face.\n",
    "\n",
    "2. [Launch Argilla using Argilla's quickstart Docker image](../../getting_started/quickstart.ipynb): This is the recommended option if you want Argilla running on your local machine. Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "    \n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter notebook tool of your choice.\n",
    "</div>\n",
    "\n",
    "## Setup\n",
    "\n",
    "For this tutorial, you'll need to install the Argilla client and a few third party libraries using `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'argilla' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n argilla ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%pip install argilla INSERT_PACKAGE==INSERT_VERSION -qqq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the Argilla module for reading and writing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running Argilla using the Docker quickstart image or Hugging Face Spaces, you need to init the Argilla client with the `URL` and `API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\", \n",
    "    api_key=\"admin.apikey\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's include the imports we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bla bla bla with specific version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First section\n",
    "\n",
    "## Second section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned INSERT_SUMMARY.\n",
    "This can INSERT_REASON."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d98cb9bf90a932b5bf8e86e91214497eb0e38eb318595fbd6fbd5460fe92036"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
