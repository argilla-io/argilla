{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîê Backup and version Argilla `Datasets` using `DVC`\n",
    "\n",
    "\n",
    "In this tutorial, we will show you how you can store and version your data using [DVC](https://dvc.org/). Alternatively, you can take a look at our [Elasticsearch docs](../../getting_started/installation/elasticsearch.md) about creating retention snapshots directly from your Elasticsearch cluster. It will walk you through the following steps:\n",
    "\n",
    "- ‚öôÔ∏è configure DVC\n",
    "- üßê determine backup config\n",
    "- üß™ test back-up config\n",
    "\n",
    "<img src=\"../../_static/tutorials/deploying-text2text-dvc-explainability/deploying-text2text-dvc-explainability.gif\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "It is important to be able to keep track and store data to version data used in training cycles and to avoid losing data. DVC creates a reference to your data and stores it within an external storage repo. Pushing this reference to get allows us to reproduce certain stages of your repository, while also having a copy of the exact data that was in the repo during that exact time. Think \"git for data\".\n",
    "\n",
    "Take a look at the [DVC docs](https://dvc.org/doc/start/data-management/data-versioning) to get a bit more familiar with the idea behind this versioning principle.\n",
    "\n",
    "\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces**: If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](../../getting_started/quickstart.ipynb). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "    \n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup packages\n",
    "\n",
    "To complete this tutorial, you will need to install the Argilla client and [DVC](https://dvc.org/doc/install)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install argilla -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!brew install dvc # mac\n",
    "# !snap install --classic dvc # linux\n",
    "# !choco install dvc # windows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the Argilla module for reading and writing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running Argilla using the Docker quickstart image or Hugging Face Spaces, you need to init the Argilla client with the `URL` and `API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\", \n",
    "    api_key=\"admin.apikey\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's include the imports we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from typing import List"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure `.git`\n",
    "\n",
    "We will use GitHub as a way to track our stored files. This requires us to link our directory to a git remote. We assume that the environment already has set-up the correct git [credentials](https://docs.github.com/en/get-started/getting-started-with-git/setting-your-username-in-git) and that it is linked to a `.git` file. This can be tested with `git remote -v`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git remote -v"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure DVC\n",
    "\n",
    "We will first initialize our DVC repo, which will automatically be linked to our git remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m             <\u001b[36mhttps://dvc.org/doc/user-guide/analytics\u001b[39m>              \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: <\u001b[36mhttps://dvc.org/doc\u001b[39m>\n",
      "- Get help and share ideas: <\u001b[36mhttps://dvc.org/chat\u001b[39m>\n",
      "- Star us on GitHub: <\u001b[36mhttps://github.com/iterative/dvc\u001b[39m>\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we assume that DVC will be used in combination with Google Drive as remote storage. Other options are available but configuring Google Drive is the most strraightforward approach. This need to be configured by adding something similar as shown below, where `<your-gdrive-folder-id>` is replaced with the Google Drive folder you would like to use for storage. Alternatively, you can go to their [configuration page](https://dvc.org/doc/user-guide/how-to/setup-google-drive-remote)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc remote add myremote gdrive://<your-gdrive-folder-id>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc remote default myremote"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Additionally, we set autostaging for dvc, which also automatically commits them to git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc config core.autostage true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Background Process\n",
    "\n",
    "After setting up DVC, we can now define function to collect and store data. This will follow the following steps:\n",
    "-   Export data using a naming convention `/data/YY-mm-dd_dataset`\n",
    "    -   (optional) create `/data_descriptions` to add to GitHub\n",
    "-   Add the data to DVC, creating a `.dvc` reference to the `/data/*`\n",
    "-   Commit the `.dvc` reference to GitHub\n",
    "-   push the `/data/*` to DVC and push the `.dvc` to GitHub\n",
    "\n",
    "This kind of versioning allows us to explore data in GitHub by using `git checkout` first (to switch a branch or checkout a .dvc file version) and then run `dvc checkout` to sync data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Unstaged files detected.\n",
      "[INFO] Stashing unstaged files to /Users/davidberenstein/.cache/pre-commit/patch1673435632-44248.\n",
      "check yaml...........................................(no files to check)Skipped\n",
      "fix end of files.....................................(no files to check)Skipped\n",
      "trim trailing whitespace.................................................Passed\n",
      "Insert license header in Python source files.........(no files to check)Skipped\n",
      "black................................................(no files to check)Skipped\n",
      "isort................................................(no files to check)Skipped\n",
      "[INFO] Restored changes from /Users/davidberenstein/.cache/pre-commit/patch1673435632-44248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[docs/tutorial-on-dvc-usage c86cb402] update DVC files\n",
      " 4 files changed, 10 insertions(+)\n",
      " create mode 100644 docs/_source/tutorials/notebooks/.dvc/.gitignore\n",
      " create mode 100644 docs/_source/tutorials/notebooks/.dvc/config\n",
      " create mode 100644 docs/_source/tutorials/notebooks/.dvcignore\n",
      " create mode 100644 docs/_source/tutorials/notebooks/data/zingg.pkl.dvc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/argilla-io/argilla.git\n",
      "   2ea0912d..c86cb402  docs/tutorial-on-dvc-usage -> docs/tutorial-on-dvc-usage\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dataset_backupper(datasets: List[str], duration: int=60*60*24):    \n",
    "    while True:\n",
    "        # load datasets and save as .pkl files\n",
    "        for dataset_name in datasets:   \n",
    "            ds = rg.load(dataset_name)\n",
    "            df = ds.to_pandas()\n",
    "            df.to_pickle(f\"data/{dataset_name}.pkl\")\n",
    "\n",
    "        # get all .pkl files using glob\n",
    "        files = glob.glob('data/*.pkl', recursive=True)\n",
    "        [os.system(f'dvc add {file}') for file in files]\n",
    "        \n",
    "        # push all .pkl.dvc files to github via git push\n",
    "        os.system(\"dvc push\")\n",
    "        os.system(\"git commit -m 'update DVC files'\")\n",
    "        os.system(\"git push\")\n",
    "        \n",
    "        time.sleep(duration)\n",
    "        \n",
    "dataset_backupper([\"argilla-dvc\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a toy example but it is highly configurable depending on your needs. \n",
    "Think about, \n",
    "- only backing up records that are more than X days old\n",
    "- deleting records after backing them up\n",
    "- separating backups per time period \n",
    "- add [model versioning](https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial) into the mix\n",
    "\n",
    "Be creative and have some fun while doing it ü§ì"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data versions\n",
    "\n",
    "Next, we can explore data based on our git commit hashes. `git checkout <commit>` opens a previous commit, along with the corresponding `*.dvc` references. Next, we can use `dvc pull` to `fetch` and `checkout` the data files, that were present during the specific `<commit>`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned a bit about [DVC](https://dvc.org/) and how this cool package might be used to back-up and version data within the Argilla ecosystem.\n",
    "This can help to preserve data and keep a clean overview of your data and model history."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Nov 24 2022, 21:36:36) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "39f4e3bd8ecb53b4a2ef9bccb982583dac0632e40e094b10b94294b76eaa26cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
