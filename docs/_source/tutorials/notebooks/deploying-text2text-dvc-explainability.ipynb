{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîê Backup and version Argilla `Datasets` using `DVC`\n",
    "\n",
    "\n",
    "In this tutorial, we will show you how you can store and version your data using [DVC](https://dvc.org/). Alternatively, you can take a look at our [Elasticsearch docs](../../getting_started/installation/elasticsearch.md) about creating retention snapshots directly from your Elasticsearch cluster. It will walk you through the following steps:\n",
    "\n",
    "- ‚öôÔ∏è configure DVC\n",
    "- üßê determine backup config\n",
    "- üß™ test back-up config\n",
    "\n",
    "<img src=\"../../_static/tutorials/deploying-text2text-dvc-explainability/deploying-text2text-dvc-explainability.gif\" alt=\"Transformers Log Demo\" style=\"width: 1100px;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "It is important to be able to keep track and store data to version data used in training cycles and to avoid losing data. DVC creates a reference to your data and stores it within an external storage repo. Pushing this reference to get allows us to reproduce certain stages of your repository, while also having a copy of the exact data that was in the repo during that exact time. Think \"git for data\".\n",
    "\n",
    "Take a look at the [DVC docs](https://dvc.org/doc/start/data-management/data-versioning) to get a bit more familiar with the idea behind this versioning principle.\n",
    "\n",
    "\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "1. [Deploy Argilla on Hugging Face Spaces](../../getting_started/installation/deployments/huggingface-spaces.html): This is the fastest option and the recommended choice for connecting to external notebooks (e.g., Google Colab) if you have an account on Hugging Face.\n",
    "\n",
    "2. [Launch Argilla using Argilla's quickstart Docker image](../../getting_started/quickstart.ipynb): This is the recommended option if you want Argilla running on your local machine. Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "    \n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup packages\n",
    "\n",
    "To complete this tutorial, you will need to install the Argilla client and [DVC](https://dvc.org/doc/install)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install argilla -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!brew install dvc # mac\n",
    "# !snap install --classic dvc # linux\n",
    "# !choco install dvc # windows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure `.git`\n",
    "\n",
    "We will use GitHub as a way to track our stored files. This requires us to link our directory to a git remote. We assume that the environment already has set-up the correct git [credentials](https://docs.github.com/en/get-started/getting-started-with-git/setting-your-username-in-git) and that it is linked to a `.git` file. This can be tested with `git remote -v`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\thttps://github.com/argilla-io/argilla.git (fetch)\n",
      "origin\thttps://github.com/argilla-io/argilla.git (push)\n"
     ]
    }
   ],
   "source": [
    "!git remote -v"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure DVC\n",
    "\n",
    "We will first initialize our DVC repo, which will automatically be linked to our git remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m             <\u001b[36mhttps://dvc.org/doc/user-guide/analytics\u001b[39m>              \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: <\u001b[36mhttps://dvc.org/doc\u001b[39m>\n",
      "- Get help and share ideas: <\u001b[36mhttps://dvc.org/chat\u001b[39m>\n",
      "- Star us on GitHub: <\u001b[36mhttps://github.com/iterative/dvc\u001b[39m>\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we assume that DVC will be used in combination with Google Drive as remote storage. Other options are available but configuring Google Drive is the most strraightforward approach. This need to be configured by adding something similar as shown below, where `<your-gdrive-folder-id>` is replaced with the Google Drive folder you would like to use for storage. Alternatively, you can go to their [configuration page](https://dvc.org/doc/user-guide/how-to/setup-google-drive-remote)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc remote add myremote gdrive://<your-gdrive-folder-id>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc remote default myremote"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Additionally, we set autostaging for dvc, which also automatically commits them to git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc config core.autostage true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Background Process\n",
    "\n",
    "After setting up DVC, we can now define function to collect and store data. This will follow the following steps:\n",
    "-   Export data using a naming convention `/data/YY-mm-dd_dataset`\n",
    "    -   (optional) create `/data_descriptions` to add to GitHub\n",
    "-   Add the data to DVC, creating a `.dvc` reference to the `/data/*`\n",
    "-   Commit the `.dvc` reference to GitHub\n",
    "-   push the `/data/*` to DVC and push the `.dvc` to GitHub\n",
    "\n",
    "This kind of versioning allows us to explore data in GitHub by using `git checkout` first (to switch a branch or checkout a .dvc file version) and then run `dvc checkout` to sync data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Unstaged files detected.\n",
      "[INFO] Stashing unstaged files to /Users/davidberenstein/.cache/pre-commit/patch1673435632-44248.\n",
      "check yaml...........................................(no files to check)Skipped\n",
      "fix end of files.....................................(no files to check)Skipped\n",
      "trim trailing whitespace.................................................Passed\n",
      "Insert license header in Python source files.........(no files to check)Skipped\n",
      "black................................................(no files to check)Skipped\n",
      "isort................................................(no files to check)Skipped\n",
      "[INFO] Restored changes from /Users/davidberenstein/.cache/pre-commit/patch1673435632-44248.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[docs/tutorial-on-dvc-usage c86cb402] update DVC files\n",
      " 4 files changed, 10 insertions(+)\n",
      " create mode 100644 docs/_source/tutorials/notebooks/.dvc/.gitignore\n",
      " create mode 100644 docs/_source/tutorials/notebooks/.dvc/config\n",
      " create mode 100644 docs/_source/tutorials/notebooks/.dvcignore\n",
      " create mode 100644 docs/_source/tutorials/notebooks/data/zingg.pkl.dvc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/argilla-io/argilla.git\n",
      "   2ea0912d..c86cb402  docs/tutorial-on-dvc-usage -> docs/tutorial-on-dvc-usage\n"
     ]
    }
   ],
   "source": [
    "import argilla as rg\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import os\n",
    "import argilla as rg\n",
    "\n",
    "rg.init(api_url=os.environ.get(\"ARGILLA_API_URL_DEV\"), api_key=os.environ.get(\"ARGILLA_API_KEY\"))\n",
    "\n",
    "def dataset_backupper(datasets: List[str], duration: int=60*60*24):    \n",
    "    while True:\n",
    "        # load datasets and save as .pkl files\n",
    "        for dataset_name in datasets:   \n",
    "            ds = rg.load(dataset_name)\n",
    "            df = ds.to_pandas()\n",
    "            df.to_pickle(f\"data/{dataset_name}.pkl\")\n",
    "\n",
    "        # get all .pkl files using glob\n",
    "        files = glob.glob('data/*.pkl', recursive=True)\n",
    "        [os.system(f'dvc add {file}') for file in files]\n",
    "        \n",
    "        # push all .pkl.dvc files to github via git push\n",
    "        os.system(\"dvc push\")\n",
    "        os.system(\"git commit -m 'update DVC files'\")\n",
    "        os.system(\"git push\")\n",
    "        \n",
    "        time.sleep(duration)\n",
    "dataset_backupper([\"argilla-dvc\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a toy example but it is highly configurable depending on your needs. \n",
    "Think about, \n",
    "- only backing up records that are more than X days old\n",
    "- deleting records after backing them up\n",
    "- separating backups per time period \n",
    "- add [model versioning](https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial) into the mix\n",
    "\n",
    "Be creative and have some fun while doing it ü§ì"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data versions\n",
    "\n",
    "Next, we can explore data based on our git commit hashes. `git checkout <commit>` opens a previous commit, along with the corresponding `*.dvc` references. Next, we can use `dvc pull` to `fetch` and `checkout` the data files, that were present during the specific `<commit>`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned a bit about [DVC](https://dvc.org/) and how this cool package might be used to back-up and version data within the Argilla ecosystem.\n",
    "This can help to preserve data and keep a clean overview of your data and model history."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Nov 24 2022, 21:36:36) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "39f4e3bd8ecb53b4a2ef9bccb982583dac0632e40e094b10b94294b76eaa26cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
