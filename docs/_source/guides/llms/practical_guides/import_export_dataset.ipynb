{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import/Export a Feedback Dataset\n",
    "\n",
    "To push `FeedbackTask` datasets to Argilla or pull them from Argilla, you can use the `FeedbackDataset.push_to_argilla()` and `FeedbackDataset.from_argilla()` methods, respectively. Additionally, you can also import and export datasets to HuggingFace for persistance and sharing, with the `FeedbackDataset.push_to_huggingface()` and `FeedbackDataset.from_huggingface()` methods, respectively.\n",
    "\n",
    "In the following section, we'll assume that the variable `dataset` is an instance of `FeedbackDataset` that has been previously created locally. If you want to follow along, you can create a new dataset with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla import rg\n",
    "\n",
    "dataset = rg.FeedbackDataset(\n",
    "    fields=[\n",
    "        rg.TextField(name=\"question\"),\n",
    "        rg.TextField(name=\"answer\"),\n",
    "    ],\n",
    "    questions=[\n",
    "        rg.RatingQuestion(\n",
    "            name=\"rating\", \n",
    "            title=\"Rate the quality of the response:\", \n",
    "            description=\"1 = very bad - 5= very good\",\n",
    "            required=True,\n",
    "            values=[1, 2, 3, 4, 5]\n",
    "        ),\n",
    "        rg.TextQuestion(\n",
    "            name=\"corrected-text\",\n",
    "            title=\"Provide a correction to the response:\",\n",
    "            required=False\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Storage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argilla"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `FeedbackDataset` is created locally (not pushed anywhere yet), we can start adding records to it with the method `add_records`, based on the `fields` and, if we have `responses` already, based on the `questions` too. Once we're happy with the dataset, we can push it to Argilla with the `FeedbackDataset.push_to_argilla()` method, so that we can see it in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_argilla(name=\"my-dataset\", workspace=\"my-workspace\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can also pull a dataset from Argilla with the `FeedbackDataset.from_argilla()` method. This method will return a new instance of `FeedbackDataset` with the same guidelines, fields, questions, and records (including annotations if any) as the dataset in Argilla. And then we can push it again to Argilla if we want e.g. under a different name, if we included new records, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.FeedbackDataset.from_argilla(\"my-dataset\", workspace=\"my-workspace\")\n",
    "dataset.push_to_argilla(name=\"my-dataset-clone\", workspace=\"my-workspace\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace Hub\n",
    "\n",
    "It is also possible to save and load `FeedbackDataset`s into the HuggingFace Hub for persistance. So on, the methods `push_to_huggingface` and `from_huggingface` allow you to push those to the HuggingFace Hub, or to pull those locally from the HuggingFace Hub, respectively.\n",
    "\n",
    "Note that just the `FeedbackDataset`s that have been pushed to the HuggingFace Hub via `push_to_huggingface` can be loaded back with `from_huggingface`, as we're not just uploading the dataset records, but also a configuration file named `argilla.cfg`, that contains the dataset configuration i.e. the fields, questions, and guidelines, if any.\n",
    "\n",
    "Also note that the args and kwargs of `push_to_huggingface` are the args of `push_to_hub` from ðŸ¤—[datasets](https://github.com/huggingface/datasets), and the ones of `from_huggingface` are the args of `load_dataset` from ðŸ¤—[datasets](https://github.com/huggingface/datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push to HuggingFace Hub\n",
    "dataset.push_to_huggingface(\"argilla/my-dataset-clone\")\n",
    "\n",
    "# Push to HuggingFace Hub as private\n",
    "dataset.push_to_huggingface(\"argilla/my-dataset-clone\", private=True, token=\"...\")\n",
    "\n",
    "# Load a public dataset\n",
    "dataset = rg.FeedbackDataset.from_huggingface(\"argilla/my-dataset\")\n",
    "\n",
    "# Load a private dataset\n",
    "dataset = rg.FeedbackDataset.from_huggingface(\"argilla/my-dataset\", use_auth_token=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, when pushing a `FeedbackDataset` to the HuggingFace Hub, one can provide the param `generate_card` to generate and push the `DatasetCard` too. `generate_card` default value is True, so it will always be generated unless `generate_card=False` is specified."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination\n",
    "\n",
    "Additionally, one could combine all the different cloud storage options to e.g. pull a `FeedbackDataset` from Argilla, and then push it to the HuggingFace Hub, or viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull from Argilla\n",
    "dataset = rg.FeedbackDataset.from_argilla(\"my-dataset\", workspace=\"my-workspace\")\n",
    "\n",
    "# Push to HuggingFace Hub\n",
    "dataset.push_to_huggingface(\"argilla/my-dataset-clone\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Storage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, due to the integration with ðŸ¤—`datasets`, as a workaround, you can also export the records of a `FeedbackDataset` locally in your preferred format by converting the `FeedbackDataset` to a `datasets.Dataset` first using the method `format_as(\"datasets\")`, and then exporting the `datasets.Dataset` to either CSV, `pandas`, Parquet, etc.\n",
    "\n",
    "Note that we are relying on ðŸ¤—`datasets` to not re-invent the wheel, but take into consideration that this workaround will just export the records into the desired format, not the dataset itself, so those cannot be loaded back automatically for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = dataset.format_as(\"datasets\")\n",
    "\n",
    "hf_dataset.save_to_disk(\"sharegpt-prompt-rating-mini\")  # Save as a `datasets.Dataset` in the local filesystem\n",
    "hf_dataset.to_csv(\"sharegpt-prompt-rating-mini.csv\")  # Save as CSV\n",
    "hf_dataset.to_parquet()  # Save as Parquet\n",
    "\n",
    "hf_dataset.to_pandas()  # Convert to `pandas.DataFrame`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d98cb9bf90a932b5bf8e86e91214497eb0e38eb318595fbd6fbd5460fe92036"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
