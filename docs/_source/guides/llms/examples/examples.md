# Examples

Here you can find end-to-end examples to help you get started with curanting datasets and collecting feedback to fine-tune LLMs.

````{grid}  1 1 3 3
:class-container: tuto-section-2
```{grid-item-card} Curate an instruction dataset for supervised fine-tuning
:link: curating-feedback-instructiondataset.html

Learn how to set up a project to curate a public dataset that can be used to fine-tune an instruction-following model.

```
```{grid-item-card} Train a Reward Model for RLHF
:link: train-reward-model-rlhf.html

Learn how to collect comparison or human preference data and train a reward model with the trl library.

```
```{grid-item-card} Add zero-shot suggestions using Setfit
:link: labelling-feedback-setfit.html

Learn how to add suggestions to your Feedback dataset using Setfit.

```
````

```{toctree}
:hidden:

curating-feedback-instructiondataset
train-reward-model-rlhf
labelling-feedback-setfit
```