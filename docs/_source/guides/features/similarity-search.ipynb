{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5723a326-5578-4c37-846b-266046c12a91",
   "metadata": {},
   "source": [
    "# Similarity search\n",
    "\n",
    "This guide gives an overview of the similarity search features. Since `1.2.0` Argilla supports adding vectors to Argilla records which can then be used for finding the most similar records to a given one. This feature uses vector or semantic search combined with more traditional search (keyword and filter based). Vector search leverages machine learning to capture rich semantic features by embedding items (text, video, images, etc.) into a vector space, which can be then used to find \"semantically\" similar items.\n",
    "\n",
    "In this guide, you'll find how to:\n",
    "* Setup your Elasticsearch or Opensearch endpoint with vector search support.\n",
    "* Encode text for Argilla records.\n",
    "* Use similarity search.\n",
    "\n",
    "The next section gives a general overview about how similarity search works in Argilla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b648c176-0442-4905-b6e7-ed1056fbf83e",
   "metadata": {},
   "source": [
    "## How it works\n",
    "Similarity search in Argilla works as follows:\n",
    "\n",
    "1. One or several vectors can be included in the `vector` field of Argilla Records. The `vector` field accepts a dictionary as for certain use cases you might want to use several vectors. In\n",
    "2. The vectors are stored at indexing time, once the records are logged with `rg.log`.\n",
    "3. If you have stored vectors in your dataset, you can use the similarity search feature in Argilla UI or the `vector` param in the `rg.load` method of the Python Client.\n",
    "\n",
    "In future versions, embedding services might be developed to skip 1 and 2 and associate vectors to records automatically. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "    \n",
    "It's completely up to the user which encoding or embedding mechanism to use for producing these vectors. In the \"Encode text fields\" section of this document you will find several examples and details about this process, using open source libraries (e.g., Hugging Face) as well as paid services (e.g., Cohere or OpenAI).\n",
    "\n",
    "Currently, Argilla uses vector search only for searching similar records (nearest neighbours) of a given vector. This can be leveraged from Argilla UI as well as the Python Client. In the future, vector search could be leveraged as well for free text queries using Argilla UI.\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "## Setup Elasticsearch or Opensearch with vector search support\n",
    "\n",
    "\n",
    "TODO: @frascuchon please add some basic content (bullet point and references) here\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Warning\n",
    "\n",
    "Add here potential issues with ES or Opensearch in terms of performance, loosing/not seeing data from past versions, etc.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e81a35-9f3e-461f-ade2-c69f080bb5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83980b39-a52d-4282-a33e-79abf7dc31b0",
   "metadata": {},
   "source": [
    "## Encode text fields\n",
    "The first and most important thing to do before leveraging similarity search is to turn text into a numerical representation: a vector. In practical terms, you can think of a vector as an array or list of numbers. You can associate this list of numbers with an Argilla Record by using the aforementioned `vectors` field. But the question is: **how do you create these vectors?** \n",
    "\n",
    "Over the years, many approaches have been used to turn text into numerical representations. The goal is to \"encode\" meaning, context,  topics, etc.. This can be used to find \"semantically\" similar text. Some of these approaches are: *LSA* (Latent Semantic Analysis), *tf-idf*, *LDA* (Latent Dirichlet Allocation), or *doc2Vec*. More recent methods fall in the category of \"neural\" methods, which leveragage the power of large neural networks to *embed* text into dense vectors (a large array of real numbers). These methods have demonstrated a great ability of capturing semantic features. These methods are powering a new wave of technologies that fall under categories like neural search, semantic search, or vector search. Most of these methods involve using a large language model to encode the full context of a textual snippet, such as a sentence, a paragraph, and more lately larger documents.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "   \n",
    "In the context of Argilla, we intentionally use the term `vector` in favour of `embedding` to emphasize that users can leverage methods other than neural, which might be cheaper to compute, or be more useful for their use cases.\n",
    "</div>\n",
    "\n",
    "### Sentence Transformers\n",
    "\n",
    "### OpenAI\n",
    "\n",
    "### Cohere\n",
    "\n",
    "### spaCy\n",
    "\n",
    "### BertTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85aef80-7600-4e32-88a8-cdad9b87ce75",
   "metadata": {},
   "source": [
    "## Use similarity search\n",
    "\n",
    "### Argilla UI\n",
    "\n",
    "### Argilla Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d2492-9384-42a6-980d-db9fd6add985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
