{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“•ðŸ“— Text Classification\n",
    "\n",
    "Text classification deals with predicting in which categories a text fits. As if youâ€™re shown an image you could quickly tell if thereâ€™s a dog or a cat in it, we build NLP models to distinguish between a Jane Austenâ€™s novel or a Charlotte Bronteâ€™s poem. Itâ€™s all about feeding models with labelled examples and seeing how they start predicting over the very same labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Categorization\n",
    "\n",
    "This is a general example of the Text Classification family of tasks. Here, we will try to assign pre-defined categories to sentences and texts. The possibilities are endless! Topic categorization, spam detection, and a vast etcÃ©tera.\n",
    "\n",
    "For our example, we are using the [SequeezeBERT](https://huggingface.co/typeform/squeezebert-mnli) zero-shot classifier for predicting the topic of a given text, in three different labels: politics, sports and technology. We are also using [AG](https://huggingface.co/datasets/ag_news), a collection of news, as our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading our dataset\n",
    "dataset = load_dataset(\"ag_news\", split=\"train[0:20]\")\n",
    "\n",
    "# Define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"typeform/squeezebert-mnli\",\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "records = []\n",
    "\n",
    "for record in dataset:\n",
    "    # Making the prediction\n",
    "    prediction = classifier(\n",
    "        record[\"text\"],\n",
    "        candidate_labels=[\n",
    "            \"politics\",\n",
    "            \"sports\",\n",
    "            \"technology\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Creating the prediction entity as a list of tuples (label, probability)\n",
    "    prediction = list(zip(prediction[\"labels\"], prediction[\"scores\"]))\n",
    "\n",
    "    # Appending to the record list\n",
    "    records.append(\n",
    "        rg.TextClassificationRecord(\n",
    "            text=record[\"text\"],\n",
    "            prediction=prediction,\n",
    "            prediction_agent=\"https://huggingface.co/typeform/squeezebert-mnli\",\n",
    "            metadata={\"split\": \"train\"},\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Logging into Argilla\n",
    "rg.log(\n",
    "    records=records,\n",
    "    name=\"text-categorization\",\n",
    "    tags={\n",
    "        \"task\": \"text-categorization\",\n",
    "        \"phase\": \"data-analysis\",\n",
    "        \"family\": \"text-classification\",\n",
    "        \"dataset\": \"ag_news\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "In this kind of project, we want our models to be able to detect the polarity of the input. Categories like *positive*, *negative* or *neutral* are often used. \n",
    "\n",
    "For this example, we are going to use an [Amazon review polarity dataset](https://huggingface.co/datasets/amazon_polarity), and a sentiment analysis [roBERTa model](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment?text=I+like+you.+I+love+you), which returns `LABEL 0` for positive, `LABEL 1` for neutral and `LABEL 2` for negative. We will handle that in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading our dataset\n",
    "dataset = load_dataset(\"amazon_polarity\", split=\"train[0:20]\")\n",
    "\n",
    "# Define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "    framework=\"pt\",\n",
    "    return_all_scores=True,\n",
    ")\n",
    "\n",
    "# Make a dictionary to translate labels to a friendly-language\n",
    "translate_labels = {\n",
    "    \"LABEL_0\": \"positive\",\n",
    "    \"LABEL_1\": \"neutral\",\n",
    "    \"LABEL_2\": \"negative\",\n",
    "}\n",
    "\n",
    "records = []\n",
    "\n",
    "for record in dataset:\n",
    "    # Making the prediction\n",
    "    predictions = classifier(\n",
    "        record[\"content\"],\n",
    "    )\n",
    "\n",
    "    # Creating the prediction entity as a list of tuples (label, probability)\n",
    "    prediction = [\n",
    "        (translate_labels[prediction[\"label\"]], prediction[\"score\"])\n",
    "        for prediction in predictions[0]\n",
    "    ]\n",
    "\n",
    "    # Appending to the record list\n",
    "    records.append(\n",
    "        rg.TextClassificationRecord(\n",
    "            text=record[\"content\"],\n",
    "            prediction=prediction,\n",
    "            prediction_agent=(\n",
    "                \"https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "            ),\n",
    "            metadata={\"split\": \"train\"},\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Logging into Argilla\n",
    "rg.log(\n",
    "    records=records,\n",
    "    name=\"sentiment-analysis\",\n",
    "    tags={\n",
    "        \"task\": \"sentiment-analysis\",\n",
    "        \"phase\": \"data-annotation\",\n",
    "        \"family\": \"text-classification\",\n",
    "        \"dataset\": \"amazon-polarity\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Textual Similarity\n",
    "\n",
    "This task is all about how close or far a given text is from any other. We want models that output a value of closeness between two inputs.\n",
    "\n",
    "For our example, we will be using [MRPC dataset](https://paperswithcode.com/dataset/mrpc), a corpus consisting of 5,801 sentence pairs collected from newswire articles. These pairs could (or could not) be paraphrases. Our model will be a [sentence Transformer](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L12-v2), trained specifically for this task. \n",
    "\n",
    "As HuggingFace Transformers does not support natively this task, we will be using the [Sentence Transformer](https://www.sbert.net) framework. For more information about how to make these predictions with HuggingFace Transformer, please visit this [link](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L12-v2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading our dataset\n",
    "dataset = load_dataset(\"glue\", \"mrpc\", split=\"train[0:20]\")\n",
    "\n",
    "# Loading the model\n",
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for record in dataset:\n",
    "    # Creating a sentence list\n",
    "    sentences = [record[\"sentence1\"], record[\"sentence2\"]]\n",
    "\n",
    "    # Obtaining similarity\n",
    "    paraphrases = util.paraphrase_mining(model, sentences)\n",
    "\n",
    "    for paraphrase in paraphrases:\n",
    "        score, _, _ = paraphrase\n",
    "\n",
    "    # Building up the prediction tuples\n",
    "    prediction = [(\"similar\", score), (\"not similar\", 1 - score)]\n",
    "\n",
    "    # Appending to the record list\n",
    "    records.append(\n",
    "        rg.TextClassificationRecord(\n",
    "            inputs={\n",
    "                \"sentence 1\": record[\"sentence1\"],\n",
    "                \"sentence 2\": record[\"sentence2\"],\n",
    "            },\n",
    "            prediction=prediction,\n",
    "            prediction_agent=(\n",
    "                \"https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L12-v2\"\n",
    "            ),\n",
    "            metadata={\"split\": \"train\"},\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Logging into Argilla\n",
    "rg.log(\n",
    "    records=records,\n",
    "    name=\"semantic-textual-similarity\",\n",
    "    tags={\n",
    "        \"task\": \"similarity\",\n",
    "        \"type\": \"paraphrasing\",\n",
    "        \"family\": \"text-classification\",\n",
    "        \"dataset\": \"mrpc\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Inference\n",
    "\n",
    "Natural language inference is the task of determining whether a hypothesis is true (which will mean entailment), false (contradiction), or undetermined (neutral) given a premise. This task also works with pair of sentences. \n",
    "\n",
    "Our dataset will be the famous [SNLI](https://huggingface.co/datasets/snli), a collection of 570k human-written English sentence pairs; and our model will be a [zero-shot, cross encoder for inference](https://huggingface.co/cross-encoder/nli-MiniLM2-L6-H768)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading our dataset\n",
    "dataset = load_dataset(\"snli\", split=\"train[0:20]\")\n",
    "\n",
    "# Define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"cross-encoder/nli-MiniLM2-L6-H768\",\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "records = []\n",
    "\n",
    "for record in dataset:\n",
    "    # Making the prediction\n",
    "    prediction = classifier(\n",
    "        record[\"premise\"] + record[\"hypothesis\"],\n",
    "        candidate_labels=[\n",
    "            \"entailment\",\n",
    "            \"contradiction\",\n",
    "            \"neutral\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Creating the prediction entity as a list of tuples (label, probability)\n",
    "    prediction = list(zip(prediction[\"labels\"], prediction[\"scores\"]))\n",
    "\n",
    "    # Appending to the record list\n",
    "    records.append(\n",
    "        rg.TextClassificationRecord(\n",
    "            inputs={\"premise\": record[\"premise\"], \"hypothesis\": record[\"hypothesis\"]},\n",
    "            prediction=prediction,\n",
    "            prediction_agent=\"https://huggingface.co/cross-encoder/nli-MiniLM2-L6-H768\",\n",
    "            metadata={\"split\": \"train\"},\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Logging into Argilla\n",
    "rg.log(\n",
    "    records=records,\n",
    "    name=\"natural-language-inference\",\n",
    "    tags={\n",
    "        \"task\": \"nli\",\n",
    "        \"family\": \"text-classification\",\n",
    "        \"dataset\": \"snli\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stance Detection\n",
    "\n",
    "Stance detection is the NLP task which seeks to extract from a subject's reaction to a claim made by a primary actor. It is a core part of a set of approaches to fake news assessment. For example:\n",
    "\n",
    "-   **Source**: \"*Apples are the most delicious fruit in existence*\"\n",
    "-   **Reply**: \"*Obviously not, because that is a reuben from Katz's*\"\n",
    "-   **Stance**: deny\n",
    "\n",
    "But it can be done in many different ways. In the search of fake news, there is usually one source of text.\n",
    "\n",
    "We will be using the [LIAR datastet](https://huggingface.co/datasets/liar), a fake news detection dataset with 12.8K human labeled short statements from politifact.com's API, and each statement is evaluated by a politifact.com editor for its truthfulness, and a zero-shot [distilbart](https://huggingface.co/valhalla/distilbart-mnli-12-3) model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading our dataset\n",
    "dataset = load_dataset(\"liar\", split=\"train[0:20]\")\n",
    "\n",
    "# Define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"valhalla/distilbart-mnli-12-3\",\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "records = []\n",
    "\n",
    "for record in dataset:\n",
    "    # Making the prediction\n",
    "    prediction = classifier(\n",
    "        record[\"statement\"],\n",
    "        candidate_labels=[\n",
    "            \"false\",\n",
    "            \"half-true\",\n",
    "            \"mostly-true\",\n",
    "            \"true\",\n",
    "            \"barely-true\",\n",
    "            \"pants-fire\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Creating the prediction entity as a list of tuples (label, probability)\n",
    "    prediction = list(zip(prediction[\"labels\"], prediction[\"scores\"]))\n",
    "\n",
    "    # Appending to the record list\n",
    "    records.append(\n",
    "        rg.TextClassificationRecord(\n",
    "            text=record[\"statement\"],\n",
    "            prediction=prediction,\n",
    "            prediction_agent=\"https://huggingface.co/typeform/squeezebert-mnli\",\n",
    "            metadata={\"split\": \"train\"},\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Logging into Argilla\n",
    "rg.log(\n",
    "    records=records,\n",
    "    name=\"stance-detection\",\n",
    "    tags={\n",
    "        \"task\": \"stance detection\",\n",
    "        \"family\": \"text-classification\",\n",
    "        \"dataset\": \"liar\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel Text Classification\n",
    "\n",
    "A variation of the text classification basic problem, in this task we want to categorize a given input into one or more categories. The labels or categories are not mutually exclusive.\n",
    "\n",
    "For this example, we will be using the [go emotions](https://huggingface.co/datasets/go_emotions) dataset, with Reddit comments categorized in 27 different emotions. Alongside the dataset, we've chosen a [DistilBERT model](https://huggingface.co/joeddav/distilbert-base-uncased-go-emotions-student), distilled from a zero-shot classification pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading our dataset\n",
    "dataset = load_dataset(\"go_emotions\", split=\"train[0:20]\")\n",
    "\n",
    "# Define our HuggingFace Pipeline\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"joeddav/distilbert-base-uncased-go-emotions-student\",\n",
    "    framework=\"pt\",\n",
    "    return_all_scores=True,\n",
    ")\n",
    "\n",
    "records = []\n",
    "\n",
    "for record in dataset:\n",
    "    # Making the prediction\n",
    "    prediction = classifier(record[\"text\"], multi_label=True)\n",
    "\n",
    "    # Creating the prediction entity as a list of tuples (label, probability)\n",
    "    prediction = [(pred[\"label\"], pred[\"score\"]) for pred in prediction[0]]\n",
    "\n",
    "    # Appending to the record list\n",
    "    records.append(\n",
    "        rg.TextClassificationRecord(\n",
    "            text=record[\"text\"],\n",
    "            prediction=prediction,\n",
    "            prediction_agent=\"https://huggingface.co/typeform/squeezebert-mnli\",\n",
    "            metadata={\"split\": \"train\"},\n",
    "            multi_label=True,  # we also need to set the multi_label option in Argilla\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Logging into Argilla\n",
    "rg.log(\n",
    "    records=records,\n",
    "    name=\"multilabel-text-classification\",\n",
    "    tags={\n",
    "        \"task\": \"multilabel-text-classification\",\n",
    "        \"family\": \"text-classification\",\n",
    "        \"dataset\": \"go_emotions\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Classification\n",
    "\n",
    "The node classification task is the one where the model has to determine the labelling of samples (represented as nodes) by looking at the labels of their neighbours, in a Graph Neural Network. If you want to know more about GNNs, we've made a [tutorial](https://docs.rubrix.ml/en/stable/tutorials/03-kglab_pytorch_geometric.html) about them using Kglab and PyTorch Geometric, which integrates Argilla into the pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "39f4e3bd8ecb53b4a2ef9bccb982583dac0632e40e094b10b94294b76eaa26cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
