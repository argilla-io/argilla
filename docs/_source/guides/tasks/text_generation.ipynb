{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## üë®üèΩüí¨ Text Generation\n",
    "The expression *TextGeneration* encompasses text generation tasks where the model receives and outputs a sequence of tokens.\n",
    "Examples of such tasks are machine translation, text summarization, paraphrase generation, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Machine translation\n",
    "\n",
    "Machine translation is the task of translating text from one language to another.\n",
    "It is arguably one of the oldest NLP tasks, but human parity remains an [open challenge](https://aclanthology.org/W18-6312.pdf) especially for low resource languages and domains.\n",
    "\n",
    "In the following small example we will showcase how *Argilla* can help you to fine-tune an English-to-Spanish translation model.\n",
    "Let us assume we want to translate \"Sesame Street\" related content.\n",
    "If you have been to Spain before you probably noticed that named entities (like character or band names) are often translated quite literally or are very different from the original ones.  \n",
    "We will use a pre-trained ü§ó transformers model to get a few suggestions for the translation, and then correct them in *Argilla* to obtain a training set for the fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "\n",
    "from transformers import pipeline\n",
    "import argilla as rg\n",
    "\n",
    "# Instantiate the translator\n",
    "translator = pipeline(\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "\n",
    "# 'Sesame Street' related phrase\n",
    "en_phrase = \"Sesame Street is an American educational children's television series starring the muppets Ernie and Bert.\"\n",
    "\n",
    "# Get two predictions from the translator\n",
    "es_predictions = [output[\"translation_text\"] for output in translator(en_phrase, num_return_sequences=2)]\n",
    "\n",
    "# Log the record to Argilla and correct them\n",
    "record = rg.TextGenerationRecord(\n",
    "    text=en_phrase,\n",
    "    prediction=es_predictions,\n",
    ")\n",
    "rg.log(record, name=\"sesame_street_en-es\")\n",
    "\n",
    "# For a real training set you probably would need more than just one 'Sesame Street' related phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the *Argilla* web app we can now easily browse the predictions and annotate the records with a corrected prediction of our choice.\n",
    "The predictions for our example phrase are:\n",
    "1. Sesame Street es una serie de televisi√≥n infantil estadounidense protagonizada por los muppets Ernie y Bert.\n",
    "2. Sesame Street es una serie de televisi√≥n infantil y educativa estadounidense protagonizada por los muppets Ernie y Bert.\n",
    "\n",
    "We probably would choose the second one and correct it in the following way:\n",
    "\n",
    "2. *Barrio S√©samo* es una serie de televisi√≥n infantil y educativa estadounidense protagonizada por los *tele√±ecos Epi y Blas*.*\n",
    "\n",
    "\n",
    "After correcting a substantial number of example phrases, we can load the corrected data set as a DataFrame to use it for the fine-tuning of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corrected translations for the fine-tuning of the translation model\n",
    "df = rg.load(\"sesame_street_en-es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Summarization\n",
    "\n",
    "Summarization is the task of producing a shorter version of a document while preserving its important information. Some models can extract text from the original input, while other models can generate entirely new text.\n",
    "\n",
    "Following example explain how to use Summarization Pipeline along with Argilla to log the summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import argilla as rg\n",
    "\n",
    "# test text\n",
    "phrase = \"Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018, in an area of more than 105 square kilometres (41 square miles). The City of Paris is the centre and seat of government of the region and province of √É∆í√Ç≈Ωle-de-France, or Paris Region, which has an estimated population of 12,174,880, or about 18 percent of the population of France as of 2017.\"\n",
    "classifier = pipeline(\"summarization\")\n",
    "\n",
    "# Get three summaries\n",
    "predictions = [output['summary_text'] for output in classifier(phrase,\n",
    "                                                               num_return_sequences=3, max_length=56)]\n",
    "\n",
    "# Log the records to Argilla\n",
    "record = rg.TextGenerationRecord(\n",
    "    text=phrase,\n",
    "    prediction=predictions,\n",
    ")\n",
    "rg.log(record, name=\"paris-demographic-summary\",\n",
    "       tags={\"task\": \"summarization\", \"family\": \"textgeneration\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf5ecc3fecf17575e278cfc1ec050b1bf24f64b662a1b5421daed12bdd8255ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
