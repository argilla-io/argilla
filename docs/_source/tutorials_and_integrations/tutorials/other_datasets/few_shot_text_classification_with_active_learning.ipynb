{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7b5a1fa-9265-4fb8-9c0e-a9156c22f4ff",
   "metadata": {},
   "source": [
    "# ðŸ‘‚ Few shot text classification with active learning using small-text and SetFit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799987c-764f-4295-97b7-d0e48324cccd",
   "metadata": {},
   "source": [
    "In this tutorial, you will learn how to set up a complete active learning loop with a [Hugging Face transformer](https://huggingface.co/docs/transformers/index):\n",
    "\n",
    " - Use the excellent [small-text](https://github.com/webis-de/small-text) library to set up your active learner;\n",
    " - Use a [Argilla listener](/../reference/python/python_listeners.html#python-listeners) to build and start an active learning loop;\n",
    " - Use the [Argilla UI](/../reference/webapp/features.html#annotate) to annotate examples and learn actively;\n",
    "\n",
    "![training-textclassification-smalltext-activelearning](/_static/tutorials/training-textclassification-smalltext-activelearning/training-textclassification-smalltext-activelearning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0136985-b7a3-4983-9d62-6750507992d7",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89104d7-b4fe-402b-a33f-f2f8ba7353ba",
   "metadata": {},
   "source": [
    "> Active learning is a special case of machine learning in which a learning algorithm can interactively query a user (or some other information source) to label new data points with the desired outputs. [Wikipedia](https://en.wikipedia.org/wiki/Active_learning_(machine_learning))\n",
    "\n",
    "Supervised machine learning often requires large amounts of labeled data that are expensive to generate. \n",
    "*Active Learning* (AL) systems attempt to overcome this labeling bottleneck. \n",
    "The underlying idea is that not all data points are equally important for training the model. \n",
    "The AL system tries to query only the most relevant data from a pool of unlabeled data to be labeled by a so-called *oracle*, which is often a human annotator.\n",
    "Therefore, AL systems are usually much more sample-efficient and need far less training data than traditional supervised systems.\n",
    "\n",
    "This tutorial will show you how to incorporate [Argilla](https://github.com/argilla-io/argilla) into an active learning workflow involving a human in the loop.\n",
    "We will build a simple text classifier by combining the active learning framework [small-text](https://github.com/webis-de/small-text) and Argilla. \n",
    "Hugging Face's [transformers](https://github.com/huggingface/transformers) will provide the classifier we will embed in an active learner from small-text. Argilla excels in making **you** the oracle that conveniently teaches the model via an intuitive UI."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a26cf42c-5c8f-4c07-bc10-6a9ba2cdd3f5",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces**: If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](/../getting_started/quickstart_installation.html). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "    \n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter Notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc04e5-ba24-474e-a38b-2992fc4b7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"argilla[listeners]\" \"datasets~=2.5.0\" \"small-text>=1.1.0\"  \"transformers[torch]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fabdd145",
   "metadata": {},
   "source": [
    "Let's import the Argilla module for reading and writing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac811da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "556046ed",
   "metadata": {
    "id": "7TRNourOwigS"
   },
   "source": [
    "If you are running Argilla using the Docker quickstart image or Hugging Face Spaces, you need to init the Argilla client with the `URL` and `API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "# Replace workspace with the name of your workspace\n",
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\", \n",
    "    api_key=\"owner.apikey\",\n",
    "    workspace=\"admin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running a private Hugging Face Space, you will also need to set the [HF_TOKEN](https://huggingface.co/settings/tokens) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the HF_TOKEN environment variable\n",
    "# import os\n",
    "# os.environ['HF_TOKEN'] = \"your-hf-token\"\n",
    "\n",
    "# # Replace api_url with the url to your HF Spaces URL\n",
    "# # Replace api_key if you configured a custom API key\n",
    "# # Replace workspace with the name of your workspace\n",
    "# rg.init(\n",
    "#     api_url=\"https://[your-owner-name]-[your_space_name].hf.space\", \n",
    "#     api_key=\"owner.apikey\",\n",
    "#     workspace=\"admin\",\n",
    "#     extra_headers={\"Authorization\": f\"Bearer {os.environ['HF_TOKEN']}\"},\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Telemetry\n",
    "\n",
    "We gain valuable insights from how you interact with our tutorials. To improve ourselves in offering you the most suitable content, using the following lines of code will help us understand that this tutorial is serving you effectively. Though this is entirely anonymous, you can choose to skip this step if you prefer. For more info, please check out the [Telemetry](../../reference/telemetry.md) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from argilla.utils.telemetry import tutorial_running\n",
    "    tutorial_running()\n",
    "except ImportError:\n",
    "    print(\"Telemetry is introduced in Argilla 1.20.0 and not found in the current installation. Skipping telemetry.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43edb962-ce5b-44ad-9175-09143d882c95",
   "metadata": {},
   "source": [
    "## The AG's News dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee4a2c-35f8-42d7-b750-7321df826baf",
   "metadata": {},
   "source": [
    "We use the \"AG's News\" dataset for this demonstration. It consists of news articles that are categorized into four mutually exclusive classes.\n",
    "\n",
    "Let us load the dataset from the [Hugging Face Hub](https://huggingface.co/datasets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f988c3d7-d9b3-40b0-be5b-ed31bf2fa29a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Disables the progress bar for notebooks: https://github.com/huggingface/datasets/issues/2651\n",
    "datasets.logging.get_verbosity = lambda: logging.NOTSET\n",
    "\n",
    "raw_dataset = datasets.load_dataset('ag_news')\n",
    "num_classes = np.unique(raw_dataset['train']['label']).shape[0]\n",
    "\n",
    "print('First 10 training samples:\\n')\n",
    "for i in range(10):\n",
    "    print(raw_dataset['train']['label'][i], ' ', raw_dataset['train']['text'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecba83d-92a0-4873-a0c6-7815b7636705",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d79fa-00b4-44ac-a01a-c39ecccadd52",
   "metadata": {},
   "source": [
    "The SetFit Classifier uses the TextData structure as input. Such datasets can be easily created from raw text and labels using TextDataset.from_arrays()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c49e1-79f1-43a1-bdb7-ff435f985bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from small_text import TextDataset\n",
    "\n",
    "num_classes = raw_dataset['train'].features['label'].num_classes\n",
    "\n",
    "target_labels = np.arange(num_classes)\n",
    "\n",
    "train = TextDataset.from_arrays(\n",
    "    raw_dataset['train']['text'], \n",
    "    np.array(raw_dataset['train']['label']), \n",
    "    target_labels=target_labels\n",
    ")\n",
    "test = TextDataset.from_arrays(\n",
    "    raw_dataset['test']['text'], \n",
    "    np.array(raw_dataset['test']['label']), \n",
    "    target_labels=target_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2befb12-de88-4b37-a80f-e1b27094e3a7",
   "metadata": {},
   "source": [
    "## Setting up the active learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688df949-5588-463b-9867-97f570340daa",
   "metadata": {},
   "source": [
    "Now that we have our datasets ready let's set up the active learner. \n",
    "For this, we need two components:\n",
    "\n",
    " - the **classifier** to be trained;\n",
    " - the **query strategy** to obtain the most relevant data;\n",
    " \n",
    "In our case, we choose a [Hugging Face transformer](https://huggingface.co/docs/transformers/index) as the classifier and a [tie-breaker](https://small-text.readthedocs.io/en/v1.0.0/components/query_strategies.html#small_text.query_strategies.strategies.BreakingTies) as the query strategy. \n",
    "The latter selects instances of the data pool with a small margin between the two most likely predicted labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9966619f-7f2d-4815-9a79-8a2696002e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from small_text import (\n",
    "    BreakingTies,\n",
    "    PoolBasedActiveLearner,\n",
    "    SetFitClassificationFactory,\n",
    "    SetFitModelArguments,\n",
    ")\n",
    "\n",
    "# Set logger to get training feedback\n",
    "logging.getLogger(\"small_text\").setLevel(logging.INFO)\n",
    "\n",
    "# Define our classifier\n",
    "sentence_transformer_model_name = 'sentence-transformers/paraphrase-mpnet-base-v2'\n",
    "setfit_model_args = SetFitModelArguments(sentence_transformer_model_name)\n",
    "clf_factory = SetFitClassificationFactory(\n",
    "    setfit_model_args, \n",
    "    num_classes\n",
    ")\n",
    "\n",
    "# Define our query strategy\n",
    "query_strategy = BreakingTies()\n",
    "setfit_train_kwargs = {'show_progress_bar': False}\n",
    "\n",
    "# Use the active learner with a pool containing all unlabeled data\n",
    "active_learner = PoolBasedActiveLearner(\n",
    "    clf_factory, \n",
    "    query_strategy, \n",
    "    train, \n",
    "    fit_kwargs={'setfit_train_kwargs': setfit_train_kwargs}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f8a4b2-b3ec-4e3e-a299-372b2091ec52",
   "metadata": {},
   "source": [
    "Since most query strategies, including ours, require a trained model, we randomly draw a subset from the data pool to initialize our AL system. \n",
    "After obtaining the labels for this batch of instances, the active learner will use them to create the first classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32804138-8e27-4a61-ac18-c9ab21b47795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from small_text import random_initialization\n",
    "import numpy as np\n",
    "\n",
    "# Fix seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples in our queried batches\n",
    "NUM_SAMPLES = 20\n",
    "\n",
    "# Randomly draw an initial subset from the data pool\n",
    "initial_indices = random_initialization(dataset, NUM_SAMPLES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b2d6d9-b5f6-4ef2-85e9-2583981f534c",
   "metadata": {},
   "source": [
    "## Argilla and you: the perfect oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc62355d-7b50-4ef2-9500-e9172a4c6826",
   "metadata": {},
   "source": [
    "With our active learner ready, it is time to teach it. \n",
    "We first create a [Argilla dataset](/../practical_guides/create_update_dataset/create_dataset.html) to log and label the initial random batch queried by the active learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d03264-f583-47e1-a39f-3335ce9573e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "\n",
    "# Choose a name for the dataset\n",
    "DATASET_NAME = \"ag_with_active_learning\"\n",
    "\n",
    "# Define the labeling schema\n",
    "labels = raw_dataset[\"train\"].features[\"label\"].names\n",
    "settings = rg.TextClassificationSettings(label_schema=labels)\n",
    "\n",
    "# Create a dataset with a label schema\n",
    "rg.configure_dataset_settings(name=DATASET_NAME, settings=settings)\n",
    "\n",
    "# Create records from the initial batch\n",
    "records = [\n",
    "    rg.TextClassificationRecord(\n",
    "        text=raw_dataset[\"train\"][\"text\"][idx],\n",
    "        metadata={\"batch_id\": 0},\n",
    "        id=int(idx),\n",
    "    )\n",
    "    for idx in initial_indices\n",
    "]\n",
    "\n",
    "# Log the initial records to Argilla\n",
    "rg.log(records, DATASET_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9142f4-0140-4128-bc90-ae1956190935",
   "metadata": {},
   "source": [
    "Before switching to the Argilla UI to label the records, we will set up the **active learning loop**. \n",
    "For this, we will use the [listener decorator](/reference/python/python_listeners.html#argilla.listeners.listener) from Argilla.\n",
    "The loop will run automatically once all records of a batch are labeled (see the `query` and `condition` argument of the decorator). \n",
    "It will trigger the classifier's training, query a new batch from the active learner, and log it to Argilla. \n",
    "We will also keep track of the accuracy of the current classifier by evaluating it on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a94391-d957-4d63-aa5c-10874f87e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argilla.listeners import listener\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define some helper variables\n",
    "LABEL2INT = raw_dataset[\"train\"].features[\"label\"].str2int\n",
    "ACCURACIES = []\n",
    "\n",
    "# Set up the active learning loop with the listener decorator\n",
    "@listener(\n",
    "    dataset=DATASET_NAME,\n",
    "    query=\"status:Validated AND metadata.batch_id:{batch_id}\",\n",
    "    condition=lambda search: search.total == NUM_SAMPLES,\n",
    "    execution_interval_in_seconds=3,\n",
    "    batch_id=0,\n",
    ")\n",
    "def active_learning_loop(records, ctx):\n",
    "    # 1. Update active learner\n",
    "    print(f\"Updating with batch_id {ctx.query_params['batch_id']} ...\")\n",
    "    y = np.array([LABEL2INT(rec.annotation) for rec in records])\n",
    "\n",
    "    # initial update\n",
    "    print(\n",
    "        \"Starting training! Depending on your device, this might take a while, so set up\"\n",
    "        \" logging.\"\n",
    "    )\n",
    "    if ctx.query_params[\"batch_id\"] == 0:\n",
    "        indices = np.array([rec.id for rec in records])\n",
    "        active_learner.initialize_data(indices, y)\n",
    "    # update with the prior queried indices\n",
    "    else:\n",
    "        active_learner.update(y)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    # 2. Query active learner\n",
    "    print(\"Querying new data points ...\")\n",
    "    queried_indices = active_learner.query(num_samples=NUM_SAMPLES)\n",
    "    new_batch = ctx.query_params[\"batch_id\"] + 1\n",
    "    new_records = [\n",
    "        rg.TextClassificationRecord(\n",
    "            text=trec[\"train\"][\"text\"][idx],\n",
    "            metadata={\"batch_id\": new_batch},\n",
    "            id=idx,\n",
    "        )\n",
    "        for idx in queried_indices\n",
    "    ]\n",
    "\n",
    "    # 3. Log the batch to Argilla\n",
    "    rg.log(new_records, DATASET_NAME)\n",
    "\n",
    "    # 4. Evaluate the current classifier on the test set\n",
    "    print(\"Evaluating current classifier ...\")\n",
    "    accuracy = accuracy_score(\n",
    "        dataset_test.y,\n",
    "        active_learner.classifier.predict(dataset_test),\n",
    "    )\n",
    "\n",
    "    ACCURACIES.append(accuracy)\n",
    "    ctx.query_params[\"batch_id\"] = new_batch\n",
    "    print(\"Done!\")\n",
    "\n",
    "    print(\"Waiting for annotations ...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb123af-71ad-4520-9ceb-55df5b4083da",
   "metadata": {},
   "source": [
    "## Starting the active learning loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a634a60-5e02-4b8a-89a7-efa72b7de2af",
   "metadata": {},
   "source": [
    "Now we can start the loop and switch to the Argilla UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402519db-4edb-4300-89e4-e542d2b372b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learning_loop.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d88756b-282f-425c-8d5e-c32651d9555f",
   "metadata": {},
   "source": [
    "In the Argilla UI, we will set the number of records per page to 20 since it is also our chosen batch size. \n",
    "Furthermore, we will use the [Status filter](/../reference/webapp/pages.html#filters) to filter out already annotated records. \n",
    "Now, all we have to do is to annotate the displayed records. \n",
    "Once annotating everything, the classifier's training will be automatically triggered.\n",
    "\n",
    "After a few seconds, you should see the newly queried batch when pressing the [Refresh button](/../reference/webapp/pages.html#refresh). \n",
    "The training can take longer depending on your machine and whether you have a CUDA device. \n",
    "You can always check the status of the active learning loop from your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54bab0-8990-4147-b44f-603b66d6d16f",
   "metadata": {},
   "source": [
    "## Can we stop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f5c03-63c7-4a0b-a375-754815e2fa23",
   "metadata": {},
   "source": [
    "After a few iterations, we can check the accuracy of the current classifier and plot its evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5bdde-bdbd-47df-a525-d1354440f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.Series(ACCURACIES).plot(xlabel=\"Iteration\", ylabel=\"Accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67563b66-713d-4118-aa10-b1ac9740a9b8",
   "metadata": {},
   "source": [
    "We should achieve an accuracy of at least **0.8 after around 12 iterations**, corresponding to roughly 260 annotated records. \n",
    "The stopping criterion is ultimately up to you, and you can choose more sophisticated criteria like the [KappaAverage](https://small-text.readthedocs.io/en/v1.0.0/components/stopping_criteria.html) implemented in small-text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36da28-e61c-422f-9c12-132efe872843",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learning_loop.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc923e-72a7-47b7-b38f-43dd9bbe57d9",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d0e5f-8af1-41c8-9e6a-1a0fe2757eaf",
   "metadata": {},
   "source": [
    "In this tutorial, we saw how you could **embed Argilla in an active learning loop involving a human in the loop**. \n",
    "We relied on **small-text to use a Hugging Face transformer within an active learning setup**. \n",
    "In the end, we gathered **a sample-efficient data set by annotating only the most informative records** for the model.\n",
    "\n",
    "Argilla makes it very easy to use a dedicated annotation team or subject matter experts as an oracle for your active learning system. They will only interact with the Argilla UI and do not have to worry about training or querying the system. We encourage you to try out active learning in your next project and make your and your annotator's life a little easier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1 (default, Dec 17 2020, 03:56:09) \n[Clang 11.0.0 (clang-1100.0.33.17)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "8874e298d2bce9702a08b32d5709c9f02d53b2045f1d246836c6e4c8123e6782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
