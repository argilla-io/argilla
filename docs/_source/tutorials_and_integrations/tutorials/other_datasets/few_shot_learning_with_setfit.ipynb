{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15d20dd-31fe-44f9-bba1-b44201dceb91",
   "metadata": {},
   "source": [
    "# ðŸ¤¯ Few-shot classification with SetFit\n",
    "\n",
    "**SetFit** is an exciting open-source package for Few-shot classification developed by teams at Hugging Face and Intel Labs. You can read all about it on the [project repository](https://github.com/huggingface/setfit). \n",
    "\n",
    "To showcase how powerful is **the combination of SetFit and Argilla**:\n",
    "\n",
    "* We manually **label 55 examples** from the unlabelled split of the IMDb dataset, \n",
    "* we train a model in **5 min**, \n",
    "* and without using a single example from the original IMDb training set, we achieve a **0.9 accuracy on the full test set!**\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "\n",
    "In this tutorial, you'll learn to:\n",
    "\n",
    "1. **Load a unlabelled dataset** in Argilla. We'll be using the unlabelled split from the `imdb` movie reviews sentiment dataset. This same workflow can be applied to any custom dataset, problem, and language!\n",
    "\n",
    "2. Manually **label a FEW examples** using the UI.\n",
    "\n",
    "3. **Train a SetFit model** to get highly competitive results. For this example, with **only 55 examples**, we get **0.9 accuracy** on the test set which is comparable to models fine-tuned on 3K examples. That means similar performance with `50x` less examples ðŸ¤¯. \n",
    "\n",
    "For reference see the [Hugging Face Hub](https://huggingface.co/spaces/autoevaluate/leaderboards?dataset=imdb) and [PapersWithCode](https://paperswithcode.com/sota/text-classification-on-imdb) leaderboards.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d44029c-c54e-474e-927b-a85749817f36",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces**: If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](/getting_started/quickstart_installation.html). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "    \n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter Notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c26c6c-b844-4fa8-a225-28104d81d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install argilla \"setfit~=0.2.0\" \"datasets~=2.3.0\" -qqq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fabdd145",
   "metadata": {},
   "source": [
    "Let's import the Argilla module for reading and writing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac811da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "556046ed",
   "metadata": {
    "id": "7TRNourOwigS"
   },
   "source": [
    "If you are running Argilla using the Docker quickstart image or Hugging Face Spaces, you need to init the Argilla client with the `URL` and `API_KEY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "# Replace workspace with the name of your workspace\n",
    "rg.init(\n",
    "    api_url=\"http://localhost:6900\", \n",
    "    api_key=\"owner.apikey\",\n",
    "    workspace=\"admin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running a private Hugging Face Space, you will also need to set the [HF_TOKEN](https://huggingface.co/settings/tokens) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the HF_TOKEN environment variable\n",
    "# import os\n",
    "# os.environ['HF_TOKEN'] = \"your-hf-token\"\n",
    "\n",
    "# # Replace api_url with the url to your HF Spaces URL\n",
    "# # Replace api_key if you configured a custom API key\n",
    "# # Replace workspace with the name of your workspace\n",
    "# rg.init(\n",
    "#     api_url=\"https://[your-owner-name]-[your_space_name].hf.space\", \n",
    "#     api_key=\"owner.apikey\",\n",
    "#     workspace=\"admin\",\n",
    "#     extra_headers={\"Authorization\": f\"Bearer {os.environ['HF_TOKEN']}\"},\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad0c33a2",
   "metadata": {},
   "source": [
    "Let's import the modules we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2d475-12d3-49a3-9cd7-a021f795f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "from setfit import SetFitModel, SetFitTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Telemetry\n",
    "\n",
    "We gain valuable insights from how you interact with our tutorials. To improve ourselves in offering you the most suitable content, using the following lines of code will help us understand that this tutorial is serving you effectively. Though this is entirely anonymous, you can choose to skip this step if you prefer. For more info, please check out the [Telemetry](../../reference/telemetry.md) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from argilla.utils.telemetry import tutorial_running\n",
    "    tutorial_running()\n",
    "except ImportError:\n",
    "    print(\"Telemetry is introduced in Argilla 1.20.0 and not found in the current installation. Skipping telemetry.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb457bf-f703-4242-9f0d-d6dea9817dbf",
   "metadata": {},
   "source": [
    "## Load unlabelled dataset in Argilla\n",
    "\n",
    "First, we load the `unsupervised` split from the `imdb` dataset and create a new Argilla dataset with 100 random examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ccfc09-ba4c-4881-838f-7186897bc1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled = (\n",
    "    load_dataset(\"imdb\", split=\"unsupervised\").shuffle(seed=42).select(range(100))\n",
    ")\n",
    "\n",
    "unlabelled = rg.DatasetForTextClassification.from_datasets(unlabelled)\n",
    "\n",
    "rg.log(unlabelled, \"imdb_unlabelled\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "574c9c3c-c841-43da-b5f0-16947cb261a4",
   "metadata": {},
   "source": [
    "## Manual labeling\n",
    "\n",
    "In this step, we create the labels `pos` and `neg` using the same label scheme as the original dataset. Then we use the UI to sequentially label a few examples. For the example, we spent literally 15 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccff9d86-55d4-42ca-ae32-1428113a5684",
   "metadata": {},
   "source": [
    "Before training, you can easily share the dataset using the `push_to_hub` method. This might be useful if you don't have a GPU on your machine and want to use a training service or Colab for example. More info [here](https://huggingface.co/docs/huggingface_hub/quick-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdb095-b546-4cdf-999c-00c59583866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.load(\"imdb_unlabelled\").prepare_for_training().push_to_hub(\"mini-imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8dbd6a-7dd1-438e-9081-d8152b4b8a00",
   "metadata": {},
   "source": [
    "## Train and evaluate SetFit model\n",
    "\n",
    "Finally, we are ready to test SetFit! \n",
    "\n",
    "Thanks to Argilla's integration with `datasets` and the Hub, if you don't have a local GPU you can use this [Google Colab](https://colab.research.google.com/drive/166TrSY0aJfKYi8U9qWilaXN2b2-nGlVD?usp=sharing) to reproduce the training process with the labeled dataset. If you use a GPU runtime, it literally takes 5 minutes to train.\n",
    "\n",
    "Below we load the dataset from Argilla, format it for training with transformers, load the full IMDb test dataset, load a pre-trained sentence transformers model, train the SetFit model, and evaluate it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d558541-6ab1-4917-9e39-26bd75849567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the hand-labeled dataset from Argilla\n",
    "train_ds = rg.load(\"imdb_unlabelled\").prepare_for_training()\n",
    "\n",
    "# Load the full IMDb test dataset\n",
    "test_ds = load_dataset(\"imdb\", split=\"test\")\n",
    "\n",
    "\n",
    "# Load SetFit model from Hub\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=16,\n",
    "    num_iterations=20,  # The number of text pairs to generate\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2175cb8-65c9-4c8c-900f-03b0d187627d",
   "metadata": {},
   "source": [
    "Optionally, you can share your amazing model with the world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec58bf-5871-41e6-81df-292237d6150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(\"setfit-mini-imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e9b078-7da9-4c92-a0d7-a6143d227400",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The metrics object should give you around 0.9 accuracy on the full test set ðŸŽ‰ \n",
    "\n",
    "And remember:\n",
    "\n",
    "- We have manually labeled 55 examples, \n",
    "- We haven't used a single example from the original training set, \n",
    "- and we've trained the model in 5 min!\n",
    "\n",
    "Now, I don't think you have any more excuses to not invest some time labeling a few good-quality examples!\n",
    "\n",
    "If you are interested in SetFit, you can check our other SetFit + Argilla tutorials:\n",
    "\n",
    "- [Zero-shot and few-shot classification with SetFit](/tutorials/notebooks/labelling-textclassification-setfit-zeroshot.html)\n",
    "- [Train a sentiment classifier with SetFit](/tutorials/notebooks/training-textclassification-setfit-sentiment.html)\n",
    "\n",
    "Or check out the [SetFit repository on GitHub](https://github.com/huggingface/setfit)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a89950ea50845724e7eccac1d52607e0edbb142472dde8c3f43ca41b572e2025"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
