{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Model with `ArgillaTrainer`\n",
    "\n",
    "In this part of our end-to-end series, we will be training our model with ArgillaTrainer. You can refer to previous tutorials such as [creating the dataset](./create-dataset-001.ipynb) or [adding responses and suggestions](./add-suggestions-and-responses-005.ipynb). Feel free to check out the [practical guides](../../../../practical_guides/practical_guides.md) page for more in-depth information.\n",
    "\n",
    "Fine-tuning is a process of training a model with a dataset that is similar to the one it was trained on. This way, the model can learn to perform better on a specific task. In our case, we will be fine-tuning a model with the dataset we created in the previous tutorial. Note that Argilla trainer is a wrapper around many different frameworks and models. Please have a look at the [ArgillaTrainer](../../../../practical_guides/fine_tune.md#the-argillatrainer) page for more information on the NLP tasks and models that are supported.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![workflow](../../../../_static/tutorials/end2end/base/workflow_train_models.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Pull the Dataset](#Pull-the-Dataset)\n",
    "    1. [From Argilla](#From-Argilla)\n",
    "    2. [From HuggingFace Hub](#From-HuggingFace-Hub)\n",
    "2. [Train with Default ArgillaTrainer](#Train-with-Default-ArgillaTrainer-Settings)\n",
    "3. [Train with Custom Formatting Function](#Train-with-Custom-Formatting-Function)\n",
    "4. [Push the Model to Huggingface Hub](#Push-the-Model-to-HuggingFace-Hub)\n",
    "5. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces:** If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](../../../../getting_started/quickstart.md). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "\n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install our dependencies and import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install argilla\n",
    "!pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "from argilla.feedback import FeedbackDataset, TrainingTask, ArgillaTrainer\n",
    "from datasets import load_dataset\n",
    "from argilla._constants import DEFAULT_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook we will need some credentials to push and load datasets from `Argilla` and `ðŸ¤— Hub`, let's set them in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Argilla credentials\n",
    "api_url = \"http://localhost:6900\"  # \"https://<YOUR-HF-SPACE>.hf.space\"\n",
    "api_key = DEFAULT_API_KEY  # admin.apikey\n",
    "# Huggingface credentials\n",
    "hf_token = \"hf_...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log in to Argilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.init(api_url=api_url, api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Telemetry\n",
    "\n",
    "We gain valuable insights from how you interact with our tutorials. To improve ourselves in offering you the most suitable content, using the following lines of code will help us understand that this tutorial is serving you effectively. Though this is entirely anonymous, you can choose to skip this step if you prefer. For more info, please check out the [Telemetry](../../../../reference/telemetry.md) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from argilla.utils.telemetry import tutorial_running\n",
    "    tutorial_running()\n",
    "except ImportError:\n",
    "    print(\"Telemetry is introduced in Argilla 1.20.0 and not found in the current installation. Skipping telemetry.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull the Dataset\n",
    "\n",
    "As we uploaded the dataset that we created in the [previous tutorial](./create-dataset-001.ipynb) to both Argilla and HuggingFace Hub, we can pull the dataset from either of them. Let us see how we can pull the dataset from both.\n",
    "\n",
    "### From Argilla\n",
    "\n",
    "We can pull the dataset from Argilla by using the `from_argilla` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.FeedbackDataset.from_argilla(\"end2end_textclassification_with_suggestions_and_responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From HuggingFace Hub\n",
    "\n",
    "We can also pull the dataset from HuggingFace Hub. Similarly, we can use the `from_huggingface` method to pull the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.FeedbackDataset.from_huggingface(\"argilla/end2end_textclassification_with_suggestions_and_responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note \n",
    "\n",
    "The dataset pulled from HuggingFace Hub is an instance of `FeedbackDataset` whereas the dataset pulled from Argilla is an instance of `RemoteFeedbackDataset`. The difference between the two is that the former is a local one and the changes made on it stay locally. On the other hand, the latter is a remote one and the changes made on it are directly reflected on the dataset on the Argilla server, which can make your process faster.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us briefly examine what our dataset looks like. It is a dataset that consists of data items with the field `text` that is yet to be annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\"}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[0].fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Default ArgillaTrainer Settings\n",
    "\n",
    "As we previously mentioned, you can employ `ArgillaTrainer` for most of your favorite NLP tasks and libraries. What it does is simplify the training process by providing a unified interface for training and fine-tuning models. Let us first see how we can train our model with the default settings.\n",
    "\n",
    "`TrainingTask` is the class that is responsible for how to process the data for training. To make things even easier, it offers task-specific methods that you can use for your particular task at hand. For this tutorial, we will be using the `for_text_classification` method, which will prepare a default data processing function for us. You can see a list of all the available task-specific methods in the [documentation](../../../../practical_guides/fine_tune.md#the-trainingtask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = TrainingTask.for_text_classification(\n",
    "    text=dataset.field_by_name(\"text\"),\n",
    "    label=dataset.question_by_name(\"label\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we need to define an `ArgillaTrainer` for our task that will be used for training. You can define the framework you want to work with in the `framework` parameter. For this tutorial, we will be using the `en_core_web_sm` model from the `spacy` framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ArgillaTrainer(\n",
    "    dataset=dataset,\n",
    "    task=task,\n",
    "    framework=\"spacy\",\n",
    "    train_size=0.8,\n",
    "    model=\"en_core_web_sm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us customize the training process a bit more with the `update_config` method. We specify a model we want to use from HuggingFace. We also specify the number of epochs and the learning rate. You can have a look at the comprehensive list of [training configs](../../../../practical_guides/fine_tune.md#training-configs) for more customization options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.update_config(\n",
    "    max_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are already good to go with the default settings. We only need to call the `train` method to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(output_dir=\"textcat_model_spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Custom Formatting Function\n",
    "\n",
    "The default settings might not be the best for your tasks sometimes. In those cases, you might need to customize the data processing function. You can do that by passing a custom formatting function to the `for_text_classification` method. Let us first define a custom formatting function and then train our model with it.\n",
    "\n",
    "It is important to note that the custom formatting function should return an object that will be accepted by the model. In our case, we will be returning a tuple of texts and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(sample):\n",
    "    text = sample[\"text\"]\n",
    "    label = sample[\"label\"][0][\"value\"]\n",
    "    return(text, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can feed the `TrainingTasks` with our custom formatting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = TrainingTask.for_text_classification(formatting_func=formatting_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we can use the `spacy` framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ArgillaTrainer(\n",
    "    dataset=dataset,\n",
    "    task=task,\n",
    "    framework=\"spacy\",\n",
    "    train_size=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us customize the training process a bit more with the `update_config` method. We specify a model we want to use from HuggingFace. We also specify the number of epochs and the learning rate. You can have a look at the comprehensive list of [training configs](../../../../practical_guides/fine_tune.md#training-configs) for more customization options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.update_config(\n",
    "    max_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we just need to call the `train` method to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(output_dir=\"textcat_model_spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the Model to HuggingFace Hub\n",
    "\n",
    "Now that we completed the training and we have a model that can be used for inference, we can push it to HuggingFace Hub. Argilla again offers quite a simple way to accomplish this with just a single line of code.\n",
    "\n",
    "First, to be able to upload your model to the Hub, you must be logged in to the Hub. The following cell will log us with our previous token.\n",
    "\n",
    "If we don't have one already, we can obtain it from [here](https://huggingface.co/docs/hub/security-tokens) (remember to set the write access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need to call the `push_to_huggingface` method to push the model to HuggingFace Hub. Do not forget to create a model card as well, which will make the model more understandable for the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_huggingface(\"textcat_model_spacy\", generate_card=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we have seen how to train a model with ArgillaTrainer. We have also customized the training process with custom formatting functions and training configs. After training, we have pushed our model to HuggingFace Hub with the `push_to_huggingface` method. You can refer to the [metrics](./use-metrics-007.ipynb) tutorial to see how you can evaluate your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
