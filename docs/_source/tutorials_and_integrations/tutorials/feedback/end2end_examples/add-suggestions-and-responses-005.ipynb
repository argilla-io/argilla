{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add `Responses` and `Suggestions` to `FeedbackDataset` \n",
    "\n",
    "In this part of the end-to-end tutorial series, we will see how we can update the records of our dataset with the responses and suggestions. You can refer to previous tutorials for [creating the dataset](./create-dataset-001.ipynb), [configuring the users and workspaces](./configure-users-and-workspaces-000.ipynb) or [adding metadata](./add-metadata-003.ipynb). Feel free to check out the [practical guides](../../../../practical_guides/practical_guides.md) page for more in-depth information.\n",
    "\n",
    "In Argilla, `responses` are the answers that the annotators give to the questions that we ask them. If we have a dataset that has been annotated already, we can add these gold responses to our dataset as responses. This comes in handy in that we will not have to annotate the dataset again. On the other hand, `suggestions` are the model predictions that we show to our annotators in the UI during the annotation process. This way, the annotation process will become much faster and easier for the annotators. \n",
    "\n",
    "![workflow](../../../../_static/tutorials/end2end/base/workflow_suggestions_and_responses.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Pull the Dataset](#Pull-the-Dataset)\n",
    "    1. [From Argilla](#From-Argilla)\n",
    "    2. [From HuggingFace Hub](#From-HuggingFace-Hub)\n",
    "    3. [Pull the Original Dataset](#Pull-the-Original-Dataset)\n",
    "2. [Add Responses](#Add-Responses)\n",
    "3. [Add Suggestions](#Add-Suggestions)\n",
    "4. [Push the Dataset](#Push-the-Dataset)\n",
    "    1. [To Argilla](#To-Argilla)\n",
    "    2. [To HuggingFace Hub](#To-HuggingFace-Hub)\n",
    "5. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces:** If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](../../../../getting_started/quickstart.md). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "\n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install our dependencies and import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install argilla\n",
    "!pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from datetime import datetime\n",
    "from argilla._constants import DEFAULT_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook we will need some credentials to push and load datasets from `Argilla` and `ðŸ¤— Hub`, let's set them in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Argilla credentials\n",
    "api_url = \"http://localhost:6900\" # \"https://<YOUR-HF-SPACE>.hf.space\"\n",
    "api_key = DEFAULT_API_KEY # admin.apikey\n",
    "# Huggingface credentials\n",
    "hf_token = \"hf_...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log in to argilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.init(api_url=api_url, api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Telemetry\n",
    "\n",
    "We gain valuable insights from how you interact with our tutorials. To improve ourselves in offering you the most suitable content, using the following lines of code will help us understand that this tutorial is serving you effectively. Though this is entirely anonymous, you can choose to skip this step if you prefer. For more info, please check out the [Telemetry](../../../../reference/telemetry.md) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from argilla.utils.telemetry import tutorial_running\n",
    "    tutorial_running()\n",
    "except ImportError:\n",
    "    print(\"Telemetry is introduced in Argilla 1.20.0 and not found in the current installation. Skipping telemetry.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull the Dataset\n",
    "\n",
    "As we uploaded the dataset that we created in the [previous tutorial](./create-dataset-001.ipynb) to both Argilla and HuggingFace Hub, we can pull the dataset from either of them. Let us see how we can pull the dataset from both.\n",
    "\n",
    "### From Argilla\n",
    "\n",
    "We can pull the dataset from Argilla by using the `from_argilla` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_remote = rg.FeedbackDataset.from_argilla(\"end2end_textclassification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From HuggingFace Hub\n",
    "\n",
    "We can also pull the dataset from HuggingFace Hub. Similarly, we can use the `from_huggingface` method to pull the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.FeedbackDataset.from_huggingface(\"argilla/end2end_textclassification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note \n",
    "\n",
    "The dataset pulled from HuggingFace Hub is an instance of `FeedbackDataset` whereas the dataset pulled from Argilla is an instance of `RemoteFeedbackDataset`. The difference between the two is that the former is a local one and the changes made on it stay locally. On the other hand, the latter is a remote one and the changes made on it are directly reflected on the dataset on the Argilla server, which can make your process faster.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us briefly examine what our dataset looks like. It is a dataset that consists of data items with the field `text` that is yet to be annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull the Original Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will be using the gold labels in the original dataset as the responses, we can pull the original dataset from HuggingFace Hub. We can do this by using the `load_dataset` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_org = load_dataset(\"ag_news\", split=\"train[:1000]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels in the original dataset are in the form of integers while we need to present them to the annotators in the form of strings. Therefore, we will create a dictionary that maps the integer labels to their string counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    "mapped_labels = [id2label[label] for label in dataset_org[\"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add `Responses`\n",
    "\n",
    "Now that we have the original dataset and the dataset that we created in the previous tutorial, we can add the responses. The process is slightly different for the local FeedbackDataset and the RemoteFeedbackDataset. Let us see how we can do it for both.\n",
    "\n",
    "### For the local `FeedbackDataset`\n",
    "\n",
    "For the local instance of the dataset, we can iterate over the data items and add the responses for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, record in enumerate(dataset.records):\n",
    "    record.responses = [\n",
    "        {\n",
    "            \"values\":{\n",
    "                \"label\":{\n",
    "                    \"value\": mapped_labels[index],\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the `RemoteFeedbackDataset`\n",
    "\n",
    "For the remote instance of the dataset, we can create a list of the records in the dataset and make the changes on the list. Then, we can update the dataset by the `update_records` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_records = [record for record in dataset_remote.records]\n",
    "\n",
    "for index, record in enumerate(modified_records):\n",
    "    record.responses = [\n",
    "        {\n",
    "            \"values\":{\n",
    "                \"label\":{\n",
    "                    \"value\": mapped_labels[index],\n",
    "                }\n",
    "            },\n",
    "            \"inserted_at\": datetime.now(),\n",
    "            \"updated_at\": datetime.now(),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "dataset_remote.update_records(modified_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add `Suggestions`\n",
    "\n",
    "As we have mentioned, suggestions are the predictions by any model of your preference to be added as suggested responses to our dataset. In this tutorial, we will be using the `cointegrated/rubert-tiny-bilingual-nli` model from the [HuggingFace Hub](https://huggingface.co/cointegrated/rubert-tiny-bilingual-nli) to obtain our model predictions. To obtain the predictions, we will use the `pipeline` method from the `transformers` library, which makes it easy to use models for inference. Let us first load the model. To give us our zero-shot model, we also create a list of the labels that we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cointegrated/rubert-tiny-bilingual-nli\"\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model_name)\n",
    "candidate_labels = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the process is slightly different for the local `FeedbackDataset` and the `RemoteFeedbackDataset`. Let us see how we can do it for both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the local `FeedbackDataset`\n",
    "\n",
    "For the local instance of the dataset, we can iterate over the data items and add the suggestions for each item by classifying the text with the model at the same time. Additionally, we would like to add the model as the `agent` of the suggestions for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in dataset.records:\n",
    "    record.suggestions = [\n",
    "        {\n",
    "            \"question_name\": \"label\",\n",
    "            \"value\": classifier(record.fields[\"text\"], candidate_labels)[\"labels\"][0],\n",
    "            \"agent\": model_name      \n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the `RemoteFeedbackDataset`\n",
    "\n",
    "For the remote instance of the dataset, instead of creating a new `modified_records` list, we will use the same list with the responses added above. Again, we will be getting the model predictions from the `pipeline` method as we are iterating over the records. Similarly, we would like to add the model as the `agent` of the suggestions for future reference. We will use the `update_records` method to update the dataset at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_records = [record for record in dataset_remote.records]\n",
    "\n",
    "for record in modified_records:\n",
    "    record.suggestions = [\n",
    "        {\n",
    "            \"question_name\": \"label\",\n",
    "            \"value\": classifier(record.fields[\"text\"], candidate_labels)[\"labels\"][0],\n",
    "            \"agent\": model_name      \n",
    "        }\n",
    "    ]\n",
    "\n",
    "dataset_remote.update_records(modified_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have split the process of adding responses and suggestions into two for demonstration purposes here. However, you can do both at the same time by iterating over the records only once. In that case, you will need to call the `update_records` method only once for the remote dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the Dataset\n",
    "\n",
    "Now that we have added the responses and suggestions to our dataset, we can push the dataset to Argilla. We can do this by using the `push_to_argilla` method. Please note that you do not have to push the dataset to Argilla if you are using the `RemoteFeedbackDataset` as the changes are directly reflected on the dataset on the Argilla server.\n",
    "\n",
    "### To Argilla\n",
    "\n",
    "If you have opted to pull the dataset from HuggingFace and want to push to Argilla, you can simply use the `push_to_argilla` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    remote_dataset = rg.FeedbackDataset.from_argilla(\"end2end_textclassification_with_suggestions_and_responses\")\n",
    "    remote_dataset.delete()\n",
    "except Exception:\n",
    "    pass\n",
    "remote_dataset = dataset.push_to_argilla(\"end2end_textclassification_with_suggestions_and_responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us go to Argilla and look at the dataset we created. When you first open the dataset, you should the message \"You have no pending records\" as we have uploaded all the responses and there is no pending record left. As seen below, if you go to the `Submitted` tab, you can see that all the records are submitted with the exact labels we have uploaded above. \n",
    "\n",
    "![ui-responses](../../../../_static/tutorials/end2end/text-classification/argilla-annotation-ui-responses.png)\n",
    "\n",
    "As all the records are submitted, we no longer see the suggestion for each one of the records. To demonstrate how they are seen, you can see the Argilla UI below where the record is not submitted yet and the suggestion (`Sports` in this case) is shown to the annotator.\n",
    "\n",
    "![ui-suggestions](../../../../_static/tutorials/end2end/text-classification/argilla-annotation-ui-suggestions.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To HuggingFace Hub\n",
    "\n",
    "If you would like to push the dataset you created to the HuggingFace Hub, you can simply use the `push_to_huggingface` method to upload it. Do not forget to create a model card as well, which will make the dataset more readable and understandable for the users.\n",
    "\n",
    "To be able to upload your dataset to the Hub, you must be logged in to the Hub. The following cell will log us with our previous token.\n",
    "\n",
    "If we don't have one already, we can obtain it from [here](https://huggingface.co/docs/hub/security-tokens) (remember to set the write access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need to call the `push_to_huggingface` method to push the dataset to HuggingFace Hub. If we have a dataset with the same name on the Hub, this method will update the existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=push-dataset-to-huggingface\n",
    "dataset.push_to_huggingface(\"argilla/end2end_textclassification_with_suggestions_and_responses\", generate_card=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we have seen how we can add responses and suggestions to our dataset. Adding responses to your dataset given that you already have the annotated labels is a great way to save time and effort for your project. Similarly, adding suggestions to your dataset will make the annotation process much faster and easier for your annotators. We have seen how we can employ these tools for both `FeedbackDataset` and `RemoteFeedbackDataset`. Now, with the dataset we obtained, we can move on to [training our model](./train-model-006.ipynb) and [computing the metrics](./use-metrics-007.ipynb). For more detailed info on how to utilize various tools, please refer to our [practical guides](../../../../practical_guides/practical_guides.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
