{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Metadata Properties to `FeedbackDataset` for `text-classification`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of our tutorial series for `FeedbackDatasets`, we will show how to use metadata properties to enhance the dataset. We will pull the dataset, add various metadata properties and upload it back. You can have a look at the previous tutorials for [creating the dataset](./create-dataset-001.ipynb) and [configuring the users and workspaces](./configure-users-and-workspaces-000.ipynb). Feel free to check out the [practical guides](../../../../practical_guides/practical_guides.md) page for more in-depth information.\n",
    "\n",
    "Utilizing metadata properties is an effective means of enriching your dataset, enabling effective filtering and sorting. They are the pieces of information for each record that are accessible both in the UI and via SDK. Argilla provides various types of metadata properties, allowing you to tailor their use based on the requirements of your specific project. \n",
    "\n",
    "![workflow](../../../../_static/tutorials/end2end/base/workflow_metadata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Pull the dataset](#Pull-the-Dataset)\n",
    "\n",
    "    A. [From Argilla](#From-Argilla)\n",
    "    \n",
    "    B. [From HuggingFace Hub](#From-HuggingFace-Hub)\n",
    "2. [Add metadata properties](#Add-Metadata-Properties)\n",
    "\n",
    "    A. [TermsMetadataProperty](#TermsMetadataProperty)\n",
    "    \n",
    "    B. [IntegerMetadataProperty](#IntegerMetadataProperty)\n",
    "    \n",
    "    C. [FloatMetadataProperty](#FloatMetadataProperty)\n",
    "3. [Push the dataset](#Push-the-Dataset)\n",
    "\n",
    "    A. [To Argilla](#To-Argilla)\n",
    "    \n",
    "    B. [To HuggingFace Hub](#To-HuggingFace-Hub)\n",
    "4. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Argilla\n",
    "\n",
    "For this tutorial, you will need to have an Argilla server running. There are two main options for deploying and running Argilla:\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces:** If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](../../../../getting_started/quickstart.md). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "\n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter notebook tool of your choice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install our dependencies and import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install argilla\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "from argilla._constants import DEFAULT_API_KEY\n",
    "import statistics\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook we will need some credentials to push and load datasets from `Argilla` and `ðŸ¤— Hub`, let's set them in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argilla credentials\n",
    "api_url = \"http://localhost:6900\"  # \"https://<YOUR-HF-SPACE>.hf.space\"\n",
    "api_key = DEFAULT_API_KEY  # admin.apikey\n",
    "# Huggingface credentials\n",
    "hf_token = \"hf_...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log in to argilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.init(api_url=api_url, api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Telemetry\n",
    "We gain valuable insights from how you interact with our tutorials. To improve ourselves in offering you the most suitable content, using the following lines of code will help us understand that this tutorial is serving you effectively. Though this is entirely anonymous, you can choose to skip this step if you prefer. For more info, please check out the Telemetry page.\n",
    "\n",
    "```python\n",
    "from argilla.utils.telemetry import tutorial_running\n",
    "\n",
    "tutorial_running()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull the Dataset\n",
    "\n",
    "As we uploaded the dataset we created in the [previous tutorial](#previous_tutorial) to both Argilla and HuggingFace Hub, we can pull the dataset from either of them. Let us see how we can pull the dataset from both.\n",
    "\n",
    "### From Argilla\n",
    "\n",
    "We can pull the dataset from Argilla by using the `from_argilla` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.FeedbackDataset.from_argilla(\"end2end_textclassification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From HuggingFace Hub\n",
    "\n",
    "We can also pull the dataset from HuggingFace Hub. Similarly, we can use the `from_huggingface` method to pull the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.FeedbackDataset.from_huggingface(\"argilla/end2end_textclassification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note \n",
    "\n",
    "The dataset pulled from HuggingFace Hub is an instance of `FeedbackDataset` whereas the dataset pulled from Argilla is an instance of `RemoteFeedbackDataset`. The difference between the two is that the former is a local one and the changes made on it stay locally. On the other hand, the latter is a remote one and the changes made on it are directly reflected on the dataset on the Argilla server, which can make your process faster.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us briefly examine what our dataset looks like. It is a dataset that consists of data items with the field `text` that is yet to be annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Metadata Properties\n",
    "\n",
    "Metadata properties are a great way to enhance the dataset for filtering and sorting, both in the UI and SDK. Argilla offers different types of metadata properties that you can make use of according to your needs for the specific project you are working on. For more information on metadata properties, please check out the [documentation](../../../../practical_guides/create_dataset.md#define-metadata).\n",
    "\n",
    "### TermsMetadataProperty\n",
    "\n",
    "The `TermsMetadaProperty` is a metadata property that can be used to filter the metadata of a record based on a list of possible terms or values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_metadata_property = rg.TermsMetadataProperty(\n",
    "    name=\"group\", title=\"Annotation Group\", values=[\"group-1\", \"group-2\", \"group-3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `name` will be the name of the metadata property shown internally. `title` is again the name of the metadata property displayed in the UI. `values` will be the list of possible values for the metadata property. To add it to the dataset, we can simply use the `add_metadata_property` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_metadata_property(terms_metadata_property)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add the metadata to individual records as well. For demonstration purposes here, we can create a list of groups and randomly select one to assign to each record. As we normally do, we should be careful to divide records into groups in equal numbers.\n",
    "\n",
    "We firstly learn how many records we have in the dataset and how many groups we have defined in our `TermsMetadataProperty`. Then, we compile a list of group names, whose length is equivalent to the number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_dataset = len(dataset)\n",
    "num_groups = len(terms_metadata_property.values)\n",
    "\n",
    "groups = [\n",
    "    f\"group-{i}\"\n",
    "    for i in range(1, num_groups + 1)\n",
    "    for _ in range(\n",
    "        length_dataset // num_groups + (1 if i <= length_dataset % num_groups else 0)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we choose one group name randomly, assign it to the record and remove it from the list.\n",
    "\n",
    "The adding process slightly differs among the `FeedbackDataset` and `RemoteFeedbackDataset`. For the former, we can simply add metadata by assigning the value. For the latter, we should use the `update_records` method. Let us see how we can do it for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the local dataset\n",
    "for record in dataset.records:\n",
    "    random_record = random.choice(groups)\n",
    "    record.metadata[\"group\"] = random_record\n",
    "    groups.remove(random_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the remote dataset\n",
    "modified_records = [record for record in dataset.records]\n",
    "\n",
    "for record in modified_records:\n",
    "    random_record = random.choice(groups)\n",
    "    record.metadata[\"group\"] = random_record\n",
    "    groups.remove(random_record)\n",
    "\n",
    "dataset.update_records(modified_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IntegerMetadataProperty\n",
    "The second type of metadata property that Argilla offers is the `IntegerMetadataProperty`, which can be used to filter the metadata of a record based on a range of integer values. While the `name` and `title` are the same as the `TermsMetadataProperty`, we do not have a `values` parameter. Instead, we have `min` and `max` parameters that define the range of the integer values. Let us create an `IntegerMetadataProperty` and add it to our dataset.\n",
    "\n",
    "A metadata property that consists of the longest and shortest data items in our list would be useful for us. To add this, let us first find out what the longest and shortest data items are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = [items.fields[\"text\"] for items in dataset]\n",
    "max_length_string = len(max(item_list, key=len))\n",
    "min_length_string = len(min(item_list, key=len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our metadata property for item length with the shortest and longest data item lengths and add it to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_metadata_property = rg.IntegerMetadataProperty(\n",
    "    name=\"length\",\n",
    "    title=\"Length of the text\",\n",
    "    min=min_length_string,\n",
    "    max=max_length_string,\n",
    ")\n",
    "\n",
    "dataset.add_metadata_property(integer_metadata_property)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add the metadata to individual records. We will be adding the length of the data item to the metadata of each record. Again, we do it differently for `FeedbackDataset` and `RemoteFeedbackDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For local dataset\n",
    "for record in dataset.records:\n",
    "    record.metadata[\"length\"] = len(record.fields[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For remote dataset\n",
    "modified_records = [record for record in dataset.records]\n",
    "\n",
    "for record in modified_records:\n",
    "    record.metadata[\"length\"] = len(record.fields[\"text\"])\n",
    "\n",
    "dataset.update_records(modified_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FloatMetadataProperty\n",
    "\n",
    "The third and last type of metadata property that we can employ for our datasets is the `FloatMetadataProperty`. This metadata property can be used to filter the metadata of a record based on a range of float values. The `name` and `title` parameters are the same as the other metadata properties. Similar to the `IntegerMetadataProperty`, we have `min` and `max` parameters that define the range of the float values. \n",
    "\n",
    "While working with text data, we might want to evaluate the text length and filter our dataset by item lengths. For this purpose, we can make use of the standard deviation of item lengths along with the mean item length. With them, we can keep or work on the items whose lengths are between a certain standard deviation from the mean. We can create a `FloatMetadataProperty` with the min value as the mean minus the standard deviation and the max value as the mean plus the standard deviation. Let us first calculate the mean and standard deviation of the item lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_len_list = [len(items.fields[\"text\"]) for items in dataset]\n",
    "std = round(statistics.stdev(item_len_list), 3)\n",
    "mean = statistics.mean(item_len_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what the mean and standard deviation of the item lengths are, let us create a `FloatMetadataProperty` and add it to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_metadata_property = rg.FloatMetadataProperty(\n",
    "    name=\"length_std\",\n",
    "    title=\"Standard deviation of the length of the text\",\n",
    "    min=mean - std,\n",
    "    max=mean + std,\n",
    ")\n",
    "\n",
    "dataset.add_metadata_property(float_metadata_property)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the float metadata property added to our dataset, let us add the metadata to individual records. We will be again adding the length of the data item. However, this time, we will add it as a float and only to the records whose lengths are between the mean minus the standard deviation and the mean plus the standard deviation. Let us see how we can do it for both `FeedbackDataset` and `RemoteFeedbackDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For local dataset\n",
    "for record in dataset.records:\n",
    "    record_len = float(len(record.fields[\"text\"]))\n",
    "    if record_len <= mean + std and record_len >= mean - std:\n",
    "        record.metadata[\"length_std\"] = record_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For remote dataset\n",
    "modified_records = [record for record in dataset.records]\n",
    "\n",
    "for record in modified_records:\n",
    "    record_len = float(len(record.fields[\"text\"]))\n",
    "    if record_len <= mean + std and record_len >= mean - std:\n",
    "        record.metadata[\"length_std\"] = record_len\n",
    "\n",
    "dataset.update_records(modified_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataset is now a dataset with metadata properties that can be used for filtering and sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedbackDataset(\n",
       "   fields=[TextField(name='text', title='Text', required=True, type=<FieldTypes.text: 'text'>, use_markdown=False)]\n",
       "   questions=[LabelQuestion(name='label', title='Label', description=None, required=True, type=<QuestionTypes.label_selection: 'label_selection'>, labels=['World', 'Sports', 'Business', 'Sci/Tech'], visible_labels=None)]\n",
       "   guidelines=Classify the articles into one of the four categories.)\n",
       "   metadata_properties=[TermsMetadataProperty(name='group', title='Annotation Group', visible_for_annotators=True, type='terms', values=['group-1', 'group-2', 'group-3']), IntegerMetadataProperty(name='length', title='Length of the text', visible_for_annotators=True, type='integer', min=100, max=862), FloatMetadataProperty(name='length_std', title='Standard deviation of the length of the text', visible_for_annotators=True, type='float', min=139.096, max=361.398)])\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the Dataset\n",
    "\n",
    "We have now enhanced our dataset in terms of metadata properties and we can push it again. Note that you do not have to upload the improved version of the dataset to Argilla again. As you can see on your Argilla UI, the dataset already has the metadata properties we added.\n",
    "\n",
    "### To Argilla\n",
    "\n",
    "If you have opted to pull the dataset from HuggingFace and want to push to Argilla, you can simply use the `push_to_argilla` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_dataset = dataset.push_to_argilla(\"end2end_textclassification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the dataset on Argilla has the metadata properties we added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot of Argilla UI](../../../../_static/tutorials/end2end/text-classification/argilla-ui-page-metadata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To HuggingFace Hub\n",
    "\n",
    "If you have opted to pull the dataset from HuggingFace Hub, you can push the dataset to HuggingFace Hub by using the `push_to_huggingface` method. Do not forget to create a model card as well, which will make the dataset more readable and understandable for the users.\n",
    "\n",
    "To be able to upload your dataset to the Hub, you must be logged in to the Hub. The following cell will log us with our previous token.\n",
    "\n",
    "If we don't have one already, we can obtain it from [here](https://huggingface.co/docs/hub/security-tokens) (remember to set the write access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need to call the `push_to_huggingface` method to push the dataset to HuggingFace Hub. If we have a dataset with the same name on the Hub, this method will update the existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_huggingface(name=\"end2end_textclassification\", generate_card=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we have seen how to use metadata properties to enhance our dataset. We have first seen how we can pull the dataset from either Argilla or HuggingFace Hub. Then, we have seen how to add `TermsMetadataProperty`, `IntegerMetadataProperty` and `FloatMetadataProperty` to our dataset. We have also seen how `RemoteFeedbackDataset` works and how to push the dataset to HuggingFace Hub."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argilla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
