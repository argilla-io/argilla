---
title: RLHF
description: Reinforcement Learning with Human Feedback (RLHF) proved to be the driving force behind the power of ChatGPT. Argilla does not provide any out-of-the-box integrations for Reinforcement Learning with Human Feedback (RLHF) but does provide some examples of how to implement this.
links:
  - linkText: Practical Guide to RLHF
    linkLink: https://docs.argilla.io/en/latest/guides/llms/practical_guides/fine_tune.html#rlhf
  - linkText: Reward Model
    linkLink: https://docs.argilla.io/en/latest/guides/llms/examples/train-reward-model-rlhf.html
---
